,Job Title,Salary Estimate,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors
0,Interactive Project Manager,$50k-$128k (Glassdoor Est.),"This position will be located in Cupertino, CA.

Overview


Hero Digital partners with leading brands to build extraordinary customer experiences. This specific role will be working with our Cupertino-based client who is world renowned for crafting products and experiences that change the world. Embedded as an Interactive Producer, you will partner with our clients digital e-commerce team made up of highly focused individuals who express both passion and incredible attention to detail on every project. You will be supporting the rollout of updated and new shopping experiences across multiple digital touch points at a global scale. This involves overseeing projects from initial brief to production, guiding UX/design, copywriting, and development from concepting through the final launch of the project.

What You'll Do
Manage the scope and resourcing for interactive projects
Assist in making adjustments to the project timeline, scheduling, and defining priorities
Ability to articulate the big picture and overarching mission while maintaining a high attention to detail and tactical execution of complex systems
Proactively identify solutions to meet changes in project scope while maintaining the integrity of the creative vision against tight deadlines
Balance project scope, priorities and goals with various teams and keep clear and constant communication channels open with all stakeholders
Work cross-functionally to route layouts, copy, renderings, and production files for review and approval
Schedule handoffs and assure delivery of appropriate assets to teams
Provide quality assurance on projects and promote exceptional quality standards on all deliverables
Who You Are

Bachelors degree with 3+ years relevant experience; agency experience preferred
The ability to communicate high-level concepts and overall business direction to stakeholders
Experience in marketing and the development of digital communications across multiple channels and platforms
Ecommerce/transactional experience required
Ability to distill and simplify complex requests into clear and actionable project plans
Work effectively with creative, development, and cross-functional teams
Demonstrated experience managing multiple projects simultaneously
Strong organizational skills and attention to detail
Ability to work under tight deadlines and respond to shifting priorities, schedules, and deliverables across multiple work streams
Extremely strong communication skills - both written and verbal
A proven track record of delivering results against deadlines
Passion for digital products
Ability to comfortably communicate with designers and developers. A high level understanding of web development principles is a plus
Ability to work onsite in Cupertino/Sunnyvale, CA once we are able to be back in the offer. Free shuttle provided.

Who We Are

We are a leading independent customer experience agency in North America that was born in California, at the intersection of business, design, and technology. Our purpose is to bring moments of Truth & Beauty into people's lives by creating customer experiences that are good for people and good for business. We drive growth and loyalty through a relentless focus of placing our client's customers at the center of their business. Led by the experts in strategy, marketing, data, design, and technology, we work in blended teams, solving client problems and delivering results at market speed. These teams help Fortune 500 companies like Comcast, Oracle, Twitter, U.S. Bank, Salesforce, Sephora, UnitedHealthcare, and TD Ameritrade Institutional invent, transform, and perform to deliver new brand and business value.

Do you share the values that set our company apart?

We are expanding our team of humble and hardworking people who share the qualities we believe in. We seek those who are Wholehearted, Craft-driven, and Bright.

We are grounded in the values of who we are that ultimately lead to moments of Truth & Beauty. We celebrate leaders at all levels who take risks and create magic. We bring our complete, genuine, and whole-hearted selves forward each day. We are craft-driven in nature, with strong curiosities, but with a diligent and meticulous approach. And we bring an unexpected brightness through imagination, inspiration and an optimistic mindset. The commitment we make to our work is the source of our pride and the basis of our reputation.

Above all, Hero Digital is committed to creating an inclusive employee experience. One that reflects the world we live in today. We are an equal opportunity employer that welcomes people regardless of backgrounds, experiences, abilities, and perspectives.",4.1,"Hero Digital
4.1","Cupertino, CA",-1,201 to 500 Employees,2014,Company - Private,Advertising & Marketing,Business Services,$50 to $100 million (USD),-1
1,In-Store Shopper,$50k-$128k (Glassdoor Est.),"Schedule:Part -Time Regular,Reduced Time Seasonal, Part-Time Seasonal

Shifts:
Morning, Day, Evening, Weekend

Flexible Shift Requirements
All flexible shift associates will start on a standard training schedule for 1 day on a day between Monday-Saturday 10:45am-3:30pm. Once training is complete, associates will have the ability to select their shifts and schedule.

Location
We're hiring part-time Shoppers in the following Whole Food Markets locations:

1765 California St, San Francisco CA 94109
399 4th St, San Francisco 94107
450 Rhode Island St, San Francisco CA 94107
2001 Market St, San Francisco CA 94114
1150 Ocean Ave, San Francisco CA 94112

Job opportunities vary by location. We update postings daily with open positions.

Salary
Earn $17.25/hr

Amazon remains open as an essential service to serve our communities delivering critical supplies directly to the doorsteps of people who need them.

Job Description
Join Amazon and become part of a dedicated team that makes shopping a lot easier.
As a Whole Foods Shoppers, youre sure to find the part-time role and environment that will work best for you. Core duties for these teams include:
Use a smartphone, manage apps, and scan bar codes
Check for order quality
Communicate with customers about their orders either verbally or through the app
As a Whole Foods Shopper, youll be working inside a Whole Foods Market and some of your duties will include:
walking the store
picking out groceries for customer orders
getting grocery orders ready for delivery
Youll be able to choose from available shifts each week to create your own schedule.
Start as soon as 7 days. No resume or previous work experience required.
Candidates must be 18 years or older with ability to read and speak English for safety.
Reasons youll love working here:
Earn more: You can expect a competitive wage and reliable pay check when you work for Amazon.
Benefits: From a 401(k) savings plan to employee discounts, Amazon has you covered on perks.
Schedule flexibility: You can choose your shifts to create a schedule that works for you.
Basic qualifications:
High school, GED, or equivalent diploma
Apply now to view available shifts.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",3.9,"Amazon
3.9","Brisbane, CA",-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
2,Asset Protection & Service Ambassador Virtual Hiring Event,$50k-$128k (Glassdoor Est.),"Hiring Immediately! Bloomingdale's Asset Protection Hiring Event!

Event Details
Date: Thursday, September 17, 2020

What We're Hiring For

Asset Protection & Service Ambassador

Asset Protection Supervisor

Intake Details:

Requirements

High School degree or equivalent and/or related Criminal Justice/Administration of Justice preferred

Prior retail security experience preferred but not required

Complete all Security training requirements, maintain personal certifications as required by law

Completing our online application prior to the event is strongly encouraged and will speed up the process.

What to wear

Dress code is Business casual (dress pants/skirt, button down/blouse, optional tie).

About Bloomingdale's

We seek talented creative people with a passion and entrepreneurial spirit who enjoy the fast paced exciting world of retail. We want people with a desire to grow professionally as well as personally because, at Bloomingdale’s, we provide the tools for both.

Your fashion voice and authority is what makes you credible as you engage with an upscale client base. What makes you successful is your ease of conversation, building relationships and connecting with others. Our top performers are goal oriented and can balance multiple priorities in a fast paced environment and most importantly truly have fun at work.

All hourly associates are eligible to receive a quarterly bonus incentive, colleague discounts and the opportunity to be a part of an iconic brand. Certain criteria must be met to receive the quarterly bonus incentive.

What is a Virtual Hiring Event?
Virtual hiring events are a great way for employers and jobseekers to connect, even if they aren't in the same physical location. Hiring is a human process, and they would like to talk with you online (either through chat, on the phone, or video) to see if you’re a fit!

As a Visual Security Officer, you will be an integral part of Bloomingdale's ability to maintain our high level of service and safety. You will have the opportunity to work a flexible schedule including weekends. Your individual responsibilities will include deterring theft via visual observation as well as maintaining a safe business environment.

Visually monitor customer traffic entering and exiting the store
Communicate suspicious activity to Asset Protection/Security",3.1,"Bloomingdale's
3.1","Palo Alto, CA",-1,10000+ Employees,1861,Subsidiary or Business Segment,"Department, Clothing, & Shoe Stores",Retail,$1 to $2 billion (USD),-1
3,Veterinary Receptionist for Emergency Clinic,$50k-$128k (Glassdoor Est.),"AAHA accredited veterinary emergency hospital with a 40+ year history of helping animals and their owners in the Inland Empire is seeking an experienced veterinary receptionist for full time hours.

If you are a
caring,
compassionate,
animal loving

individual, with strong customer service skills, and appreciate a quick-paced environment, we want to meet you.

We are open 365 days a year so weekends and holidays are a requirement.

Previous experience in a veterinary hospital is a necessity.",4.0,"Animal Emergency Clinic
4.0","Grand Terrace, CA",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
4,Part-Time Warehouse Worker Hiring Event,$50k-$128k (Glassdoor Est.),"UPS Hiring Event! Offers on the Spot!

Event Details
Date: Thursday, September 10, 2020, Friday, September 11, 2020

Location: UPS, 1245 Hammerwood Ave, Sunnyvale, CA 94089 US

What We're Hiring For

Part-Time Warehouse Worker

Intake Details:

Requirements

Job requirements depend on job. See job description.

What to bring to this event

A completed application on upsjobs.com is required, but no physical copy is needed.

Completing our online application prior to the event is strongly encouraged and will speed up the process.

What to wear

Dress code is Casual (come as you are, but please be presentable).

How to get to the event

Interview times for both event dates: 6:30am - 8:30am

About UPS
*Apply before the event at upsjobs.com**
Part-Time Warehouse Worker - $17.50/hr

What is a Hiring Event?
Think of it like a job fair, but for one company and more personal. Hiring events are a great way for employers to fill multiple roles quickly. Hiring is a human process, and they would like to meet you to see if you’re a fit!",3.5,"UPS
3.5","Sunnyvale, CA",-1,10000+ Employees,1907,Company - Public,Logistics & Supply Chain,Transportation & Logistics,$10+ billion (USD),-1
5,Find jobs with Flexible Hours!,$50k-$128k (Glassdoor Est.),Search for flexible jobs that allow you to choose your own hours!,3.9,"Indeed Gigs
3.9","Los Angeles, CA",-1,10000+ Employees,2004,Company - Private,Internet,Information Technology,$2 to $5 billion (USD),-1
6,"Child Therapist/Clinician - LCSW, LMFT, LPCC",$50k-$128k (Glassdoor Est.),"Well known and respected Non-profit Behavioral Health organization in the San Jose area is hiring for a Therapist for their Children and Family Program for children ages 0-5. We are offering an excellent compensation and benefits package for this position as well as the opportunity to make a difference in the community!
Responsibilities *
Complete a comprehensive psychological assessment to initiate ongoing behavioral health counseling
Establish goals/treatment through a collaborative process with the client utilizing advanced counseling skills, including evidence-based practices and screening (assessments); create and update treatment plans
Complete and update case files with treatment plans, progress, behavior issues, and other related information regarding the clients behavior outcomes
Coordinate, schedule, and facilitate individual and family therapy sessions to address clients emotional, mental, and social well-being and as outlined in the treatment plan
Comply with HIPPA privacy regulations and maintain confidentiality at all times
Qualifications*
Master’s degree in Social Work, Mental Health Counseling, Counseling, Psychology, or closely related field
LCSW, LMFT, or LPCC full licensure
1 years’ relevant experience
Ability to establish rapport, trust, and boundaries with children, parents, and families
Strong people and interpersonal skills with the ability to interact with diverse groups of people
Excellent verbal and written communication skills
Job Type: Full-time

Pay: $70,000.00 - $80,000.00 per year

Benefits:
401(k)
Dental Insurance
Flexible Schedule
Health Insurance
Paid Time Off
Medical Specialty:
Psychiatry
Schedule:
Monday to Friday",5.0,"Source EQ
5.0","San Jose, CA",-1,1 to 50 Employees,-1,Unknown,-1,-1,Less than $1 million (USD),-1
7,Administrative Assistant,$50k-$128k (Glassdoor Est.),"Come join an amazing team of close to 900 employees dedicated to providing Excellence on Every Level!

The Administrative Assistant provides support to the Office and Operations Manager with minimal supervision. They will support the company mission, policies, procedures, and exhibit a commitment to excellence and collaboration. This person must be able to prioritize, handle sensitive information with confidentially and meet deadlines. A successful Admin will be innovative, committed, use independent judgment to organize a diversified workload.

ESSENTIAL FUNCTIONS

The Administrative Assistant will be assigned specific functions from the general list below but should be cross-trained to perform all listed duties.
Answer/Direct phone calls; take messages to assist Managers
Create, enter, record purchase orders for business unit
Review Driver’s Logs and Driver’s Vehicle Inspection Reports along with timecards for accuracy and maintain for records
Maintain all Job Files; create folder; file permits, Daily Work Reports, and POs
Request Certificates of Insurance of Liability and Bonds for the business unit
Business Licenses complete application and renewals for Business Unit
Overall processing of invoices for payment. Maintain client files and send completed AR to Corporate.
Complete Well Completion Reports after each job is completed
Work with accounting to clear unapproved invoices and purchase orders for month end closing.
Maintain/Updating job files and employee certificates in SharePoint
Maintain UPS/FedEx Accounts and ship packages
Process manual and/or COD checks when needed
Complete all other duties and projects as assigned
JOB REQUIREMENTS AND QUALIFICATIONS
High School Diploma, preferred Associates Degree
At least three years office experience or combination of post High School Education and experience. Excellent verbal and written skills
Must be proficient in MS word, Excel, PowerPoint and ability to learn other programs and software used by the company and ability to access and use data base
Ability to work independently and with a team, keeping confidentiality
Ability to work overtime if needed
Cascade Environmental, LLC, and our subsidiaries is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, national origin, age, sex, religion, disability, sexual orientation, marital status, veteran status, gender identity or expression, or any other basis protected by local, state or federal law. This policy applies with regard to all aspects of one’s employment, including hiring, transfer, promotion, compensation, eligibility for benefits, and termination. EEO is the Law.

Cascade is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at (425) 527-9700.

Who is Cascade?

From our roots as a Northwest regional drilling company, we have grown into a national, full-service environmental services company offering innovative solutions to our customers. We believe in excellence at every level and that includes hiring employees who are the best at what they do. We firmly believe our employees are the most critical component of our long-term success. At Cascade, we provide a career, not just a job.

Cascade’s core purpose is to be the essential business partner that contributes to our clients’ success and advancement in tackling even the most challenging environmental and geotechnical problems, to contribute to our industry and the betterment of our employee’s careers and the communities we serve.

What does Cascade offer?
Comprehensive training and flexible career paths
Encouragement to pursue new roles nationwide, explore a variety of projects, and work with mentors and experts who help shape the industry
Comprehensive Medical/Prescription Drug/Dental/Vision
401(k) Retirement Savings Plan with Company Match
Company-paid Basic Life Insurance / Short- and Long-Term Disability
Health Reimbursement Account and Flexible Spending Account
Sick Leave / Holiday / Vacation Pay
License Bonuses / Tuition Reimbursement
Charitable Donation Match
We are proud to provide a full range of benefits programs that help our employees and their families plan for today and their future. The benefits we offer are competitive and allow flexibility and choice to meet the individual needs of our employees and their families.

Who are you?
Hard-working, talented, and career-minded
Challenge-seeking
Strong desire to contribute to a stable, diverse organization
Work hard, play hard mindset
Open to continued learning and development
Collaborative, team player
Customer service minded
Interested in learning more about Cascade and how we provide Excellence on Every Level? Click here to learn more https://www.youtube.com/watch?v=WwzxUvjbHC0.

To learn more about our exciting career opportunities at Cascade, check out our Careers site at http://www.cascade-env.com/careers",2.5,"Cascade Environmental
2.5","Upland, CA",-1,1001 to 5000 Employees,1991,Company - Private,Energy,"Oil, Gas, Energy & Utilities",$100 to $500 million (USD),-1
8,Fugitive Recovery Agent,$50k-$128k (Glassdoor Est.),"Fugitive Recovery Agent Position *
Fugitive Recovery Investigations, Inc. has an opening for a contracted Fugitive
Recovery Agent on its NORCAL North Team. The ideal applicant will have a basic understanding of California bail law and practice as well as a basic understanding of the
California Penal Code and other compliance codes, prior law enforcement and/or military experience, will be bilingual, and will be interested in a long term position with a growing company which is a top competitor in its industry.

The NORCAL North Team currently works in the northern region of California conducting fugitive investigations including, but not limited to, working with informants, working with state of the art investigative resources, conducting surveillance, performing fugitive apprehensions, conducting the transportation and booking of criminal defendants, and numerous other tasks.
Each agent is required to carry a caseload and work in a team to resolve fugitive investigations. The majority of fugitive investigations take place between Sacramento and
San Francisco Counties south to Monterey and Stanislaus Counties, however at times agents travel as the investigations require.

The work schedule is inconsistent at times and is based on investigations conducted, leads generated, and at times deadlines.
Minimum Requirements *
Be certified pursuant to 1299 and 832 of the California Penal Code
Have reliable transportation, that is registered and insured, that is conducive to surveillance and other investigative operations
Have a basic understanding of California bail law and practice as well as the California judicial system, have good time management & be able to work with limited supervision
Have all required equipment, or be able to acquire all required equipment, to provide contract services to F.R.I including a registered and legally owned firearm, protective and tactical equipment, a laptop computer, reliable cell phone with internet access, etc
Must be computer literate and willing to learn new software and database applications
Must be able to draft motions and declarations for various superior courts in regards to the cases that are assigned.
Must have tactical experience, a willingness to learn & a flexible schedule
Job Type: Commission

Schedule:
Monday to Friday
On Call
Experience:
Computer Literacy: 1 year (Preferred)
Multilingual: 1 year (Preferred)
relevant: 2 years (Required)
Commission Only:
No
Work Location:
Multiple locations
On the road
Pay Frequency:
Bi weekly or Twice monthly
This Company Describes Its Culture as:
Detail-oriented -- quality and precision-focused
Aggressive -- competitive and growth-oriented
Outcome-oriented -- results-focused with strong performance culture
People-oriented -- supportive and fairness-focused
Team-oriented -- cooperative and collaborative",-1,Fugitive Recovery Investigations Inc.,"Oakland, CA",-1,-1,-1,-1,-1,-1,-1,-1
9,Fugitive Recovery Agent,$50k-$128k (Glassdoor Est.),"Fugitive Recovery Agent Position *
Fugitive Recovery Investigations, Inc. has an opening for a contracted Fugitive
Recovery Agent on its NORCAL North Team. The ideal applicant will have a basic understanding of California bail law and practice as well as a basic understanding of the
California Penal Code and other compliance codes, prior law enforcement and/or military experience, will be bilingual, and will be interested in a long term position with a growing company which is a top competitor in its industry.

The NORCAL North Team currently works in the northern region of California conducting fugitive investigations including, but not limited to, working with informants, working with state of the art investigative resources, conducting surveillance, performing fugitive apprehensions, conducting the transportation and booking of criminal defendants, and numerous other tasks.
Each agent is required to carry a caseload and work in a team to resolve fugitive investigations. The majority of fugitive investigations take place between Sacramento and
San Francisco Counties south to Monterey and Stanislaus Counties, however at times agents travel as the investigations require.

The work schedule is inconsistent at times and is based on investigations conducted, leads generated, and at times deadlines.
Minimum Requirements *
Be certified pursuant to 1299 and 832 of the California Penal Code
Have reliable transportation, that is registered and insured, that is conducive to surveillance and other investigative operations
Have a basic understanding of California bail law and practice as well as the California judicial system, have good time management & be able to work with limited supervision
Have all required equipment, or be able to acquire all required equipment, to provide contract services to F.R.I including a registered and legally owned firearm, protective and tactical equipment, a laptop computer, reliable cell phone with internet access, etc
Must be computer literate and willing to learn new software and database applications
Must be able to draft motions and declarations for various superior courts in regards to the cases that are assigned.
Must have tactical experience, a willingness to learn & a flexible schedule
Job Type: Commission

Schedule:
Monday to Friday
On Call
Experience:
Computer Literacy: 1 year (Preferred)
Multilingual: 1 year (Preferred)
relevant: 2 years (Required)
Commission Only:
No
Work Location:
Multiple locations
On the road
Pay Frequency:
Bi weekly or Twice monthly
This Company Describes Its Culture as:
Detail-oriented -- quality and precision-focused
Aggressive -- competitive and growth-oriented
Outcome-oriented -- results-focused with strong performance culture
People-oriented -- supportive and fairness-focused
Team-oriented -- cooperative and collaborative",-1,Fugitive Recovery Investigations Inc.,"Oakland, CA",-1,-1,-1,-1,-1,-1,-1,-1
10,Electrician - 5 Yrs+ Experience,$50k-$128k (Glassdoor Est.),"Knowledge/Skills:

· Ability to take initiative and work independently on projects

· Excellent communication skills for working with both co-workers, vendors, subcontractors and clients

· Ability to present facts and recommendations verbally and in writing

· General Electrical California State Certification a plus

Minimum Requirements:

· Experience as a general electrician (residential and commercial)

· Must be able to perform panel upgrades and meter installs

· Must have a solid comprehension of electrical specifications

· Knowledgeable of the National Electrical Code

· Must have a valid CA driver's license with no points in the last 12 months

Job Type: Full-time

Pay: $40,000.00 - $60,000.00 per year

Benefits:
Paid time off
Retirement plan
Schedule:
Day shift
Monday to Friday
Experience:
electrician : 5 years (Preferred)
journeyman electrician: 5 years (Preferred)
residential and or/commercial building and service: 5 years (Preferred)
Work Location:
Multiple locations
Work Remotely:
No",-1,Electrical Company,"San Diego, CA",-1,51 to 200 Employees,-1,Company - Private,Consumer Products Manufacturing,Manufacturing,$10 to $25 million (USD),-1
11,Escrow Assistant,$50k-$128k (Glassdoor Est.),"We are hiring for ALL five of our office locations. We have offices in Mission Valley, La Mesa, Rancho Bernardo, Esondido and Del Mar.

Are you an experienced Escrow assistant interested in working for the fastest growing, largest, independent Escrow company in San Diego?

Must have minimum of 3 years of escrow assisting experience in a fast paced environment. Must enjoy working in a family like environment and being a team player.

Full time position, complete benefits package with medical, dental, vision, 401K with company match.

Looking for an immediate start date for the ideal candidate.",5.0,"Oakwood Escrow
5.0","San Diego, CA",-1,51 to 200 Employees,-1,Unknown,-1,-1,Less than $1 million (USD),-1
12,Customer Service Representative,$50k-$128k (Glassdoor Est.),"Job Title: Customer Service Representative
Department: Customer Service
Reports to: Director of Marketing & eCommerce
Location: Ventura, CA USA or Remote
Summary:
Orbit Baby is looking for an enthusiastic self-starter to join our Customer Service team. In this role, you’ll be pivotal in offering a premium beginning-to-end experience for Orbit Baby customers. You’ll apply a modern approach to Customer Service utilizing the latest technologies to provide a personalized and delightful experience. Your top priority will be to ensure that Orbit’s customers feel supported and inspired at every step of their journey- from initial research to enjoying our products as a family. You’ll work side by side with colleagues across other disciplines, including Marketing and Operations, to share valuable insights pertaining to Orbit’s customers, products, and how to continually improve the way we deliver our overall experience.
More about you:
You are enthusiastic, friendly, service-oriented, energetic, technically-savvy and motivated to help others. You seek and apply innovative solutions to the art of customer experience. You’re performance driven, a natural problem solver, and a strong communicator with a true passion for assisting others and making personal connections. You possess a desire to shine in your role, taking on increased opportunities commensurate with your professional development and the brand’s continued growth.
Key Responsibilities:
Provide a premium customer experience to customers via all Orbit Baby support channels, including phone, email, live chat, SMS, and events.
Resolve any questions, comments, and issues from customers, tailoring solutions according to Orbit’s policies.
Develop, maintain, and achieve all required Customer Support KPI, including; Customer Satisfaction, Abandon Rate, Average First Reply Time, One Touch Resolution Rate and others.
Monitor and report weekly issue trends, and product/sales performance. Develop and share insights with other departments as required.
Maintain and continually improve Orbit Baby’s Help Center.
Moderate, manage and develop Orbit Baby’s community forum via the Zendesk Community App.
Engage and monitor social media channels for customer support, conversation engagement and brand sentiment.
Manage, process, accept or decline customer return authorization requests and coordinate returns as necessary and in line with Orbit Baby warranty and return policies.
Participate in related monthly operations and quarterly business reviews as required to ensure a consistent and premium support experience across Orbit’s business.
Support the inspection, classification and disposition of inventory as may be required on a quarterly basis.
Develop expertise and mastery of Orbit Baby products, policies, and brand.
Requirements:
A minimum of 5-yrs of multi-channel Customer Support experience, preferably with premium brands.
A passion for Customer Support and eCommerce.
Exceptional communication skills, with attention to details, tone, and voice.
Experience and expertise using Zendesk.
Technically proficient with a strong working knowledge of Excel.
Understanding of professional situations and efficient execution.
Comfortable working across multiple communication channels.
Exceptional writing skills.
Ability to work within Orbit’s operating hours, including flexibility around special events, circumstances, and holidays.
Ability to work independently and in a team environment.
Education:
Bachelor’s Degree preferred.
We Offer:
Ability to work remotely.
Competitive Wages.
Environment for growth and career development.
A fun-loving, success-oriented growing team.
Training in new technologies.
To Apply:
Apply below by clicking the button ""Apply""
Resumes submitted without a cover letter will be rejected.
About Orbit Baby:
Founded in 2004, Orbit Baby is a leader in the modern-day luxury baby stroller industry. Known for their patented technology and innovative travel systems, their goal has always been to design the safest and most versatile baby products in the marketplace. Their patented Smart Hub™ technology enabled their baby seat to smoothly turn 360 degrees without disruption, and allowed perfect compatibility and modularity of their stroller, car seat and bassinet. Orbit Baby travel systems quickly became heralded for their convenience, style, safety, and optimized role in engagement between baby, parent, and the world around them. Orbit Baby has newly returned to the North American market with an all-new leadership team and a collection of updated products developed for safety, style, and premium comfort for babies and parents.
Orbit Baby provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",3.1,"Orbit Baby, Inc.
3.1","Ventura, CA",-1,1 to 50 Employees,-1,Subsidiary or Business Segment,Consumer Products Manufacturing,Manufacturing,$5 to $10 million (USD),-1
13,Warehouse Team Member,$50k-$128k (Glassdoor Est.),"Shifts: Overnight, Sunrise, Day, Evening, Weekend

Location
San Leandro, CA
Job opportunities vary by location. We update postings daily with open positions.

Salary
$16.35/hr - $17.75/hr

Immediate openings available now. Start as soon as 7 days. No resume or previous work experience required.
Amazon remains open as an essential business to serve our communities delivering critical supplies directly to the doorsteps of people who need them. Find out what Amazon is doing to provide a safe environment for employees at this time on our COVID-19 FAQ page: https://www.amazondelivers.jobs/covid-19-updates/
Join Amazon and become part of the dedicated team that gets orders ready for people relying on Amazons service. Earn a competitive wage while learning new skills and building your experience by doing a range of different types of work. Stay active in this fast-paced warehouse environment.

Candidates must be 18 years or older with ability to read and speak English for safety.

What this job will be like:
The Delivery Station Team is the final stop for orders on their way to getting to customers. As a Delivery Station Team Member, you will get packages ready for their final destination. You will receive truck deliveries and build, wrap, sort, and transport pallets and packages. These duties will rotate on a daily basis. Youll also get to use technology like smartphones and handheld devices to sort, scan, and prepare orders for delivery.
This is a part-time role. You will work 4-hour shifts early in the morning or late at night for 15-25 hours a week. Shift times will vary to ensure we meet customer-promised delivery times during the day. Flexibility is key.

Reasons youll love working here:
Health and safety are a top priority with all of our roles and sites. We continue to consult with medical and health experts, and take all recommended precautions in our buildings and stores to keep people healthy.
• Earn more: You can expect a competitive wage and reliable pay check when you work for Amazon.
• Career development: Many of our entry-level warehouse employees become leaders in operations, HR, and other areas. See where your Amazon journey can take you.
• Teamwork environment: Work is more fun when you are part of a great team.
• Variety every day: Your days will keep you busy with different types of work.

Basic qualifications:
• High school, GED, or equivalent diploma

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.
Basic qualifications:
High school, GED, or equivalent diploma
Apply now to view available shifts.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin,gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

0",3.9,"Amazon
3.9","San Leandro, CA",-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
14,TRACK AND TRACE ASSISTANT,$50k-$128k (Glassdoor Est.),"JOB RESPONSIBILITIES:
This position is part of the Track and Trace team and works alongside the greenhouse crew to track the movement of plants and maintain inventory counts. Daily tasks include obtaining plant transfer information, providing plant ID tags for all plants, and recording harvest information for the track and trace team. This role will assist in taking regular inventory counts and reporting.
JOB DUTIES:
Provide plant transfer information
Confirm accuracy of plant transfer information
Ensure all plants are appropriately tagged
Take inventory counts
Assist track and trace team as needed
SKILLS and QUALIFICATIONS:
21+ years old
Attention to detail
Able to work in fast paced environment
Bilingual preferred
OTHER SKILLS and ABILITIES:
Must be a self-starter with minimal supervision, able to work independently and in a team environment
Ability to stay organized
Willingness to work weekends
MENTAL/ PHYSICAL REQUIREMENTS:
Ability to work in conditions typically found in an office setting and in greenhouses with high humidity and varying temperatures
Ability to exert up to 15-50 pounds occasionally in order to lift and move product
Ability to balance, reach grasp while climbing on a step stool and/ or ladder
Ability to crouch, grasp and lift product above shoulders in order to lift product from the floor properly
Ability to be on feet while performing job responsibilities
EDUCATION and/or EXPERIENCE:
Experience with Metrc track and trace a plus
Experience with inventory counting a plus
Cannabis experience a plus
High School diploma or equivalent (preferred)
PAY: $16.00 HOURLY",-1,GLASS HOUSE FARMS,"Carpinteria, CA",-1,-1,-1,-1,-1,-1,-1,-1
15,TRACK AND TRACE ASSISTANT,$50k-$128k (Glassdoor Est.),"JOB RESPONSIBILITIES:
This position is part of the Track and Trace team and works alongside the greenhouse crew to track the movement of plants and maintain inventory counts. Daily tasks include obtaining plant transfer information, providing plant ID tags for all plants, and recording harvest information for the track and trace team. This role will assist in taking regular inventory counts and reporting.
JOB DUTIES:
Provide plant transfer information
Confirm accuracy of plant transfer information
Ensure all plants are appropriately tagged
Take inventory counts
Assist track and trace team as needed
SKILLS and QUALIFICATIONS:
21+ years old
Attention to detail
Able to work in fast paced environment
Bilingual preferred
OTHER SKILLS and ABILITIES:
Must be a self-starter with minimal supervision, able to work independently and in a team environment
Ability to stay organized
Willingness to work weekends
MENTAL/ PHYSICAL REQUIREMENTS:
Ability to work in conditions typically found in an office setting and in greenhouses with high humidity and varying temperatures
Ability to exert up to 15-50 pounds occasionally in order to lift and move product
Ability to balance, reach grasp while climbing on a step stool and/ or ladder
Ability to crouch, grasp and lift product above shoulders in order to lift product from the floor properly
Ability to be on feet while performing job responsibilities
EDUCATION and/or EXPERIENCE:
Experience with Metrc track and trace a plus
Experience with inventory counting a plus
Cannabis experience a plus
High School diploma or equivalent (preferred)
PAY: $16.00 HOURLY",-1,GLASS HOUSE FARMS,"Carpinteria, CA",-1,-1,-1,-1,-1,-1,-1,-1
16,TRACK AND TRACE ASSISTANT,$50k-$128k (Glassdoor Est.),"JOB RESPONSIBILITIES:
This position is part of the Track and Trace team and works alongside the greenhouse crew to track the movement of plants and maintain inventory counts. Daily tasks include obtaining plant transfer information, providing plant ID tags for all plants, and recording harvest information for the track and trace team. This role will assist in taking regular inventory counts and reporting.
JOB DUTIES:
Provide plant transfer information
Confirm accuracy of plant transfer information
Ensure all plants are appropriately tagged
Take inventory counts
Assist track and trace team as needed
SKILLS and QUALIFICATIONS:
21+ years old
Attention to detail
Able to work in fast paced environment
Bilingual preferred
OTHER SKILLS and ABILITIES:
Must be a self-starter with minimal supervision, able to work independently and in a team environment
Ability to stay organized
Willingness to work weekends
MENTAL/ PHYSICAL REQUIREMENTS:
Ability to work in conditions typically found in an office setting and in greenhouses with high humidity and varying temperatures
Ability to exert up to 15-50 pounds occasionally in order to lift and move product
Ability to balance, reach grasp while climbing on a step stool and/ or ladder
Ability to crouch, grasp and lift product above shoulders in order to lift product from the floor properly
Ability to be on feet while performing job responsibilities
EDUCATION and/or EXPERIENCE:
Experience with Metrc track and trace a plus
Experience with inventory counting a plus
Cannabis experience a plus
High School diploma or equivalent (preferred)
PAY: $16.00 HOURLY",-1,GLASS HOUSE FARMS,"Carpinteria, CA",-1,-1,-1,-1,-1,-1,-1,-1
17,Controller,$50k-$128k (Glassdoor Est.),"Controller
Mountain Bikers of Santa Cruz’s (MBOSC) Controller is responsible for maintaining the
infrastructure and systems needed to support our financial objectives and maximize our return on
financial assets. This individual will establish financial policies, procedures, controls and
reporting systems. This position is also responsible for our HR function which includes
maintaining our personnel Handbook, coordinating staff onboarding/offboarding with hiring Managers,
and overseeing employee growth development. We seek a seasoned finance leader to serve as our
Controller to take responsibility for all financial and HR management systems to report to and work
closely in support of the Operations Director, and Executive Director.

Time Commitment: Full Time. Flexible schedule, requires some evening and weekend work.
Salary: $75,000 - $85,000 Based on Experience
Benefits: Health insurance (including vision and dental), retirement, vacation, holidays and sick
leave, cell phone service stipend.

Position Responsibilities
● Works closely with the COO or ED in developing MBOSC's strategic plan
● Serves as the primary liaison to the board’s Audit and Finance Committees, working closely to
strengthen MBOSC's financial position.
● Continually evaluates best industry practices in comparison to internal systems, with an eye
toward future needs and budget realities.
● Overall financial management responsibility including the development and refinement of,
weekly internal management reports, monthly / quarterly / and annual financial statements to
department managers and senior management, and update presentations to the Board.
● Will work closely with Directors and their staff to educate them regarding finance and
accounting procedures and will provide financial reports and support for their program
requirements.
● Coordinate annual budgeting; oversee financial forecasting, cash flow and preparation for
annual audits, as well as taking final responsibility for accurate and well-managed accounts
receivable and payable.
● Maintains and updates our Staff HR functions including the coordination of onboarding,
communication, training/growth development, and benefit programs.
● Manage and develop our finance staff including selecting, orienting, training and
cross-training employees.
● Coordination of annual Tax preparation and filing.
● Prepares special reports as needed by collecting, analyzing, and summarizing
information, and provides guidance on recommended actions.


● Coordinate Grant compliance between finance, program and fund development (where applicable);
ensure that program managers are kept abreast of grant-supported work and related balances, and
that expenditures are consistently aligned with grant and
program budgets throughout the grant period; collate financial reporting materials for corporate,
foundation, and government awards, including full compliance with federal cost principles in the
relevant circulars.
● Maintains professional and technical knowledge by attending educational workshops; reviewing
professional publications; establishing personal networks; participating in professional societies,
and, when appropriate, recommending similar steps for the Accounting Manager in particular.
● Assists the management team in achieving budget objectives by advising on optimal scheduling
of expenditures, creating transparent reporting processes, analyzing variances and engaging
necessary managers in discussions of appropriate steps to take thereby initiating corrective
measures.
● Protects assets and the overall accuracy, confidentiality, and reliability of MBOSC's
financial reporting by establishing, monitoring and enforcing appropriate controls, policies and
procedures.
● Leads in a manner to ensure compliance with federal, state, and local legal requirements by
studying existing and new legislation, anticipating future legislation, enforcing adherence to
requirements, filing financial reports, and advising management on needed actions.
● Works with the highest standards of integrity, ongoing team support, and overall
organizational confidentiality.

Qualifications
● 10+ years of experience with at least 5 years managing a Finance and HR Department.
Demonstrated experience in the specific hands-on work in financial management and accounting
● Particular facility with Excel or Sheets, and a general comfort with digital technology,
networked operations, advanced Telecom, office applications and Adobe Acrobat.
● Experience with complex charts of accounts and advanced accounting software is a necessity to
be successful, and experience with Construction Project job costing.
● QB Accounting. Experience with CRM systems would be helpful.
● Demonstrates outstanding time management skills and interpersonal leadership.
● Strong written, verbal and listening communications skills
● Experience with financial and A-133 audits, legal compliance and budget development.
● Proven effectiveness managing and developing others, empowering them to make decisions when
appropriate

● Experience effectively communicating key data, including presentations to program managers,
senior management, the Board or other outside stakeholders, funders and influentials.
● Experience with HR best practices, hiring and onboarding support, termination, personnel
development activities, and coordination of employee benefits programs.
● Success seeing beyond the numbers, identifying trends and new possibilities. Integrity/ethics
beyond reproach and a passion for MBOSC's mission.
● Attentive to detail, producing consistent, reliable, accurate and understandable work product.
● Familiarity with conservation, construction, and/or outdoor sports industries
● Ability to manage multiple projects independently
● Experience with Google Drive and Google Calendar

MBOSC Values
● Integrity - Acts with honesty
● Excellence - Do whatever it takes to ensure the highest level of quality
● Service - Exceed expectations, keep promises, and focus on helpfulness
● Teamwork - Work for the good of the whole
● Financial Stewardship - Be accountable for exemplary fiscal stewardship
● Inclusiveness - Embrace and appreciate individual differences
● Transparency - Operate with openness
● Collaboration - Partner in all we do
Performance Metrics and Evaluation
● Overall performance and contributions to the organization
● Ability to function as a key member of our team
● Ability to build relationships with employees, Board and Finance Committee Members, and
partnering organizations.
● Ability to problem solve

Apply
To apply for this position please submit the following to jobs@mbosc.org. Please no calls or drop
ins.
● Cover letter
● Resume
● Three professional references",-1,"JVS, San Francisco
3.5","Santa Cruz, CA",-1,1 to 50 Employees,-1,Unknown,-1,-1,Less than $1 million (USD),-1
18,Third Party Coordinator (Office Engineer),$50k-$128k (Glassdoor Est.),"Harris is a 100% employee-owned company focused on solving today's complex challenges in planning, design, and construction of public infrastructure. Our offices and project sites span the West Coast in California, Nevada, and Washington with a staff of over 200 employee-owners. We focus on serving clients in the municipal, water, transportation, and education markets.

Harris is looking for a Third Party Coordinator (Office Engineer) to join our dynamic Program & Construction Management team in Fresno, California. If you're a driven professional looking for a collaborative environment, work that makes a difference, and a firm that invests heavily in your growth, you could be a perfect fit for Harris & Associates.

Responsibilities & Duties

Position responsibilities include, but are not limited to the following:
Assist with Coordination efforts with Excluded Third Parties
AT&T
PG&E
Schedule
Coordinate Design Deliverable Dates
Coordinate Construction Deliverable Dates
Interface with Service Relocations/Reconnections/Disconnects
Agreements
Utility Agreements
Notice to Owners
Track Projected Relocation Costs
Submittals
Utility Relocations
Variances
Track Submittals
Request for Information (RFI's)
Track and Process
Meetings
Agendas
Meeting Minutes
Prepare Exhibits
Environmental
Interface with Environmental for relocations that may fall outside of footprint
Right of Way
Review Easement Requirements
Qualifications & Skills
College degree from a four-year institution
0 - 3 years construction experience in a diverse construction environment
Compensation & Benefits

We offer competitive salaries and benefits, including medical, dental, vision, and life insurance. Harris & Associates is an Equal Opportunity Employer (EOE AA M/F/Vet/Disability) and provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics.

Harris expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability or veteran status.

Powered by JazzHR",3.6,"Harris & Associates
3.6","Fresno, CA",-1,201 to 500 Employees,1974,Company - Private,Architectural & Engineering Services,Business Services,$50 to $100 million (USD),-1
19,General Labor,$50k-$128k (Glassdoor Est.),"We are HIRING!!!

Has your employment money ran out? Getting bored of just staying home? Looking for work? Come out and join the TEAM


We have multiple positions available.


Entry level construction (Molding blocks)
Cabinet building
Machine operator
Lamination
Fabrication
Welding
Lumpers
Packers
Cooks
Dishwashers
Forklift Drivers
Class C
Class A
And more....

Join the TEAM TODAY!!!",-1,Sync Staffing,"Riverside, CA",-1,1 to 50 Employees,-1,Unknown,-1,-1,Less than $1 million (USD),-1
20,Customer Service Specialist,$50k-$128k (Glassdoor Est.),"Do you have an entrepreneurial spirit? Do you dream of working on a team of like-minded individuals that love to work hard, play hard and have a great time while doing so? Do you long for an environment that believes in you being able to make your desk your own franchise instead of the wanting you to fall in line with the other drones that walk lifelessly around the office? If you’re nodding your head Yes vigorously, we’ve have the perfect opportunity for you!

LifePro™ Financial Services, Inc. is a premier distributor of life, annuity, and long-term care and securities based insurance products serving over 5,000 financial professionals nationwide. The company, based in Southern California and formally established in 1986, has roots as a life insurance marketing organization that goes back over forty years. The company was formed to help independent insurance agents, financial planners, and other financial service professionals become successful. They are LifePro’s customers and we understand that our success depends on their success.
This position is an excellent opportunity for a motivated, energetic individual to join our Case Management team. LifePro™ provides full service, back office support for independent financial advisors. It is the role of the Case Manager to gather all of the necessary documents and requirements of an application, as needed, from our representatives/agents, and follow the application through the various stages of underwriting through application completion. During this time it is the responsibility of the Case Manager to provide constant communication to and from the agent and the insurance carrier that the application is with. It is imperative that every interaction that we have with our representatives be positive and supporting. It is also vital that the communication we have with our insurance carriers and vendors demonstrates that we are a true partnership with them.
Daily responsibilities will eventually include, but are not limited to:
Processing of incoming life insurance and annuity applications; ensuring that every application is complete with the correct paperwork, requirements and signatures.
Working closely with various LifePro™ departments such as Contracting, Field Support Representatives, and Administration.
Responding to inquiries from agent and insurance carriers via phone and email.
Tracking status of submitted applications and providing status to agents.
Learning and maintaining industry product knowledge, with a focus on the LifePro vendor companies
Training our advisors and advisors assistants on using the e-platform to submit new business applications.
Keeping up to date on industry, insurance carrier and underwriting updates.
A qualified candidate must always present a positive, professional attitude and be a true team player. Characteristics include, but are not limited to, the following:
Positive Attitude – A great attitude will make all of the difference in your success.
Phones – You must exhibit a pleasant, upbeat, professional attitude. You will be speaking with agents and vendor company personnel on the agent’s behalf. Our goal is to have everybody that we come in contact with be a LifePro™ evangelist.
Computer Skills – Basic to intermediate computer skills are required. While you do not need to know the programs specific to our business, you must be able to navigate your way on the computer, and have basic knowledge of Microsoft Office.
Project Management – You must be able to work independently and manage multiple applications, while maintaining your composure. An ideal candidate is well organized, possesses excellent attention to detail, and is able to multi-task without becoming overwhelmed.
Strong Analytical Mindset – You must have the ability to think outside the box and understand that sometimes there are many solutions to one situation. Being able to dig deeper into any situation is must.
Team Player – Although you will be working independently, you will be a part of the Case Management team, as well as the LifePro™ team as whole. An ability to be able to draw on and respect the knowledge of others, as well as offer feedback yourself is a must.
Reliable and Dependable – Our perfect candidate is one that has the ability to be at work on time every day. We expect you to have a personal life outside of the office, yet be able to be focused 100% to our business inside of our work hours.
A successful candidate must always possess a positive, professional attitude, and be a consummate team player. Experience in a high volume, high touch, service position or call center environment is a plus. Strong communication, organization and sales skills are necessary.
We offer a competitive base salary with a motivating bonus structure, as well as comprehensive benefits. These coupled with inspiring leadership and an enjoyable work environment make LifePro™ “The Greatest Company of Its Kind in the World”.",4.1,"LifePro Financial Services
4.1","San Diego, CA",-1,1 to 50 Employees,1986,Company - Private,Insurance Agencies & Brokerages,Insurance,$10 to $25 million (USD),-1
21,Compliance Specialist,$50k-$128k (Glassdoor Est.),"Aperto Property Management, Inc. is seeking an experienced and qualified Compliance Specialist for Northern California . Qualified candidates will have experience with HUD/LIHTC.
In this role you will be responsible for maintaining file compliance for assigned properties.
The requirements listed below are representative, but not exclusive of the knowledge, skill and/or ability required:
Minimum 4 years’ experience with LIHTC & HUD programs
Yardi experience
Onesite experience
Certification in related field a plus
Ability to read and interpret complex documents, such as regulatory agreements and compliance regulations, tenant files, etc.
Ability to successfully manage multiple competing priorities
Some of the Responsibilities:
Oversee completion of files to ensure they are compliant with applicable Affordable Programs including Move-Ins, Annual Recertification, Interim Recertification, Gross Rent Changes, Terminations, Initial Certifications
Review files to ensure they are compliant with applicable Affordable Programs
Complete Enterprise Income Verification (EIV) tasks, including running reports and working discrepancies
Ensure income/rent limits and utility allowances are accurate on each certification
Ensure calculated tenant rent and subsidies are accurate
Monitor status of all certifications
Monitor portfolio compliance with state, federal, local agency requirements for Affordable programs
Identify and work through potential compliance issues, working with the Managers
Perform site file reviews for property audit preparation
Attend state and national compliance trainings, as directed
Assist in compiling/preparing data to ensure all annual/quarterly agency audits/reports are completed timely
Work with the site teams to ensure the HUD Voucher is submitted timely
Participate and assist with the updates to income/rent limits and updates to Utility allowances to ensure compliance is maintained per affordable housing requirements
Provide excellent customer service
Communicate professionally and effectively, verbally and in writing and provide customer assistance and answer questions on compliance issues
Promote a supportive environment
Work as an effective member of a team and in a collaborative manner with staff, peers, and supervisor
Other duties, as assigned and/or as necessary",5.0,"Aperto (CA)
5.0","Sacramento, CA",-1,201 to 500 Employees,-1,Company - Public,Real Estate,Real Estate,Unknown / Non-Applicable,-1
22,Finish Carpenter,$50k-$128k (Glassdoor Est.),"Installation of crown moldings, baseboard, door and window trim, and all related finish carpentry. Must have tools and vehicle to get to various local job sites in the Los Angeles area.

Job Type: Full-time

Pay: $20.00 - $25.00 per hour

Experience:
* Finish Carpentry: 3 years (Preferred)",3.6,"ASD
3.6","Canoga Park, CA",-1,51 to 200 Employees,1987,Company - Private,IT Services,Information Technology,$25 to $50 million (USD),-1
23,Interior Design Assistant/Sales,$50k-$128k (Glassdoor Est.),"We are seeking a highly motivated and team-oriented individual to join our Retail Sales Team as an addition to the largest furniture business located in the Central Valley. If you are self-motivated, have an entrepreneurial spirit, coachable, professional, have Integrity and a true people person we are interested in discussing a career position with us.
We have devoted over 47 years to assisting people to create and design beautiful living spaces whether they are starting out or updating their home furnishings. Our sales associates are the face of the company and are to maintain long term relationships with our customers. The diversity, quality, custom choices of pieces and fabrics give the customer endless possibilities for their home and it is with the assistance of the Sales Associate that make it possible the customer makes the best choice for their home. We want you to make help make their ‘house’ into a ‘home’. This is a high-level sales position with high-end income potential.

Responsibility:
Welcome each quest in a professional and friendly manner.
Follow the company’s sales guidelines seeking out what they are looking for and how much do they want to spend.
Complete post-sales procedures.
Follow up with your customers to ensure good customer service.
Develop and maintain knowledge of various products from multiple vendors.
Maintain a high level of customer service in all aspects of the sales process.
Complete showroom recovery to maintain its beautiful and clean appearance.
Be a passionate professional team associate.
Focus on the customer’s needs and wants.
Knowledge, Skills, and Abilities for Retail Sales Associate:
*Exceptional Customer relationship skills.
*Work professionally with customers and co-workers.
*Proficient computer skills.
*Excellent verbal skills with attention to detail.
*Assist customers in an inspirational way creating a partnership environment.
*Follow through the sale from beginning to delivery.
*Good organizational and professional skills.
*Be coachable to continuously improve the sales experience for each customer.
* Maintain confidentiality.
*Average income $40 to $80K+ a year.",-1,Hansen's Home Furnishing Center,"Modesto, CA",-1,1 to 50 Employees,1972,Unknown,Home Furniture & Housewares Stores,Retail,Unknown / Non-Applicable,-1
24,Enrollment Coordinator,$50k-$128k (Glassdoor Est.),"Overview


Are you passionate about improving the lives of low and moderate income San Franciscans? Do you want to learn more about local and state health care programs while expanding your communication and customer oriented skills? San Francisco Health Plan is looking for you!

San Francisco Health Plan is a public, not for profit, mission driven organization working towards universal health coverage. Our highly trained Enrollment Services team seeks a full time, bilingual (Spanish, Cantonese, or Mandarin, and English) Enrollment Coordinator. As an Enrollment Coordinator, you will serve the diverse communities of San Francisco at our Service Center. You will experience the deep satisfaction of helping immigrants, low income families, the elderly and disabled enroll into health care programs, such as Healthy San Francisco and Medi-Cal.

This is a unique opportunity for those with a public health, human services or community service background, or for those interested in learning this field.

A key to our success at SFHP is the support and assistance we provide to our members and the community. We work closely with our clients on a one on one basis to provide accurate and customized information so they are empowered to make the best decisions for themselves and their families. Our Enrollment Services team annually helps thousands of clients navigate complex health insurance rules, processes, and programs so they can enroll into Medi-Cal, Covered California, Healthy San Francisco, Cal Fresh and SF City Option.

The ideal candidate has a deep commitment to serving low income communities with the highest performance standards and integrity. We want an empathetic and smart listener who is detail oriented, organized, and system savvy. You will be a part of a dynamic and committed team of experienced enrollment professionals who will support you in your professional growth. You will undergo extensive training and obtain certifications in eligibility rules and application processes in a supportive environment that consistently provides learning and professional growth opportunities.

The SFHP Service Center, located at 7 Spring Street in San Francisco, is currently closed until further notice due to the COVID-19 Pandemic and all SFHP staff is working remotely. This position will work remotely using SFHP supporting technology and tools.

WHAT YOU WILL DO:
Application support and enrollment: assist members of the public with eligibility and enrollment into health coverage.
Program knowledge: maintain program expertise, training requirements, and certifications for all application assistance services offered by the SFHP Service Center, including Medi-Cal, Covered CA, and Healthy San Francisco.
Counseling and education: inform and educate about health insurance and health coverage options for clients and their families in a fair, accurate, impartial, and culturally sensitive manner.
Outreach and follow up: conduct outreach calls and schedule appointments with potential applicants and existing SFHP members and participants renewing coverage.
Community Engagement: participate in community events where we bring information about our coverage programs to the public, work towards universal coverage in San Francisco.
WHAT YOU WILL BRING:
Bachelor’s degree or equivalent experience desired
Bilingual ability in Spanish, Cantonese or Mandarin
Exemplary interpersonal and customer service skills
Strong critical thinking and analytical skills
Ability to simplify complex concepts and communicate in simple, understandable terms
Superior interviewing and communication skills with individuals and groups of diverse backgrounds
Empathy and ability to demonstrate cultural humility
Good judgment and self-awareness
Strong organization and time management abilities
Strong computer skills, including high proficiency in Microsoft Office (Excel, Word, Outlook, PowerPoint)
Experience with eligibility applications such as One-e-App, CalHEERS, or mybenefitsCalWIN is preferred but not required
WORK SCHEDULE:

Must be able to work at Monday to Friday: 8:00 AM – 5:00 PM.

ABOUT US

Established in 1994, San Francisco Health Plan (SFHP) is a an award winning, managed care health plan whose mission is to provide affordable health care coverage to the under-served low and moderate-income residents in San Francisco county. SFHP is chosen by eight out of every ten San Francisco Medi-Cal managed care enrollees and its 140,000+ members have access to a full spectrum of medical services including preventive care, specialty care, hospitalization, prescription drugs, and family planning services. SFHP was designed by and for the residents it serves, and takes great pride in its ability to accommodate a diverse population that includes young adults, seniors, and people with disabilities. SFHP also acts as a Third-Party Administrator to support the SF Department of Public Health for Healthy Kids, Healthy San Francisco and the SF City Option.

San Francisco Health Plan is an Equal Opportunity Employer (EOE) M/F/D/V

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",3.7,"San Francisco Health Plan
3.7","San Francisco, CA",-1,201 to 500 Employees,-1,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$5 to $10 million (USD),-1
25,VP of Professional Services,$50k-$128k (Glassdoor Est.),"As the leader in Lead-to-Account Matching, Routing and Marketing Attribution solutions, LeanData drives growth for business. We help many of the world’s fastest-growing enterprises automate, simplify and accelerate revenue.

We’re looking for an executive with experience building and growing a Professional Services practice in a SaaS organization; developing service offerings, managing organization and project financials, and overseeing customer negotiations and escalations.
What you'll be doing:
Build and lead a world class Professional Services organization
Own all aspects of PS strategy, hiring, implementation methodology, services P&L, and project success for our PS team
Develop the necessary KPIs and scorecard to manage the success of the business and proactively respond to data trends
Build services offerings to take our customers from a targeted value proposition to achieving value realization
Implement global partner strategies in collaboration with sales
Work with the Global Sales, Customer Success and Business Development leadership teams to adapt our services sales, product and partner strategy
Lead services sales activities, including proposal generation, SOW creation, selling PS, change orders, and client negotiations
Direct the activities of the PS team through ongoing oversight of active implementations, ensuring we deliver on time, within budget, and with high quality outcomes and customer satisfaction
Actively manage practice financials including team utilization, budget vs actual hours and project margins
Ensure the team follows best practice implementation processes and identify opportunities to improve our methodologies and tools
Act as the escalation point for project issues, work with the team to develop solutions to problems, drive customer alignment, and be accountable for project success
Requirements:
Experience building a 40+ person PS organization that scales globally
Experience recruiting and leading a high-functioning PS team
15+ years client facing software implementation and/or consulting experience, with demonstrated success managing enterprise scale SaaS projects
Experience working with Revenue Operations (Marketing Ops & Sales Ops) with an understanding of emerging trends, GTM processes and technologies
Ability to confidently interface and build trust with Director, VP and C-Level Sales and Marketing leaders in our client accounts
Strong negotiation skills with the ability to make trade-off decisions
An Achievement orientation, i.e.: experience measuring performance, improving outcomes, and setting challenging goals
Why work at LeanData
LeanData covers employee insurance premiums up to 90%
Stock options in LeanData for all full-time employees
Flexible PTO
401K plan
We warmly welcome into the LeanData family all persons without regard to ethnic and racial identity, indigenous heritage, national origin, religion, gender, gender identity, gender expression, sexual orientation, age, disability, marital status, veteran status, genetic information, or any other legally protected status.",4.1,"LeanData
4.1","Santa Clara, CA",-1,51 to 200 Employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
26,Clerical - Indio/,$50k-$128k (Glassdoor Est.),"We are a Multi-Location Psychiatric Clinic. We currently have very few patients come in to the clinic to be seen, and most have telepsychiatry or telephone appointments with the Physicians and other Clinicians. We are looking for various locations, including: Some hours in Indio & some in Yucca Valley, Training may be done in Redlands or Palm Desert. See our other job postings.

Filing Patient Private Health Information Paperwork
Assisting Patient's with Check-in If they Have to Come In to the Clinic to Be Seen
Calling Patients for appointment reminders
Insurance Verification by Phone
General Filing
General Input of Patient Information into our Electronic Medical Records Software
Answering phone calls during Business Hours",3.8,"Inland Psychiatric Medical Group
3.8","Palm Desert, CA",-1,51 to 200 Employees,1992,Private Practice / Firm,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
27,Heavy Equipment Instructor,$50k-$128k (Glassdoor Est.),"Job Description - Instructor*
General Job Description: *The Instructor is responsible, as directed by the Lead Instructor, for the safe training of all students. The Instructors should be knowledgeable on the equipment used for training as well as the curriculum. The Instructors must assure that all equipment and other operations at the training facilities are done in a safe manner.
General Qualifications: *
To be self-directed and self-motivated;
The ability to organize ones work time;
A full understanding of the school curriculum;
The ability to answer and respond to questions by the student;
The ability to solve problems for prospective students;
A full understanding of how to operate all approved equipment;
An understanding of the basic maintenance requirements for each piece of equipment.
Have a minimum of 3 years verifiable experience operating the equipment they teach.
Accountability: *The Instructor is accountable to the School Director as well as to provide a daily written accounting to the School Director.
Criteria for Compensation Increases and Advancement: *
The ability to meet performance goals;
The ability to operate the training with no injuries;
Positive work attitude including following Policies and Procedures of the College.
Acquiring additional education and training through formal education programs;
Annual reviews by the School Director.
Fully utilizing in an efficient manner the equipment provided for training.
Job Type: Full-time

Benefits:
401(k)
401(k) matching
Dental insurance
Disability insurance
Health insurance
Paid time off
Vision insurance
Schedule:
10 hour shift
Experience:
heavy equipment operator: 3 years (Preferred)
Work authorization:
United States (Required)
Working Days:
Monday (Required)
Tuesday (Required)
Wednesday (Required)
Thursday (Required)
Work Location:
One location
Labor type:
Other
Involves the operation of heavy equipment, including:
Excavators
Loaders
Dozers
Graders
This Job Is Ideal for Someone Who Is:
Dependable -- more reliable than spontaneous
People-oriented -- enjoys interacting with people and working on group projects
This Job Is:
A job for which military experienced candidates are encouraged to apply
Work Remotely:
No",-1,Heavy Equipment Colleges of America,"San Bernardino, CA",-1,51 to 200 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
28,Financial Operations Associate,$50k-$128k (Glassdoor Est.),"FINANCIAL OPERATIONS ASSOCIATE
Why Work for Ohana:
Ohana is a Hawaiian word meaning family, including extended family and all those that you care about and are there for you. This is how we think of the families we serve, as well as our own team. We are a small, close-knit team with high standards for success. We embrace a collaborative culture, where every employee is valued, has a voice, and makes a noticeable impact. Contact with all levels of personnel helps fuel our employees’ knowledge and growth.
Firm Overview:
Ohana Advisors has been serving as an investment adviser and family office services provider to a select group of ultra-high net worth families for over 25 years. We are a boutique firm that is diligent, curious, and creative with a penchant for independent thinking. Ohana helps families make informed decisions efficiently in all financial areas, including investments, estate and tax planning, next generation education, and philanthropy. We initiate, coordinate, and communicate. We are committed to supporting a long-term, multi-generational focus to build strong families.
Financial Operations Associate Job Description:
We are looking for a candidate who has a strong desire to further their career in financial operations. The ideal individual is a highly versatile and independent individual with strong communication skills and the ability to collaborate effectively. Responsibilities will include the following:
• Investment and personal account reconciliations in both our accounting and reporting software
• Account maintenance
• Account balance management
• Expense reporting preparation
• Assisting our CPA with various tax related items
• Preparation of security trade approvals and stock distribution management, including tracking of cost basis and tax lots
• Preparing various forms including new investment subscription documents, new issue questionnaires, new account forms, DTC forms, and other documents; also, obtaining client signatures and follow-up
• Preparation of letters of authorization
• Shared office tasks including weekly reports and wires
• Managing various Excel schedules including those covering insurance, mortgages, loans, cost basis, account fees, charitable giving, etc.
• Aircraft accounting
• Special projects
Qualifications:
• Bachelor’s degree in accounting or related major | minor and work experience in accounting and/or operations
• Skills in accounting software, Microsoft Excel and Word
• Familiarity with Addepar and Quicken/Quickbooks is helpful
• Highly organized individual
• Ability to work independently, approach problems logically, and apply available options to create effective communications
• Ability to work in a small team environment with an exceptional client service culture
• Ability to be versatile by taking on various types of tasks and projects while meeting deadlines
Compensation and Benefits:
• Compensation will be commensurate with the candidate’s previous roles and experience
• Ohana offers a company-funded HSA health insurance program
• Ohana also offers a 401(k) program with annual company contributions
To apply, please send a cover letter and resume to investments@ohanaadvisors.com.",-1,Ohana Advisors,"San Rafael, CA",-1,-1,-1,-1,-1,-1,-1,-1
29,Financial Operations Associate,$50k-$128k (Glassdoor Est.),"FINANCIAL OPERATIONS ASSOCIATE
Why Work for Ohana:
Ohana is a Hawaiian word meaning family, including extended family and all those that you care about and are there for you. This is how we think of the families we serve, as well as our own team. We are a small, close-knit team with high standards for success. We embrace a collaborative culture, where every employee is valued, has a voice, and makes a noticeable impact. Contact with all levels of personnel helps fuel our employees’ knowledge and growth.
Firm Overview:
Ohana Advisors has been serving as an investment adviser and family office services provider to a select group of ultra-high net worth families for over 25 years. We are a boutique firm that is diligent, curious, and creative with a penchant for independent thinking. Ohana helps families make informed decisions efficiently in all financial areas, including investments, estate and tax planning, next generation education, and philanthropy. We initiate, coordinate, and communicate. We are committed to supporting a long-term, multi-generational focus to build strong families.
Financial Operations Associate Job Description:
We are looking for a candidate who has a strong desire to further their career in financial operations. The ideal individual is a highly versatile and independent individual with strong communication skills and the ability to collaborate effectively. Responsibilities will include the following:
• Investment and personal account reconciliations in both our accounting and reporting software
• Account maintenance
• Account balance management
• Expense reporting preparation
• Assisting our CPA with various tax related items
• Preparation of security trade approvals and stock distribution management, including tracking of cost basis and tax lots
• Preparing various forms including new investment subscription documents, new issue questionnaires, new account forms, DTC forms, and other documents; also, obtaining client signatures and follow-up
• Preparation of letters of authorization
• Shared office tasks including weekly reports and wires
• Managing various Excel schedules including those covering insurance, mortgages, loans, cost basis, account fees, charitable giving, etc.
• Aircraft accounting
• Special projects
Qualifications:
• Bachelor’s degree in accounting or related major | minor and work experience in accounting and/or operations
• Skills in accounting software, Microsoft Excel and Word
• Familiarity with Addepar and Quicken/Quickbooks is helpful
• Highly organized individual
• Ability to work independently, approach problems logically, and apply available options to create effective communications
• Ability to work in a small team environment with an exceptional client service culture
• Ability to be versatile by taking on various types of tasks and projects while meeting deadlines
Compensation and Benefits:
• Compensation will be commensurate with the candidate’s previous roles and experience
• Ohana offers a company-funded HSA health insurance program
• Ohana also offers a 401(k) program with annual company contributions
To apply, please send a cover letter and resume to investments@ohanaadvisors.com.",-1,Ohana Advisors,"San Rafael, CA",-1,-1,-1,-1,-1,-1,-1,-1
30,Financial Operations Associate,$50k-$128k (Glassdoor Est.),"FINANCIAL OPERATIONS ASSOCIATE
Why Work for Ohana:
Ohana is a Hawaiian word meaning family, including extended family and all those that you care about and are there for you. This is how we think of the families we serve, as well as our own team. We are a small, close-knit team with high standards for success. We embrace a collaborative culture, where every employee is valued, has a voice, and makes a noticeable impact. Contact with all levels of personnel helps fuel our employees’ knowledge and growth.
Firm Overview:
Ohana Advisors has been serving as an investment adviser and family office services provider to a select group of ultra-high net worth families for over 25 years. We are a boutique firm that is diligent, curious, and creative with a penchant for independent thinking. Ohana helps families make informed decisions efficiently in all financial areas, including investments, estate and tax planning, next generation education, and philanthropy. We initiate, coordinate, and communicate. We are committed to supporting a long-term, multi-generational focus to build strong families.
Financial Operations Associate Job Description:
We are looking for a candidate who has a strong desire to further their career in financial operations. The ideal individual is a highly versatile and independent individual with strong communication skills and the ability to collaborate effectively. Responsibilities will include the following:
• Investment and personal account reconciliations in both our accounting and reporting software
• Account maintenance
• Account balance management
• Expense reporting preparation
• Assisting our CPA with various tax related items
• Preparation of security trade approvals and stock distribution management, including tracking of cost basis and tax lots
• Preparing various forms including new investment subscription documents, new issue questionnaires, new account forms, DTC forms, and other documents; also, obtaining client signatures and follow-up
• Preparation of letters of authorization
• Shared office tasks including weekly reports and wires
• Managing various Excel schedules including those covering insurance, mortgages, loans, cost basis, account fees, charitable giving, etc.
• Aircraft accounting
• Special projects
Qualifications:
• Bachelor’s degree in accounting or related major | minor and work experience in accounting and/or operations
• Skills in accounting software, Microsoft Excel and Word
• Familiarity with Addepar and Quicken/Quickbooks is helpful
• Highly organized individual
• Ability to work independently, approach problems logically, and apply available options to create effective communications
• Ability to work in a small team environment with an exceptional client service culture
• Ability to be versatile by taking on various types of tasks and projects while meeting deadlines
Compensation and Benefits:
• Compensation will be commensurate with the candidate’s previous roles and experience
• Ohana offers a company-funded HSA health insurance program
• Ohana also offers a 401(k) program with annual company contributions
To apply, please send a cover letter and resume to investments@ohanaadvisors.com.",-1,Ohana Advisors,"San Rafael, CA",-1,-1,-1,-1,-1,-1,-1,-1
31,Global Risk and Compliance Specialist,$50k-$128k (Glassdoor Est.),"This role will be responsible for supporting our ongoing compliance efforts (PCI DSS, GDPR, CCPA, SOC2, and FedRAMP environments), working collaboratively to manage risk within the organization, and assisting to shape the Qualys information security program through documentation and evaluation of security controls within Qualys and external 3rd part entities. You will work side by side with the information security team and others from across the organization to help ensure Qualys and our customers data in secure and meeting organizational compliance standards.
Produce weekly, monthly and quarterly uptime and status reports for production and critical internal infrastructure
Manage organizational infrastructure LDAP/RADIUS/Basic auth,
Design processes, programs and workflows,
Handle all internal/External Audits, ISP document maintenance,
Security log management & event monitoring (Splunk/IPS sourcepower),
Incident Response,
Build custom packages & key management,
VM, PKI management external/internal,
Automation of legacy/scheduled manual tasks,
Identity and Access Management.
Skillset Needed:
5-8 Years in GRC with background in ISO27001, FedRAMP, SOC2, and GDPR.
Strong user of PowerPoint, MS Project Plan, Visio, Excel.
Experience with Office365, Sharepoint and/or Confluence.
Be self-directed and self-motivated.
Ability to focus on repetitive work efforts.
Beneficial Skillset:
Qualys on Qualys, Threat Intel,
FedRAMP Continuous Monitoring background,
Detailed background in FedRAMP Moderate and High environments.
Detailed knowledge of Qualys products and scanners",3.0,"Qualys
3.0",California,-1,501 to 1000 Employees,1999,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
32,Data Engineer,$79k-$143k (Glassdoor Est.),"Company or Affiliated Company:
AHI agilon health, inc.
Location:
Anaheim
Job Title:
Data Engineer
Job Description:


Job Description

Leverage key Big Data technologies in Microsoft Azure such as Azure Data Factory, Azure Databricks, and Data Lake technologies to deliver timely and automated end user solutions. Participate and support key areas of business decision making, including but not limited to operational, clinical, and financial functions. Work closely with data analyst and data science teams to provide critical access to data that has been prepped, cleansed, and ready for analysis in a variety of tools including Power BI, SQL Server, Python, SAS, and others. The ideal candidate will have outstanding communication skills, proven data infrastructure design and implementation capabilities, strong business acumen, and an innate drive to deliver results. He/she will be a self-starter, comfortable with ambiguity and will enjoy working in a fast-paced dynamic environment.

Essential Job Functions
Design, build, and implement quality data pipelines that deliver high quality data models to agilon systems and analytics applications.
Play a key part in building and maintaining foundational data infrastructure to support data architecture and product development.
Act as a liaison and leader between business & technical resources as needed.
Partner with Data Engineers, Data architects, domain experts, data analysts, data scientists, and other teams to build foundational data sets that are trusted, well understood, and aligned with business strategy and to enable self-service analytics.
Set up and participate in source code version control with Git and Azure DevOps.
Partner with data governance bodies & product management teams to maintain a high degree of documentation and ETL transparency.
Required Qualifications
Minimum of 4 years’ experience with data warehousing methodology & data engineering tools within a health care payer or provider environment, preferably within a managed care organization.
Very strong experience with SQL, dimensional modeling, common data model (CDM) concepts, and optimizing/scaling data pipelines that support a data warehouse environment.
Excellent understanding and knowledge of relational data sources and the difference between dimensional modeling and third normal form (3NF).
Passion to work with large data sets and to solve complex & unique business problems with data engineering methods.
Experience working and mentoring junior-mid level data engineers in large scale projects.
A desire to work in a collaborative, team-based environment with both business & technical resources.
Bachelor’s in Computer Science, Information Systems, Engineering, Mathematics, or a related field.
Deep knowledge of data transformation technologies using SQL Server Integration Services (SSIS), Python, Azure Databricks, or other Big Data solutions.
Proficiency in at least one object-oriented programming language, preferably Python, Java, or Scala.
Experience working in version control environments using Azure DevOps or equivalent and Git repos to manage large scale coding projects.
Experience working with information security teams to ensure HIPAA protocols and all security standards are adhered to all times.
Experience managing a small to mid-size budget for data tools and resources.
Preferred Qualifications
2+ years’ experience with Medicare Advantage data in a global risk environment (claims, eligibility, MMR, RAPS, MOR, Capitation files) is highly desired.
Exposure to working with resources such as actuarial, healthcare/medical economics, finance and/or clinical analytics requirements is a major plus.
Experience building different data model types, including Star Schema, Common Data Model (CDM) or equivalent methodologies/techniques.",2.2,"agilon health
2.2","Anaheim, CA",-1,201 to 500 Employees,2016,Company - Private,-1,-1,Less than $1 million (USD),-1
33,Data Analyst-Process Engineer,$79k-$143k (Glassdoor Est.),"Kite is continuing to hire for all open roles. Our interview process may be conducted virtually and some roles will be asked to temporarily work from home. Over the coming weeks and months, we will be implementing a phased approach to bringing employees back to site to ensure the health and safety of our teams.

For Current Kite Pharma Employees and Contractors:


Please log onto your Internal Career Site to apply for this job

Job Description


Kite is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors. Kite is based in Santa Monica, CA. For more information on Kite, please visit www.kitepharma.com. Sign up to follow @KitePharma on Twitter at www.twitter.com/kitepharma.

We are seeking a highly motivated Process Engineer to join the Data Analytics team within PD - Global Manufacturing Sciences and Technology (GMSAT) in Santa Monica in order to support early & late stage Product Development, analytical, commercial and clinical mfg. Work cross functionally within Tech Ops including quality, research, bioinformatics and translation for PD Data Analysis. Under minimal supervision, your primary job function will be developing, maintaining, and testing infrastructure for data generation. You will be working closely with data analysts, process engineers, and scientists in order to streamline and optimize methods of storing and retrieving information. Data sources consist of Laboratory Information Management System (LIMS), Oracle E-Business Suite (Suite), Werum PAS-X Manufacturing Execution System (MES), paper batch records, and other various software common to the Cell Therapy and Biologics industries.

Responsibilities (include but are not limited to):
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Product Development, Analytical Development, Manufacturing, Regulatory, and Process Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across regions and manufacturing facilities
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications:
Bachelor’s Degree with 3+ years of experience
Master degree is preferred with no experience
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Ability to construct secure and structured databases for ease of data entry and verification, and with data integrity in mind
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 0 – 2 years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL databases
Experience with data pipeline and workflow management
Experience with AWS cloud services: Hue, Impala, etc.
Experience with object-oriented/object function scripting languages: R, Python, Java, C++, etc.
Optional: Experience in Cell Therapy/Biologics/Pharmaceuticals or in a Good Manufacturing Practices (GMP) setting are a plus
Do you want to make a real difference in the world? Come help us in our quest to cure cancer! Everyone at Kite is grounded by this common goal. Every single day, we seek to establish a direct line between that purpose and our day-to-day work. Join us in our mission!

For jobs in the United States:

As an equal opportunity employer, Gilead Sciences Inc. is committed to a diverse workforce. Employment decisions regarding recruitment and selection will be made without discrimination based on race, color, religion, national origin, gender, age, sexual orientation, physical or mental disability, genetic information or characteristic, gender identity and expression, veteran status, or other non-job related characteristics or other prohibited grounds specified in applicable federal, state and local laws. In order to ensure reasonable accommodation for individuals protected by Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veterans' Readjustment Act of 1974, and Title I of the Americans with Disabilities Act of 1990, applicants who require accommodation in the job application process may contact careers@gilead.com for assistance.

For more information about equal employment opportunity protections, please view the ‘EEO is the Law’ poster.

NOTICE: EMPLOYEE POLYGRAPH PROTECTION ACT
YOUR RIGHTS UNDER THE FAMILY AND MEDICAL LEAVE ACT
PAY TRANSPARENCY NONDISCRIMINATION PROVISION

Our environment respects individual differences and recognizes each employee as an integral member of our company. Our workforce reflects these values and celebrates the individuals who make up our growing team.

Gilead provides a work environment free of harassment and prohibited conduct. We promote and support individual differences and diversity of thoughts and opinion.

Kite is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors. Kite is based in Santa Monica, CA. For more information on Kite, please visit www.kitepharma.com. Sign up to follow @KitePharma on Twitter at www.twitter.com/kitepharma.

For jobs in the United States:


As an equal opportunity employer, Gilead Sciences Inc. is committed to a diverse workforce. Employment decisions regarding recruitment and selection will be made without discrimination based on race, color, religion, national origin, gender, age, sexual orientation, physical or mental disability, genetic information or characteristic, gender identity and expression, veteran status, or other non-job related characteristics or other prohibited grounds specified in applicable federal, state and local laws. In order to ensure reasonable accommodation for individuals protected by Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veterans' Readjustment Act of 1974, and Title I of the Americans with Disabilities Act of 1990, applicants who require accommodation in the job application process may contact careers@gilead.com for assistance.

For more information about equal employment opportunity protections, please view the ‘EEO is the Law’ poster.

NOTICE: EMPLOYEE POLYGRAPH PROTECTION ACT
YOUR RIGHTS UNDER THE FAMILY AND MEDICAL LEAVE ACT

PAY TRANSPARENCY NONDISCRIMINATION PROVISION

Our environment respects individual differences and recognizes each employee as an integral member of our company. Our workforce reflects these values and celebrates the individuals who make up our growing team.

Gilead provides a work environment free of harassment and prohibited conduct. We promote and support individual differences and diversity of thoughts and opinion.

For Current Kite Pharma Employees and Contractors:",3.7,"Kite Pharma
3.7","Santa Monica, CA",-1,1001 to 5000 Employees,2008,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10 to $25 million (USD),-1
34,Sr. Data Engineer,$79k-$143k (Glassdoor Est.),"Company Description

Wish is a mobile e-commerce platform that flips traditional shopping on its head. We connect hundreds of millions of people with the widest selection of delightful, surprising, and—most importantly—affordable products delivered directly to their doors. Each day on Wish, millions of customers in more than 160 countries around the world discover new products. For our over 1 million merchant partners, anyone with a good idea and a mobile phone can instantly tap into a global market.

We're fueled by creating unique products and experiences that give people access to a new type of commerce, where all are welcome. If you’ve been searching for a supportive environment to chase your curiosity and use data to investigate the questions that matter most to you, this is the place.

Job Description

At Wish, our Data Science & Engineering team is composed of Data Scientists, Data Analysts & Data Engineers who focus on centralizing corporate data in order to gain insights, knowledge and scalability, that empower a proactive and rigorous analysis of key business indicators. Our mission is to derive wisdom from data via the application of Data Science.

We have opportunities for talented Data Engineers to build our framework and platform to power all data applications at Wish.

#LI-WISHXDS #HiringNow

What you'll be doing:
Design and implement an efficient and scalable data engineering framework that powers the company's key data applications such as experimentation and metrics reporting.
Design and drive data architecture for future data storage, processing, and applications.
Develop and maintain critical data pipelines.
Qualifications
Minimum 2 years of work experience in data engineering related fields.
Experience and knowledge of modern data warehouse, pipeline and reporting/analytic techniques and tools such as Airflow, presto/hive, Spark.
Familiar with Python and SQL.
Bachelor's degree in Computer Science or related field.
Preferred Qualifications:
4 years of work experience in data engineering related fields.
Experience in building framework to automate and scale workflows.
Experience with data related AWS services such as EMR and S3.
Experience in building web interface and data visualization is a plus.
Additional Information

Wish values diversity and is committed to creating an inclusive work environment. We provide equal employment opportunity for all applicants and employees. We do not discriminate based on any legally-protected class or characteristic. Employment decisions are made based on qualifications, merit, and business needs. If you need assistance or accommodation due to a disability, please let your recruiter know. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.

Individuals applying for positions at Wish, including California residents, can see our privacy policy here.",3.5,"Wish
3.5","San Francisco, CA",-1,501 to 1000 Employees,2011,Company - Private,Other Retail Stores,Retail,$1 to $2 billion (USD),-1
35,"Data Engineer, Analytics (Facebook Reality Labs - Privacy)",$79k-$143k (Glassdoor Est.),"Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.On Facebook Reality Labs (FRL), we want to create a world where physical distance doesnt limit our ability to connect with one another and neither do our devices. Whether we are on the go with augmented reality, in the home or at work with Portal, or fully immersed in alternate worlds in virtual reality our friends and colleagues are always within reach in the highest fidelity afforded by our technology.

This role is in our Insights and Growth org. The Insights and Growth Org creates the foundation to help support and empower our users ability to drive growth of, and engagement with, hardware and software products.

On Facebook Reality Labs, data privacy is our top priority. Earning trust is critical to the success of the products we build, and building a strong foundation for privacy is a critical part of earning that trust. This provides you with a unique opportunity to build the AR/VR data ecosystem with Privacy first design principles from the ground up and to influence product direction with data.

In this role, you will partner closely with the Facebook Reality Labs teams that are responsible for the entire product ecosystems, to building AR/VR Privacy centric products.

You will be the subject matter expert on ensuring Data Privacy and help translate concepts to specific actions in the warehouse. On execution, work on projects to achieve privacy compliance in time for key milestones such as launch deadlines as well as managing access on the warehouse namespaceand address any privacy gaps, lay the foundation for building AR/VR products and platforms with privacy by design.

You will collaborate with data engineering across the entire Facebook family of apps to define principles that allow us to build products with a privacy first mindset at lightning speed and you will be responsible for building a strong data foundation and architecture that will allow us to understand the data privacy from end-to-end from logging to core datasets to namespace controls. In this role, you will have the opportunity to define technical specifications for logging, define and influence the right metrics and build the core datasets and visualizations that will be used by our Data Scientists, Machine Learning engineers, Product Engineers and Product Managers.

Responsibilities:

Manage data warehouse plans for a product or a group of products.
Interface with engineers, product managers and product analysts to understand data needs.
Build data expertise and own data quality for allocated areas of ownership.
Design, build and launch new data models in production.
Design, build and launch new data extraction, transformation and loading processes in production.
Support existing processes running in production.
Define and manage SLA for all data sets in allocated areas of ownership.
Work with data infrastructure to triage infra issues and drive to resolution.
Mininum Qualifications:

4+ years experience in custom ETL design, implementation and maintenance.
7+ years experience in the data warehouse space.
4+ years experience working with either a MapReduce or an MPP system.
4+ years experience with object-oriented programming languages.
7+ years experience with schema design and dimensional data modeling.
7+ years experience in writing SQL statements.
Experience analyzing data to identify deliverables, gaps and inconsistencies.
Experience managing and communicating data warehouse plans to internal clients.
Preferred Qualifications:

BS/BA in Technical Field, Computer Science or Mathematics.
Knowledge in Python or Java.
Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.

Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",4.5,"Facebook
4.5","Menlo Park, CA",-1,10000+ Employees,2004,Company - Public,Internet,Information Technology,$5 to $10 billion (USD),-1
36,Senior Data Engineer - Pipeline & Tools R&D,$79k-$143k (Glassdoor Est.),"At Rockstar Games, we create the games we would want to play ourselves.

A career at Rockstar is about being part of a team working on some of the most creatively rewarding, large-scale projects to be found in any entertainment medium. You would be welcomed to a friendly, inclusive environment where you can learn, and collaborate with some of the most talented people in the industry.

Rockstar San Diego is seeking a Senior Data Engineer to join a team focused on building a cutting-edge game analytics platform and tools to better understand our players and enhance their experience in our games. This is a full-time permanent position based out of Rockstar's unique game development studio in Carlsbad, CA.

The ideal candidate will be skilled in developing complex ingestion and transformation processes with an emphasis on reliability and performance. In collaboration with other data engineers, database administrators, and developers, the candidate will empower the team of analysts and data scientists to deliver data driven insights and applications to company stakeholders.

WHAT WE DO
The Rockstar Analytics team provide insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making.
We work together with several departments to design and implement streamed and batched data pipelines.
We collaborate as a global team to develop cutting-edge data pipelines serving data products, data models, reports, analyses, and machine learning applications.
RESPONSIBILITIES
Implement and support big data tools and frameworks such as HDFS, Hive, and Impala.
Implement and support streaming technologies such as Kafka and Spark-Streaming.
Deliver near-real time and non-near-real-time data and applications to a team of analysts and data scientists who create insights and analytics applications for our stakeholders.
Assist in the development of deployment automation and operational support strategies.
Assist in the development of a big data platform in Hadoop using pipeline technologies such as Spark, Oozie, and more to support a variety of requirements and applications.
Set the standards for warehouse and schema design in massively parallel processing engines such as Hadoop and Snowflake while collaborating with analysts and data scientist in the creation of efficient data models.
Maintain and extend our CI/CD processes and documentation.
QUALIFICATIONS
5+ years of work experience with ETL, data modeling, and business intelligence big data architectures.
5+ years of experience with the Hadoop ecosystem (Map Reduce, Spark, Spark-Streaming, Oozie, Impala, etc.) and big data ecosystems (Kafka, Cassandra, etc.).
Expert in at least one SQL language such as T-SQL or PL/SQL.
Experience developing and managing data warehouses on a terabyte or petabyte scale.
Strong experience in massively parallel processing & columnar databases.
Experience working with Real-Time, Near-Real-Time streaming pipelines.
Experience with Python and shell scripting.
Experience working in a Linux environment.
SKILLS
Deep understanding of advanced data warehousing concepts and track record of applying these concepts on the job.
Ability to manage numerous requests concurrently and strategically, prioritizing when necessary.
Good communication skills.
Dynamic team player.
A passion for technology.
PLUSES


Please note that these are desirable skills and are not required to apply for the position.
Experience with event processing frameworks.
Experience in Lambda architecture.
Experience with Java or Scala programming languages.
Experience with CI/CD.
Familiar with Restful APIs.
Experience with Artifact Repositories.
Knowledge of the video game industry.
HOW TO APPLY


Please apply with a resume and cover-letter demonstrating how you meet the skills above. If we would like to move forward with your application, a Rockstar recruiter will reach out to you to explain next steps and guide you through the process.

Rockstar is proud to be an equal opportunity employer, and we are committed to hiring, promoting, and compensating employees based on their qualifications and demonstrated ability to perform job responsibilities.

If you've got the right skills for the job, we want to hear from you. We encourage applications from all suitable candidates regardless of age, disability, gender identity, sexual orientation, religion, belief, or race.",4.1,"Rockstar Games
4.1","Carlsbad, CA",-1,1001 to 5000 Employees,1998,Subsidiary or Business Segment,Video Games,Media,$10 to $25 million (USD),-1
37,AWS Data Engineer,$79k-$143k (Glassdoor Est.),"Digital Health Technology team powers digital experiences and engagement to enhance the lives of millions of people every day through connected care. We build, deliver and manage a portfolio of data management platforms and mobile offerings in support of our core businesses. We thrive on simple and elegant architecture and agility. You’ll be immersed in a dynamic high-growth environment and empowered to excel, take informed risks, and drive ingenuity across the enterprise.

Let's talk about the team and you:

As the world-leading connected health company, leveraging big data to derive actionable insights in support of better clinical outcomes for patients and business outcomes for our partners is a critical component of our core strategy. The Advanced Analytics team is responsible for leading the way in executing on this promise. This position will partner with the data science and analyst teams to build the systems and capabilities to discover these insights and deliver them in impactful ways.

We are passionate and innovative problem solvers that support business units across the globe, providing on-going opportunities to engage with new and challenging projects. You are passionate about data and using it in meaningful ways. You have a deep understanding of a wide-variety of big data tools and technologies which you can implement to achieve desired business outcomes. You are a team player who lifts the entire team through collaboration, mentoring and sharing your experience.

As a Data Engineer within ResMed’s Data Analytics team, you are responsible for transforming and analyzing data by expanding and optimizing our data and data pipeline in AWS architecture. The Data Engineer will support our architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Reporting to the Manager of Data Engineering, you will play a key role of developing, constructing, testing and maintaining data on the AWS platform.

Let's talk about Responsibilities:
Assemble extensive, complex data that meet functional/non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing transformation for greater scalability, etc.
Use the infrastructure/services required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS services.
Create data for analytics and data scientist team members that assist them in building and optimizing our product.
Work with stakeholders, including the Product, Data, and Design teams to assist with data-related technical issues and support their data requirement needs.
Create and maintain optimal data pipeline architecture in AWS.
Keep our data separated and secure across boundaries through multiple AWS regions.
Let's talk about Qualifications and Experience:
Bachelor/Engineering degree in IT / Computer Science/ software engineering or relevant field
3+ years of relevant experience in a complex, technical environment
AWS Certified Solutions Architect - Associate/Professional level is good to have.
Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets
Excellent working knowledge on Linux
Experience working with Data Scientist
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Must have experience working on Spark/Scala, Kafka, Elasticsearch and Python (at least two)
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Experience in manipulating, processing and extracting value from large disconnected datasets.
Experience with AWS cloud services: (Redshift, RDS, EMR, Kinesis, S3, Glue, DMS-Batch/CDC, Athena, EC2, Lambda, SQS, SNS etc.)
Experience working on AWS Data Lakes
Experience working on AWS Data Pipeline and CI/CD processes
Exposure to Hadoop Ecosystem preferably on AWS/EMR, NoSQL-based, SQL-like technologies
Experience with Data Science tools & technologies on AWS Cloud is plus
Experience supporting and working with cross-functional teams in a dynamic environment.
Excellent communication and able to work with stakeholders
All listed duties, requirements and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional task and responsibilities.
#LI-NF1

Joining us is more than saying “yes” to making the world a healthier place. It’s discovering a career that’s challenging, supportive and inspiring. Where a culture driven by excellence helps you not only meet your goals, but also create new ones. We focus on creating a diverse and inclusive culture, encouraging individual expression in the workplace and thrive on the innovative ideas this generates. If this sounds like the workplace for you, apply now!",4.0,"ResMed
4.0","San Diego, CA",-1,5001 to 10000 Employees,1989,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD),-1
38,Senior Data Scientist,$79k-$143k (Glassdoor Est.),"About us:
Grand Rounds is a new kind of healthcare company. Founded in 2011, the company is on a mission to raise the standard of healthcare for everyone, everywhere. The Grand Rounds team goes above and beyond to connect and guide people to the highest quality healthcare available for themselves and their loved ones. Grand Rounds creates products and services that give people the best possible healthcare experience. Named a 2019 Best Place to Work by Glassdoor and Rock Health’s 2018 Fastest Growing Company, Grand Rounds works with inspiring employers and doctors to empower them to be the change agents we need to make our shared vision a reality.

The Role:

Data Scientists at Grand Rounds work on problems that are core to the company’s mission. Major challenges include developing systems and models to identify the highest quality Doctors in the country as well as methodologies to uncover the subtle differences between each physician’s clinical expertise. Additionally, patient-level modeling allows us to understand the specific healthcare needs of every person. With a high fidelity understanding of both patients and physicians we are able to route patients to both appropriate and high quality care. In addition to developing the company’s core technologies, data scientists provide decision support analysis for many teams across the organization including product development, sales, marketing, and strategy. Data scale ranges from small data sets that fit on a single laptop to large multi-terabyte clinical information in distributed database systems.
In your first 30 days, you will:
Onboard with the Grand Rounds team in San Francisco, setup your dev environment, get access to data systems, and become familiar with the tech stack
Learn about on-going initiatives involving Data Scientists, Product Managers, and Engineers
Spend time with members of the Analytics, Medical, and Patient Care teams and learn how our teams collaborate
Become familiar with the data landscape and hit the ground running on a primary project
In your first 60 days, you will:
Accelerate on-going development efforts around physician quality and expertise models
Master the ins and outs of claims data: ICDs, CPTs, and all that
Collaborate with engineers to improve the claims warehousing infrastructure
Collaborate with engineers to develop a process/pipeline for model updates that seamlessly flows data to production systems
In your first 90 days, you will:
Integrate into long-term multi-data-scientist ventures and deliver on one or several short-term individual projects
Develop internal tools and codebases that are useful for other Data Scientists and/or Engineers
Spend time with Staff Physicians and other medical domain experts to learn about the world of healthcare
Develop an understanding of both immediate business objectives as well as longer term company aspirations to develop intuition around prioritization and trade-offs between short-term deliverables and longer term R&D efforts
Responsibilities:
Develop creative solutions to diverse problems including engineering challenges, unstructured data messes, ontology development, and machine learning applications
Lead and develop major projects from end-to-end encompassing planning, design, technical implementation, debugging, roll-out to Product & Engineering, testing, and iteration
Operate at level of sophistication in statistics, machine learning, or computer science that is publication-worthy
Regularly monitor pull requests, perform code reviews, and produce excellent peer reviews on projects prior to shipping to Product & Engineering
Evaluate and experiment with new technologies and tools prior to wider adoption by the team
Work closely with Analysts, Data Scientists, Product Managers, and Engineers
Qualifications:
Excellent verbal communications, including the ability to clearly and concisely articulate complex concepts to both technical and non-technical collaborators
BS with 8+ years or MS with 6+ years or PhD with 3+ years of experience. Degree(s) should be in a technical discipline such as Computer Science, Engineering, Statistics, Physics, Math, quantitative social science
Work experience as an Engineer highly desired
Experience with SQL relational databases as well as big data: the Hadoop ecosystem, Hive, Spark, Presto, Vertica, Greenplum, etc
Required: SQL, Python, R, Linux, Shell scripting
Desired: Scala, Java, or Ruby
Experience with machine learning and computational statistics packages (sci-kit learn, nltk, statsmodels, networkx, gephi, arules, glmnet, bigrf, caret, igraph, MLLib, GraphX, MADlib, Weka, etc)
Experience with visualization tools (seaborn, d3, plotly, bokeh, ggplot2, rCharts, networkD3, Shiny, Tableau, CartoDB, etc)
Frequent user of cloud computing platforms such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform
Bonus Points for: experience with web application frameworks (Shiny, Flask, Tkinter, Ruby on Rails, Pyramid, Django, etc)
Double Bonus Points: previous work on medical applications and/or with claims data
-----
Grand Rounds is an Equal Opportunity Employer and considers applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics or any other basis forbidden under federal, state, or local law. Grand Rounds considers all qualified applicants in accordance with the San Francisco Fair Chance Ordinance.

Apply Now",4.3,"Grand Rounds
4.3","San Francisco, CA",-1,501 to 1000 Employees,2011,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
39,"Senior Data Engineer, Data Engineering",$79k-$143k (Glassdoor Est.),"Job Summary:
We have created a new Big Data Platforms group within Disney Direct-To-Consumer and International (DTCI) technology with the skills, drive, and passion to innovate, create, and succeed in enabling a Direct to Consumer Strategy for ESPN, Disney and ABC products. We are here to disrupt and start a cultural revolution that can lead a revolution in the application of data and analytics across The Walt Disney Company, focused on building self-serve analytics, advanced analytics using machine learning methods Deep User Understanding, Audience Segmentation for Linear to Digital Ad Sales. We need an experienced Data Engineer who drive multiple data initiatives applying innovative architecture that can scale in the cloud. We are looking for a creative and talented individual who loves to design a scalable platform which scale at peta-byte level and extract value from both structured and unstructured real-time data. Specifically, we are looking for a technology leader to build a highly scalable and extensible Big Data platform which enables collection, storage, modeling, and analysis of massive data sets from numerous channels. You must be self-driven to continuously evaluate new technologies, innovate and deliver solutions for business-critical applications with little to no oversight from management team.

The internet-scale platforms that you design and build will be a core assets in the delivering the highest quality content to over 150MM+ consumers on monthly basis. This is an opportunity to fundamentally evolve how DTCI delivers content and monetizes our audiences.
Responsibilities:

Build cool things Build scalable analytics solution, including data processing, storage, and serving large-scale data through batch and stream, analytics for both behavioral & ad revenue through digital & non-digital channels.
Harness curiosity Change the way how we think, act, and utilize our data by performing exploratory and quantitative analytics, data mining, and discovery.
Innovate and inspire Think of new ways to help make our data platform more scalable, resilient and reliable and then work across our team to put your ideas into action.
Think at scale - Lead the transformation of a peta-byte scale batch based processing platform to a near real-time streaming platform using technologies such as Apache Kafka, Cassandra, Spark and other open source frameworks.
Have pride Ensure performance isnt our weakness by implementing and refining robust data processing using Python, Java, Scala and other database technologies such as RedShift or Snowflake .
Grow with us Help us stay ahead of the curve by working closely with data architects, stream processing specialists, API developers, our DevOps team, and analysts to design systems which can scale elastically in ways which make other groups jealous.
Lead and coach Mentor other software engineers by developing re-usable frameworks. Review design and code produced by other engineers.
ML First - Provide expert level advice to data scientists, data engineers, and operations to deliver high quality analytics via machine learning and deep learning via data pipelines and APIs.
Build and Support Embrace the DevOps mentality to build, deploy and support applications in cloud with minimal help from other teams
Basic Qualifications:

Not your first rodeo Have 4+ years of experience developing data driven application using mix of languages ( Python or Scala) and open source frameworks to implement data ingest, processing, and analytics technologies.
Data and API expert You are also very handy with big data framework such as Hadoop, Apache Spark, No-SQL systems such as Cassandra or DynamoDB, Streaming technologies such as Apache Kafka; Understand reactive programming and dependency injection such as Spring to develop REST services.
Have a technology toolbox Hands on experience with newer technologies relevant to the data space such as Spark, Airflow, Apache Druid, Snowflake (or any other OLAP databases).
Cloud First - Plenty of experience with developing and deploying in a cloud native environment preferably AWS cloud.
Embrace ML Work with data scientists to operationalize machine learning models and build apps to make use of power of machine learning.
Problem solver Enjoy new and meaningful technology or business challenges which require you to think and respond quickly.
Passion and creativity Are passionate about data, technology, & creative innovation
Preferred Qualifications:

Prior experience building internet scale platforms handling Peta- byte scale data, operationalizing clusters with hundreds of compute nodes in cloud environment.
Experience in operationalizing Machine Learning workflows to scale will be a huge plus as well.
Experience with Content Personalization/Recommendation, Audience Segmentation for Linear to Digital Ad Sales, and/or Analytics
Experience with open source such as Spring, Hadoop, Spark, Kafka, Druid, Kubernetes.
Experience in working with Data Scientists to operationalize machine learning models.
Proficiency with agile development methodologies shipping features every two weeks. It would be awesome if you have a robust portfolio on Github and / or open source contributions you are proud to share
Required Education
Bachelors degree or better in Computer Science or a related technical field or equivalent job experience
Preferred Education
Masters in Computer Science or similar is preferred",4.0,"Walt Disney Company
4.0","Glendale, CA",-1,10000+ Employees,1923,Company - Public,Motion Picture Production & Distribution,Media,$10+ billion (USD),-1
40,Senior Data Engineer,$79k-$143k (Glassdoor Est.),"Uplift Pay Monthly was founded by a passionate team of travel industry veterans to make travel more accessible, affordable, and rewarding for everyone. By offering simple, flexible payments, Uplift helps travelers book early while prices are low, and pay for their trip over time. Uplift is a well-financed Series C startup serving the $1.4 Trillion consumer travel segment.

Uplift partners with top travel brands such as the vacations sites of United, American, Southwest, cruise lines such as Carnival and Norwegian, theme parks such as Universal, and many more. Learn more at www.uplift.com.


Responsibilities
Design, build and maintain data pipelines in cloud infrastructure (AWS)
Develop and maintain real time data pipelines
Build Python libraries, tools, serverless applications and workflows
Internal process improvements such as automating manual processes, building alerting/monitoring bots
Collaborate closely with product teams to build tools, frameworks, reports to run experiments, analyze A/B test results
Work with analysts and data scientists to extract actionable insights from data that shape the direction of the company
Actively engage in design and code reviews - learn from your peers and teach your peers
Lead initiatives to research, analyze and propose new technologies and tooling for our stack
Requirements
5+ years of work related experience
BA/BS degree in Engineering, CS, or equivalent, Master's degree a plus
Experience with Big Data, ETL and data modeling
Solid coder with Python and Bash
Strong SQL knowledge
Experience with cloud data warehouse (preferably Snowflake or AWS Redshift)
Familiar with BI tools (Tableau or Looker)
Familiar with Linux, AWS, and Docker
Experience in developing and operating high-volume, high-available and scalable environments
Ability to align with rapid business changes: new requirements, evolving goals and strategies and technological advancements
Entrepreneurial, persistent, with the desire to go deep in details
Comfortable working in a startup culture with the ability to earn trust
Benefits
Medical and dental insurance, vision reimbursement program
Free daily catered lunches and fully stocked kitchen
10 company paid holidays and unlimited PTO
Life insurance
401K plan
Pre-IPO stock options
Commuter benefits program
Wellness program
Pick-A-Perk program


Uplift is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Note: Uplift does not accept agency resumes. Please do not forward resumes to any recruiting alias or employee. Uplift is not responsible for any fees related to unsolicited resumes.",4.4,"Uplift Inc.
4.4","Menlo Park, CA",-1,51 to 200 Employees,2014,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
41,Data Engineer,$79k-$143k (Glassdoor Est.),"Greetings from Conch Technologies,

Â

Hope you are doing well,

Â

Please go through the below job description and apply/revert with your updated resume if you are interested. Thanks!

Â

Â

Position: Data Engineer

Location: Agoura Hills, CA

Duration: Long-Term

Â

Overview:

The Data Engineer will work with the data Analyst and project managers to determine logical and physical database designs for new analytics models. The Data Engineer will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The Data Engineer will support database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout analytics ongoing projects.

Â

Qualifications:
Moderate experience working with relational databases, query authoring (SQL) as well as
working familiarity with a variety of databases.
Moderate knowledge of AWS cloud services: EC2, EMR, RDS, Redshift
Experience with object-oriented/object function scripting languages: Python, Java, C++
Experience building and optimizing AWS data pipelines, architectures and data sets.
Strong project management and organizational skills.
Moderate skill in business intelligence tools such as Tableau or Qlik
Moderate skills with MS Office, including Excel & PowerPoint
Must be a team player with strong attention to detail and able to work independently
Proven track record at delivering timely and accurate information in a fast-paced environment
Excellent critical thinking, problem solving, and mathematical skills, and sound judgment
Strong business acumen and ability to interface with executive management
Â

Pavan Kumar | Sr IT Recruiter

E: pavan@conchtech.com | T: (571) 398 5867

Conch Technologies, Inc | www.conchtech.com

Â",4.6,"Conch Technologies, Inc
4.6","Agoura Hills, CA",-1,51 to 200 Employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD),-1
42,Software Engineer in Big Data Infra,$79k-$143k (Glassdoor Est.),"Who we are


Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 305 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom, enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.

When applying for a job you are required to create an account, if you have already created an account - click Sign In.

Creating an account will allow you to follow the progress of your applications. Our system does have some requirements that will help us process your application, below are some guidelines for creation of your account:
Provide full legal First Name/Family Name – this is important for us to ensure our future hires have the right system set up.
Please Capitalize first letter of your First and Last Name.
Please avoid using fully capitalized text for your First and/or Last Name.
NOTE: If your name is hyphenated or has multiple capitalization, please use the same format as your government ID.
Job Description Summary:

We are solving one of the most impactful problems affecting productivity of data scientist and analysts - setting up and ephemeral environments. Our solution involves creating a highly scalable and available cloud infrastructure for PayPal’s data scientists to be able to explore PayPal’s 100+PB datasets. As an engineer in this group, you would get to work on cloud technologies and solve problems around building, managing, governing, automating and monitoring elastically scalable compute infrastructure for data scientists.

Job Description:

What you will work on
As an engineer you will be building services that can help operate and scale the infrastructure
Take responsibility for services you build
Work directly with Lead engineer, Architecture, Product Managers, Program Managers and stakeholders
Work directly with Product Managers, Program Managers, Data Scientists/Customers
Mentor engineers locally and globally
Analyze platform behavior to optimize resource usage and cost
Build services to support Multi-tenant environment with 100+ PBs in Datasets.
Job requirements

Basic Qualifications:
A successful candidate will be a strong engineer who can be part of a high performance engineering team, with excellent communication skills, and an ability to deliver results in a fast paced environment.
Excellent team player and great attitude. Willingness to understand and work through global software development approaches and inherent problems it surfaces
Experience with design and development of scalable services and platforms
3+ years’ experience in one or more of the following language: Golang (big plus), Java, C++, NodeJS, python and scripting.
Knowledge and experience with cloud technologies
Preferred Qualifications:
Experience with big data technologies like Spark
Experience with GCP Big data services
Experience with DevOps methodologies and tools for automating and monitoring
If you feel that your experience matches only some of the basic qualifications, please don't hesitate and apply to this role. Let us decide if you are a good fit.

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public as

Subsidiary:

PayPal

Travel Percent:

0

Primary Location:

San Jose, California, United States of America

Additional Locations:

Austin, Bellevue, Chicago, Los Angeles, Remote California, Remote Colorado, Remote Massachusetts, Remote Tennessee, Remote Texas, Remote Wisconsin, Scottsdale

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.",3.9,"PayPal
3.9","San Jose, CA",-1,10000+ Employees,1998,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
43,"Senior Data Engineer, Data Platform Engineering",$79k-$143k (Glassdoor Est.),"Job Summary:
We have created a new Big Data Platforms group within Disney Direct-To-Consumer and International (DTCI) technology with the skills, drive, and passion to innovate, create, and succeed in enabling a Direct to Consumer Strategy for ESPN, Disney and ABC products. We are here to disrupt and start a cultural revolution that can lead a revolution in the application of data and analytics across The Walt Disney Company, focused on building self-serve analytics, advanced analytics using machine learning methods Deep User Understanding, Audience Segmentation for Linear to Digital Ad Sales. We need an experienced Data Engineer who drive multiple data initiatives applying innovative architecture that can scale in the cloud. We are looking for a creative and talented individual who loves to design a scalable platform which scale at peta-byte level and extract value from both structured and unstructured real-time data. Specifically, we are looking for a technology leader to build a highly scalable and extensible Big Data platform which enables collection, storage, modeling, and analysis of massive data sets from numerous channels. You must be self-driven to continuously evaluate new technologies, innovate and deliver solutions for business-critical applications with little to no oversight from management team.

The internet-scale platforms that you design and build will be a core assets in the delivering the highest quality content to over 150MM+ consumers on monthly basis. This is an opportunity to fundamentally evolve how DTCI delivers content and monetizes our audiences.
Responsibilities:

Build cool things Build scalable analytics solution, including data processing, storage, and serving large-scale data through batch and stream, analytics for both behavioral & ad revenue through digital & non-digital channels.
Harness curiosity Change the way how we think, act, and utilize our data by performing exploratory and quantitative analytics, data mining, and discovery.
Innovate and inspire Think of new ways to help make our data platform more scalable, resilient and reliable and then work across our team to put your ideas into action.
Think at scale - Lead the transformation of a peta-byte scale batch based processing platform to a near real-time streaming platform using technologies such as Apache Kafka, Cassandra, Spark and other open source frameworks.
Have pride Ensure performance isnt our weakness by implementing and refining robust data processing using Python, Java, Scala and other database technologies such as RedShift or Snowflake .
Grow with us Help us stay ahead of the curve by working closely with data architects, stream processing specialists, API developers, our DevOps team, and analysts to design systems which can scale elastically in ways which make other groups jealous.
Lead and coach Mentor other software engineers by developing re-usable frameworks. Review design and code produced by other engineers.
ML First - Provide expert level advice to data scientists, data engineers, and operations to deliver high quality analytics via machine learning and deep learning via data pipelines and APIs.
Build and Support Embrace the DevOps mentality to build, deploy and support applications in cloud with minimal help from other teams
Basic Qualifications:

Not your first rodeo Have 4+ years of experience developing data driven application using mix of languages (Python, Scala, and advanced SQL) and open source frameworks to implement data ingest, processing, and analytics technologies.
Data and API expert You are also very handy with big data framework such as Hadoop, Apache Spark, No-SQL systems such as Cassandra or DynamoDB, Streaming technologies such as Apache Kafka; Understand reactive programming and dependency injection such as Spring to develop REST services.
Have a technology toolbox Hands on experience with newer technologies relevant to the data space such as Spark, Airflow, Apache Druid, Snowflake (or any other OLAP databases).
Cloud First - Plenty of experience with developing and deploying in a cloud native environment preferably AWS cloud.
Embrace ML Work with data scientists to operationalize machine learning models and build apps to make use of power of machine learning.
Problem solver Enjoy new and meaningful technology or business challenges which require you to think and respond quickly.
Passion and creativity Are passionate about data, technology, & creative innovation
Preferred Qualifications:

Prior experience building internet scale platforms handling Peta- byte scale data, operationalizing clusters with hundreds of compute nodes in cloud environment.
Experience in operationalizing Machine Learning workflows to scale will be a huge plus as well.
Experience with Content Personalization/Recommendation, Audience Segmentation for Linear to Digital Ad Sales, and/or Analytics
Experience with open source such as Spring, Hadoop, Spark, Kafka, Druid, Kubernetes.
Experience in working with Data Scientists to operationalize machine learning models.
Proficiency with agile development methodologies shipping features every two weeks. It would be awesome if you have a robust portfolio on Github and / or open source contributions you are proud to share
Required Education
Bachelors degree or better in Computer Science or a related technical field or equivalent job experience
Preferred Education
Masters in Computer Science or similar is preferred",4.0,"Walt Disney Company
4.0","Glendale, CA",-1,10000+ Employees,1923,Company - Public,Motion Picture Production & Distribution,Media,$10+ billion (USD),-1
44,"AI/ML - Sr Search Data Quality Engineer, Siri Data",$79k-$143k (Glassdoor Est.),"Posted: Aug 25, 2020
Role Number:
200188042
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search.

We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to the hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Hive, Impala, Flink, Kafka, and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers.

In this role you will help to build out a data quality ecosystem that measures and tracks data quality across the stack and along the lifecycle of new products and features. You will work with data scientists and product engineers to generate the insights that drive improvements to our search products and beyond.
Key Qualifications
You have excellent written and verbal communication skills
You are self-directed and capable of operating amidst ambiguity
You have a demonstrated ability to drive highly cross-functional solutions
You are curious and you have excellent analytical and problem solving skills and great intuitions about data
You are excited about digging into massive petabyte-scale semi-structured datasets
4+ years of industry experience working with distributed data technologies (e.g. Hive, Impala, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL/HQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience applying ML to understand real-world data (classification, anomaly detection, etc.)
Experience with data visualization (SQL, Tableau)
Experience with native client development (iOS)
Description
Dealing with data quality issues: Quantifying them, diagnosing root causes, and driving to resolution
Conceptualizing, proposing, designing, building, and maintaining tools to improve data quality, from the logging through the aggregation phases of the system
Interacting with multiple teams spread across the stack to synchronize the work towards improving data quality
Analyzing data to identify signals from the billions of events we collect every day
A champion of data hygiene, building toward a strong culture of data quality and inspiring everyone to do the same
Education & Experience
Surprise us! Many will have an MS or BS in CS, Engineering, Math, Statistics, or a related field or equivalent practical experience in data science or analytics.",4.2,"Apple
4.2","Santa Clara, CA",-1,10000+ Employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),-1
45,Cyber Security Data Engineer University Grad,$79k-$143k (Glassdoor Est.),"Job description

Bigger challenges. Bolder ideas. Global impact. At Viasat, we're on a mission to deliver connections with the capacity to change the world. We're the company behind the world's fastest satellite internet service, with technology that's helping to bridge the digital divide and improve life for our customers around the globe. By providing powerful new ways for people to connect with one another, gain greater access to education, entertainment, medical research, commerce, and much more, our team is empowering millions of customers worldwide.

We're looking for passionate, innovative professionals to join our team and connect the world to more. You'll work in a collaborative and inclusive environment that values diverse perspectives and continuous learning, and provides industry-leading benefits with unmatched opportunities for career growth. Our team is fearless in pursuit of new ideas and uncompromising in our quest to become the world's first truly global Internet Service Provider. Interested in joining our mission? Take a look at career opportunities at Viasat today.

Job Responsibilities
Every day, petabytes of data from Viasat networks across the globe are collected, processed, and stored -- and our Data Platform team within ANCS makes it all happen. By leveraging modern tools such as Spark, Kafka, and Impala, we equip every employee with the power to make data driven decisions. The Viasat cybersecurity analytics group uses the latest big-data technologies (Spark, Kafka, Impala, Hadoop) to analyze petabytes of data streaming from our operational systems to develop patterns related to cybersecurity risks and intrusions. Our diverse team of developers, data engineers and data scientists create innovative solutions to gain technical and business insights that help to defend our subscribers and networks. Data Engineers serve as the backbone of the Platform team. They:
Architect real-time data processing pipelines
Work alongside business leaders, analysts, and data scientists to deliver data that drives decisions
Use technologies that bring the Internet to millions of subscribers
Utilize the latest cloud technologies to make it all happen
In this position, you will:
Design, build and own data pipelines & storage systems
Design and develop analytic tools

Requirements
Bachelor's Degree in Computer Science, Computer Engineering, Software Engineering, Electrical Engineering, Math, Physics or related technical field or equivalent practical experience
Comfortable with several programming languages, including Python, Java
Familiar with RDBMS technologies (PostgreSQL, MySQL, Oracle, etc.)
Familiar with any scripting language (Python, Ansible, Chef, Puppet, Salt, SaltStack, Ruby, BASH, etc.)
Comfortable with Linux environment and common tools
Experience dealing with transactional data from a wide variety of systems
Up to 10% travel

Preferences
Familiar or experience with Continuous Integration / Continuous Delivery (CI/CD) pipelines and tool chains (Jenkins)
Hadoop, Spark, Kafka, Impala, MapReduce or other big data technologies experience
Ansible, Docker, Kubernetes container orchestration and SecDevOps Concepts / Tools
Familiar with several languages, for example, Python, Scala, C/C++, Lua, Go, Haskell
Previous internship experience is a plus

Additional requirements

Minimum education:
BA/BS

Years of experience:
0-2 years

Travel:
Up to 10%

Citizenship:
US Citizenship Required",4.0,"Viasat
4.0","Carlsbad, CA",-1,5001 to 10000 Employees,1986,Company - Public,Telecommunications Services,Telecommunications,$1 to $2 billion (USD),-1
46,Senior Data Engineer,$79k-$143k (Glassdoor Est.),"Senior Data Engineer

Job Details
Job Location
Studio City - Studio City, CA
Education Level
4 Year Degree
Description
The Sr Data Engineer supports the DM&BI team to organize, leverage, expand, optimize and distribute Crown Media’s select data from and to different sources and destinations for internal and external vendors through the use of existing and/or introduction of new technologies with highly awareness on industry and best practices. The Sr Data Engineer will support software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

ESSENTIAL FUNCTIONS (Duties and responsibilities)
Develop high quality, reliable and fault tolerant data solutions based on internal and external customers/users’ requirements, applying best practices and new trends/technologies all along the solution lifecycle. ETL tool of preference is Pentaho Data Integration (PDI).
Integration of external data into data warehouses using REST API and web services among others.
Delivery of data to internal customers and external vendors through different data formats (CSV, Excel, XML, JSON) and delivery methods (ex. Email, SFTP, S3, etc.), including REST API.
Provide daily monitoring, management, troubleshooting and issue resolution to existing and new data solutions and systems’ interfaces affected by them.
Follow and implement Agile Best Practices for Data Warehousing.
Support the Business Intelligence team through delivery of reliable and timely data.
Qualifications
BASIC QUALIFICATIONS (The requirements that must be met to fill this position)
University degree in computer science, college diploma, technical certification, equivalent relevant academic qualifications or a minimum of 5 years of professional experience.
Proficiency as an advanced SQL Programmer/Analyst/Data Warehouse practitioner, with experience in analysis, programing, technical documentation, unit testing and training.
Proficiency with SQL DML (Data Manipulation Language) with special focus on query tuning/performance.
Experience with AWS ecosystem (Data Lake Formation, Glue, Data Pipelines, EC2, Redshift, S3, Glacier, DynamoDB, Lambda, etc.)
Background on Data Modeling and Data Warehouse design (Methodologies: Kimball, OLAP, EDW).
Proficiency with ETL programming tools (preferably Pentaho PDI), jobs and scheduling management.
Experience with reporting, visualization and dashboarding solutions using Tableau or similar.
Experience with Version Control Systems. Tool of preference is git.
OTHER QUALIFICATIONS
Experience with JSON, XML, CSV and other data formats. Experience with Python is a plus.
Experience with Project Management, SDLC & CI/CD methodologies.
Experience and ability to lead a team of Data Engineers/ETL Developers as well as work as a team-member and with minimal supervision.
Experience on NoSQL or non-relational DBMS is a plus.
Curious, self-motivated and autodidact, always keeping up to date with the latest ETL/BI tools and technologies.
Organized, meticulous and quality oriented.",3.7,"Crown Media
3.7","Studio City, CA",-1,201 to 500 Employees,1999,Company - Public,TV Broadcast & Cable Networks,Media,$100 to $500 million (USD),-1
47,"Data Engineer, NVIDIA Developer Programs",$79k-$143k (Glassdoor Est.),"The NVIDIA Developer Program connects over a million developers, researchers, and data scientists worldwide with the SDKs, training materials and resources they need to develop GPU-accelerated applications that are changing the world.

This dynamic and rapidly growing community of developers is applying their passion to develop a wide range of applications and services using the latest accelerated computing technologies. Key areas of application development include Deep Learning/AI, Autonomous Vehicles, Robotics, Design & Visualization, VR/AR, Ray Tracing, and advanced technologies changing the face of PC Gaming. NVIDIA is now looking for a data engineer to help automate the collection and management of data used to better understand how we can serve the diverse needs of our developer community. You will be implementing ETL and reporting capabilities, integrating data from multiple sources to track downloads and improve our developer programs..

In this role you will be responsible for working with a variety of product development and analytics teams to build tools for automating the delivery, tracking and reporting of software products.

What you’ll be doing:
Designing, implementing, testing and maintaining data management systems involving data collected from our content delivery networks and other sources (e.g. GitHub)
Building applications with core design principles of scalability, maintainability, security and standard coding practices
Developing and implementing formal processes for data mining, data modeling, and data production
Applying API-level security for data at-rest and in-transit over the network
Designing and implementing comprehensive error handling and fault tolerance
Developing automated test routines that perform unit, functional, and system testing
Working directly with data analysts and product marketing leads to diagnose any issues that arise in day-to-day data operations
What we need to see:
BS degree in Computer Science, or equivalent experience
4+ years of API and web services development experience
In-depth knowledge of SQL, Python, JavaScript, regular expressions, and HTML
Experience working with 3rd-party integrations
Experience in designing and building web-accessible scripting and automation tools
Familiarity with Linux repo structures and usage
Strong analytical, problem solving and interpersonal skills
Ways to stand out from the crowd:
MS degree in Computer Science or related discipline
Experience with the Drupal content management system
Working knowledge of GitHub APIs for data collection
In-depth knowledge of security standards such as OAuth 2.0, JWT tokens, two-way TLS (1.2), encryption algorithms, hashing with SHA-256, etc.
AWS Lambda, S3, and Terraform experience
Experience working with Salesforce APIs and data
Experience parsing and decoding file paths and data strings in CDN logs
NVIDIA is leading the way in groundbreaking developments in Artificial Intelligence, High-Performance Computing and Visualization! The GPU, our invention, serves as the visual cortex of modern computers and is at the heart of our products and services. Our work opens up new universes to explore, enables amazing creativity and discovery, and powers what were once science fiction inventions from artificial intelligence to autonomous cars. NVIDIA is looking for phenomenal people like you to help us accelerate the next wave of artificial intelligence!

NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",4.7,"NVIDIA
4.7","Santa Clara, CA",-1,10000+ Employees,1993,Company - Public,Computer Hardware & Software,Information Technology,$5 to $10 billion (USD),-1
48,Big Data Engineer,$79k-$143k (Glassdoor Est.),"NG - 017
Big Data Engineer

San Jose, California, USA

JOB TITLE


Big Data Engineer

Job Duties


• Complete spark and hive based ETL framework with Python/Java/Scala along with AWS services and Cloud.

• Write the Python Pyspark code for data analysis and data management and spark development for reports.

• Design AWS migration Python framework application which helps the Data engineering team data pipelines migration from On-prem to AWS cloud.

• Translate business requirements into flow charts and user stories as a baseline for development for Data pipelines with automation tools to eliminate human error and speed up production processes.

• Write SQL and NoSQL queries for different data requirements.

• Participate in designing and develop pipelines from different type resources.

• Deploy AWS EMR cluster and create data for reports using Spark and Hive.

• Write CloudFormation scripts to provision different AWS resources.

• Manage the AWS EMR clusters to complete data generation.

• Analyze data and create data pipeline for data modeling and data quality.

• Contribute and implement the continuous integration and continuous delivery pipeline

• Ensure data availability, data quality and data modeling smooth process.

• Act to find out the root cause of any issues, while generating the data using spark and Hadoop eco system components with AWS services and cloud services.

• Implement data management using Redshift, HBase, Kafka, spark, hive and sqoop.

• Create reports using AWS Glue, AWS Athena, Hadoop, Spark, AWS EMR, Hive and Databricks Platform.

• Ability to communicate with data analysts, Data scientists and Clients requirements for Data, to deliver the data from data pipelines. Taking proactive identification & resolve the incidents in data delivery process.

• Review Design, code changes, test scenarios and test results to onboard the migration changes.

Job Requirements


Required Bachelors or foreign equivalent in CS, CA, CIS, IT, MIS, Engineering (Any), or any related field. Must be able to travel/relocate to various client sites throughout the U.S.

Location of Work


San Jose, CA.

To apply please send resumes to NextGen Technologies Inc., 1735 N 1st ST. Ste#308, San Jose, CA 95112 or email resumes to kushal@nextgentechnologiesinc.com.",4.2,"Nextgen Technologies
4.2","San Jose, CA",-1,51 to 200 Employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
49,Senior Software Engineer - Data Platform,$79k-$143k (Glassdoor Est.),"Our mission at Udemy is to improve lives through learning. Today, more than 40 million students around the world are advancing their careers and passions by mastering new skills on Udemy.

The Data Platform team’s mission is to build the tools, services and infrastructure that empower data scientists, analysts and engineers to use data effectively and to achieve our overall mission. As a senior member of the team, you will be responsible for a variety of software development projects ranging from scaling the data infrastructure to setting up new internal data services/products to building and expanding frameworks that enable others to more easily develop data pipelines.
Here’s what you’ll be doing:
Design, build and manage a scalable and robust data platform and infrastructure
Collaborate with data scientists and engineers to solve complex data problems at scale
Identify and evaluate new technologies that improve performance, maintainability and elegance of our infrastructure
Serve as a technical lead for various projects/tasks as needed
Mentor engineers, both junior and senior
Contribute to a team culture that values inclusiveness and quality while fostering innovation
We’re excited about you because you have:
5+ years of full-time experience working in data engineering, data infrastructure, or equivalent
Solid software engineering skills and proficiency with object-oriented or functional programming languages, such as Python, Scala, Java, etc
Experience with data processing frameworks and tools, such as Spark, Hadoop, Hive, Kafka, etc
Experience with infrastructure as code tools such as Terraform, Ansible and Packer
Experience in developing end-to-end data pipelines
#LI-MC1

About Udemy
We believe anyone can build the life they imagine through online learning. Today, more than 50 million students around the world are advancing their careers and passions by exploring and mastering new skills on Udemy, and expert instructors are able to share their knowledge with the world. Through our global marketplace and our solutions for businesses and governments, we connect people everywhere with the skills they need for success in work and life. We’re a close-knit bunch that enjoys problem-solving and collaboration, and we share a serious belief in the power of learning and teaching to change lives. Udemy’s culture encourages innovation, creativity, passion, and teamwork. We also celebrate our milestones and support each other every day.

Founded in 2010, Udemy is privately owned and headquartered in San Francisco’s SOMA neighborhood with offices in Denver (Colorado), Dublin (Ireland), Ankara (Turkey), Gurugram (India), and São Paulo (Brazil).

Udemy in the News
Udemy Raises 50 Million at a 2 Billion Dollar Valuation from Japanese Publisher Benesse
Paid Paternity Leave Should be the Norm in the U.S.
Breakdown of Most In-Demand Skills for 2020—Finance, Marketing, Sales and Engineering
How Investing in Yourself Today Will Set You Up for Career Success Tomorrow
Feedback Isn’t the Problem, but the Way That We Deliver It Is Broken",4.4,"Udemy
4.4","Mountain View, CA",-1,501 to 1000 Employees,2010,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
50,"AI/ML - Sr Search Data Engineer, Siri Data",$79k-$143k (Glassdoor Est.),"Posted: Aug 25, 2020
Role Number:
200188040
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search.

We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers.

In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
Key Qualifications
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
4+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) building efficient extraction and transformation pipelines at scale
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth attitude
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Description
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day
Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning
Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products
Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access to datasets, etc)
Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction.
Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions
Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration)
Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
Education & Experience
Surprise us! Many will have an MS or BS in CS, Engineering, Math, Statistics, or a related field or equivalent practical experience in data engineering.",4.2,"Apple
4.2","Santa Clara, CA",-1,10000+ Employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),-1
51,Senior Data Engineer,$79k-$143k (Glassdoor Est.),"Who we are


Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 305 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom, enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.

When applying for a job you are required to create an account, if you have already created an account - click Sign In.

Creating an account will allow you to follow the progress of your applications. Our system does have some requirements that will help us process your application, below are some guidelines for creation of your account:
Provide full legal First Name/Family Name – this is important for us to ensure our future hires have the right system set up.
Please Capitalize first letter of your First and Last Name.
Please avoid using fully capitalized text for your First and/or Last Name.
NOTE: If your name is hyphenated or has multiple capitalization, please use the same format as your government ID.
Job Description Summary:

PayPal has a real opportunity to make a difference in the financial lives of millions of people across the globe. At PayPal, we are reinventing how the world making payments. We connect people to send and receive money with the confidence of the security PayPal enables.

The Decision & Analytics Management organization in Paypal is responsible for risk and customer service decision management. We are looking for a data engineer with passion in payment industry to develop data and provide data-driven solutions/products to improve decision management. Facing the complex big data challenges or problems in fraud management, understanding the enormous and heterogeneous data deeply is essential in developing a multi-latency data processes and solutions to derive system and business insights with high ATB, SLA, and short TTM.

Job Description:

Key Responsibilities
Collaborate with x-functional teams to translate business challenges into data science problems, transform data into analytical data assets, data products and actionable intelligence for faster decision making on one of the largest data platforms in the world. Responsible for requirement gathering, data model design, data ETL process design, data product development and maintenance.
Supports PayPal business units by providing data in a ready-to-use form to data analysts, data scientists and engineers for system/business insights, predictive analytics, machine learning, etc. Influence data instrumentation based on business requirement understanding.
Owns and is accountable for the design and development of a data solution feature or a data pipeline with high reliability, stability, scalability, and performance.
Design or develop data model and enrich the analytical data sources for further usability and availability by adopting advanced & cutting-edge technology.
Establish comprehensive monitoring framework, proactively identifies, investigates, and resolves data issues and challenges. Skilled in identifying root causes and providing solutions.
Communicates effectively, able to connect complex technical concepts/information and business requirements/implications.
Basic Qualifications
BS, MS or equivalent degree in Mathematics, Statistics, Computer Science and Engineering.
Good understanding of Data Modelling Concepts; experienced with modelling data and metadata in relational & non-relational database.
Strong data analytics background, good at transform business knowledge into analytical data assets; experience with data ETL, data warehouse/data mart building is a big plus.
3+ years’ experience in data engineering, software engineering or data science.
Strong data processing skill, High proficiency in several fundamental technical skills such as SQL, Python, PIG, Hive; Experience with Teradata or big data systems such as Hadoop, Spark. Experience in developing data processing tasks using pySpark such as reading data from sources in different format, merging data with complex conditions, performing data enrichment/transformations.
Proficient in Unix scripting; batch processing
Experienced with report analysis and development using business intelligence tools such as Tableau. Able to pick up new programming skills quickly.
Experience / knowledge in Machine Learning is a plus.
Strong interpersonal skills and capability to work successfully in a collaborative environment
Quick-thinker, fast learner, wide general knowledge, problem solver
Team worker, responsible, delivery-oriented
Flexibility to work early or late hours with teams in different time zone.
Subsidiary:

PayPal

Travel Percent:

5

Primary Location:

San Jose, California, United States of America

Additional Locations:

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.",3.9,"PayPal
3.9","San Jose, CA",-1,10000+ Employees,1998,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
52,"Senior Business Intelligence Data Engineer, Cash App",$79k-$143k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",4.0,"Square
4.0","San Francisco, CA",-1,1001 to 5000 Employees,2009,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
53,Senior Data Engineer,$79k-$143k (Glassdoor Est.),"The Company:

Personal Capital is a leading digital wealth management company, founded in 2009. Were on a mission to transform financial lives through technology and people, providing both insight-driven advice with free financial tools and personalized wealth management from 200+ registered financial advisors across the country. Personal Capital has raised $315 million in capital from accomplished financial and strategic investors (IVP, Venrock, Crosslink, Corsair, Blackrock, BBVA, USAA, IGM/Power) to disrupt the traditional $30 trillion U.S. wealth management market. Our free personal finance app is utilized by over two million users, helping them track over $840 billion of their personal finances, all in one place. Our award-winning apps paved the way for our advisory firm, which now manages over $12 billion in personalized investment portfolios for American families. Personal Capital is headquartered in Redwood Shores with offices in San Francisco, Denver, Dallas and Atlanta.

The Opportunity

You will play a leading role on the Data and Analytics team, responsible for transforming data from disparate systems to provide insights and analytics for business stakeholders. Youll leverage cloud-based infrastructure to implement technology solutions that are scalable, resilient, and efficient. You will collaborate with Data Engineers, Data Analysts, Data Scientists, DBAs, cross-functional teams, and business leaders. You will architect, design, implement and operate data engineering solutions, using Agile methodology, that empower users to make informed business decisions.

Candidate

You are self-motivated, work independently, and have direct experience with all aspects of the software development lifecycle, from design to deployment. You have a deep understanding of the full life data lifecycle and the role that high-quality data plays across applications, machine learning, business analytics, and reporting, Strong candidates will exhibit solid critical thinking skills, the ability to synthesize complex problems, and a talent for transforming data to create solutions that add value to a myriad of business requirements. You have the demonstrated ability to lead and take ownership of assigned technical projects in a fast-paced environment. Excellent written and speaking communication skills are required as we work in a collaborative cross-functional environment and interact with the full spectrum of business divisions.

Qualifications:
Bachelor of Science degree in Computer Science or equivalent.
At least 7 years of post-degree professional experience.
4+ years development experience building and maintaining ETL pipelines.
3+ years of Python development experience.
Experience with AWS integrations such as Kinesis, Firehose, Aurora Unload, Redshift, Spectrum, Elastic Mapreduce, SageMaker and Lambda.
Experience in mentoring junior team members through code reviews and recommend adherence to best practices.
Deep understanding of writing test cases to ensure data quality, reliability and high level of confidence.
Track record of advancing new technologies to improve data quality and reliabilit
Continuously improve quality, efficiency, and scalability of data pipelines.
Expert skills working with SQL queries, including performance tuning, utilizing indexes, and materialized views to improve query performance.
Advanced knowledge of both OLTP and OLAP environments with successful implementation of efficient design concepts.
Proficiency with the design and execution of NoSQL database to optimize BigData storage and retrieval.
Experience with API code integrations with external vendors to push/pull data between organizations.
Familiarity with data orchestration pipeline using Argo or Airflow.
Knowledge of analytic tools such as R, Tableau, Plotly, Python Pandas.
Financial services industry experience is a plus.
Powered by JazzHR",3.9,"Personal Capital
3.9","Redwood City, CA",-1,201 to 500 Employees,2009,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
54,Scientific Data Manager and Analyst,$79k-$143k (Glassdoor Est.),"It's a Perfect Day to change the world! At Perfect Day, we're doing just that.

Perfect Day was founded in 2014 to create delicious, nutritious dairy products that everyone can love. We’re using fermentation (not animals) to make dairy proteins that are the foundation for foods like ice cream, cheese and yogurt – all with the distinctive taste and textures that consumers demand, but without lactose or environmental downsides. Through partnerships with respected brands, we’re working to launch a whole range of dairy products that will help shape a humane, sustainable food system for future generations.

We seek to fill a cross-functional data management role which will empower multiple teams through data organization, sharing, and analysis. The company has both R&D and commercial manufacturing operations in the animal-free diary protein space. The Data Science & Engineering department at Perfect Day is currently looking for an enthusiastic Data Management Engineer to join the team. This role will fill the substantial need to structure disparate data streams, link functional teams via data sharing, and generally derive organization value through data integration. The ideal candidate will be comfortable working with scientists and engineers in cross-functional projects with the goal of make their data findable, accessible, interoperable and reusable (FAIR). This may be an opportunity to learn new areas or apply your considerable domain-specific knowledge and skills in a more senior role. Initial work might be as liaison to the food science, downstream processing, and/or fermentation teams.
YOUR CONTRIBUTIONS
Drive and implement structuring and ingestion of new and existing data sources in cooperation with disparate functional teams on various R&D departments
Interface with DevOps engineers, data engineers and application developers to continuously improve data infrastructure and data analysis and ETL pipelines
Advise functional team members on value extraction from data via integration and analysis, liaise with data scientists
REQUIREMENTS
Data Modeling: ability to translate complex/messy data types and streams into storable, linkable, and interpretable datasets
Project Management: ability to influence and motivate individuals across teams to achieve data-centric goals
Analysis: basic abilities in data munging, statistics, and/or machine learning
Science/Engineering Background: ability to understand/learn and link biological, operations, and process engineering concepts
DESIRED SKILLS AND EXPERIENCE
Knowledge of one or more of the following disciplines: food science, protein biochemistry, microbial strain engineering, fermentation, process engineering and other disciplines related to our animal-free diary business and data types
Demonstrated experience in a similar or related role
Experience maintaining or creating a knowledge base for a similar organization
Basic SQL skills, basic pandas/R data munging experience
Familiarity with advantages/disadvantages of various database flavors
Experience working in or managing software development: JIRA, git, python, javascript, AWS, software testing, documentation
Statistics and Machine Learning Skills: basic tests, model training concepts, power analysis, model interpretation, Bayesian Inference
Image processing and storage
Natural Language Processing and applications



It's a Perfect Day to change the world. The day when delicious dairy goodness is something everyone can love. The day we say goodbye to the downsides of factory farming. The day we throw a big party with luscious, animal-free milk, cheese, yogurt, and ice cream, all made with Perfect Day! We hope you join us!",4.7,"Perfect Day
4.7","Emeryville, CA",-1,51 to 200 Employees,2014,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
55,Lead Data Scientist,$79k-$143k (Glassdoor Est.),"Our mission is to make the best mental health tools radically accessible for everyone.

We are pioneers in building personalized digital mental health tools to help millions of people with mental health difficulties. We are building a suite of regulated, prescription only digital therapeutics as well as a sophisticated delivery platform capable of responding to the lived experience of our users.

Our tools are powered by the latest research in NLP and ML, use scientifically proven techniques from Cognitive Behavior Therapy, and are based on 10 years of intervention science at Stanford University. Our founder has an international reputation in Digital Mental Health intervention development. And our Chairman is Andrew Ng; and Dan Jurafsky is a member of our advisory board, both globally recognized leaders in AI/NLP.

There has never been a better time to use your data science skills for good. Given the recent acceleration in infrastructure to allow for the meaningful adoption of DTx, our strong product reputation and existing relationships within health systems, Woebot is in a period of explosive growth. We are looking for a product-minded data scientist to continue to create value for our users, customers, and execute on our IP strategy.

What you will do:

As a leader in the Product team, you will work cross-departmentally with clinical and engineering team members to build machine learning and AI algorithms that are the core of Woebot's intelligence. There are four areas we want you to own and drive:

Drive An Insights & Analytics Culture
You will help create data analysis and analytics pipelines that improve not only the underlying ML algorithms but also the product and the user's experience.
You will lead a team of Analysts and be responsible for good data driven hygiene, including the creation, redesign, and maintenance of analytics dashboards and BI tools such as BigQuery, Google Data Studio, or Tableau.
You will also advise on data labeling strategy so that Woebot's conversational engine is continuously improved and informs changes in features, content, and UX.
Improve User Personalization:
Woebot exchanges 4.7 M messages with our users every week. You will create & lead a data-driven personalization strategy for this audience.
We consider personalization to be key for developing a relationship over time while delivering precision interventions, that is; the right method to the right person at the right time.
Contribute To Evidence:
In the next 6 months, you'll help Woebot develop evidence & trends to demonstrate the value of our highest priority products.
You're helping answer the most pressing questions in the mental health field around engagement, dose, and treatment outcomes.
In partnership with our Clinical team and academic partners, we expect you to contribute to our pipeline of peer-reviewed published research.
In addition to some platform-related pieces, you will lead publication in Data Science and HCI research.
What Your First 90 Days Could Look Like
By Day 30 - Assess the lay of the landscape & team - and make suggestions around in house analytic tools, dashboard and strategies.
By Day 60 - understand the roadmap with our founder and reverse engineer our tailored interventions. Deliver a prioritized list of roadmap items.
By Day 90 - Submit your first publication. Execute on a plan for improving user outcomes with our analytics and ML.
Role Specific Competencies:
PhD in Data Analysis or ML/AI or computational field with 8-10+ years of applied experience
Knowledge of one or more modern ML/NLP frameworks, such as PyTorch, Tensorflow, or Keras
Track Record of publishing in peer reviewed academic literature
You've led and managed other analysts and data scientists.
Strong written and verbal communication skills
What you will add to our culture:
Strong work-ethic: Works hard to get a job done.
Proactive & flexible: Able to hit the ground running, takes responsibility for finding a way to get the job done.
Empathic: Place a high value on user-experience, are a team player motivated to help others be successful.
High standards: Applies high standards toward everything.
Humble: You want to learn and grow in the role, and are open to feedback on how to do that.
What we offer:
Competitive Salary
Stock Options
Flexible PTO
Health, Dental & Vision
Healthy Snacks & Meals
Woebot is an equal opportunity employer and we deeply value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.1,"Woebot Health
4.1","San Francisco, CA",-1,1 to 50 Employees,2017,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
56,Senior Data Engineer,$79k-$143k (Glassdoor Est.),"Handshake is the number one site for college students to find a job. Today, the Handshake community includes 17 million students and young alumni at over 1,000 colleges and universities — including 120+ minority-serving institutions. We connect up-and-coming talent across all 50 states with nearly 500,000 employers recruiting on Handshake — from every Fortune 500 company to thousands of small businesses, nonprofits, startups, and more. Handshake is democratizing opportunity and ensuring college students have the support they need to find a great job and kick-off a meaningful career regardless of where they go to school, what they choose as a major, and who they know.

We welcome all people. We celebrate diversity of all kinds and are committed to creating an inclusive culture built on a foundation of respect for all individuals. We seek to hire, develop and retain talented people from all backgrounds. Individuals from non-traditional backgrounds, historically marginalized or underrepresented groups strongly encouraged to apply.

If you are not sure that you’re 100% qualified, but up for the challenge - we want you to apply.

What does a Senior Data Engineer do at Handshake?

Handshake is building a diverse team of dynamic engineers who value creating a high quality, high impact product. You will use your technical knowledge to drive the architecture, implementation and evolution of the data platform we are current developing. You will also be working with product teams helping millions of students find meaningful careers regardless of where they go to school, who their parents know, or how much money they have.

Here are some projects we're excited for you to work on


We're focused on building a data platform that will ensure all teams are capable of creating data-driven features, and all sides of the business have access to the right data to make the correct decisions. Your job may include:
Working closely with product managers and product engineers to ship data-driven features
Closely interact with data scientists and analysts to build pipelines and warehousing solutions
Translate business requirements into data models that are easy to understand and used by different disciplines across the company
Design, implement and build pipelines that deliver data with measurable quality under the SLA
Partner with our infrastructure team to build core data infrastructure
What we look for
You prefer taking projects from inception to completion and are outcome oriented.
You have a consistent track record of designing and implementing scalable, robust data pipelines, data services and data products.
You have experience working with tracking systems, click streams and session analytics.
You are proud of your craft, and enjoy and value clean code that scales to keep large teams productive.
You have experience providing technical leadership and mentoring other engineers for best practices on data engineering.
You have the ability to navigate between big-picture and implementation details.
You have 5+ years of relevant experience.
Technologies you'll work with
Big Data warehouses and processing frameworks such as Spark, Snowflake, BigQuery, Presto,...
Analytics framework such as Segment
Cloud infrastructure such as AWS and GCP
Benefits
Stock: Ownership in a fast-growing company.
401k: We care about your ability to save for your future.
Family Focus: Parental leave and flexibility for families.
Time Off: Flexible vacation policy to encourage people to get out and see the world.
Healthcare: World-class medical, dental, and vision policies.
Goodies: Whatever hardware and software you need to get the job done.
Team Fun: Regularly scheduled events, sports, game nights, book clubs.
Learning: Learning & Development opportunities for you to grow your skills and career.
Great team: Working with fun, hardworking, nice people who are committed to making a difference!
...And much more!

We value diversity of all kinds, and are committed to building a diverse and inclusive workplace where we learn from each other. We are an equal opportunity employer and welcome people of all different backgrounds, experiences, abilities, and perspectives.",4.2,"Handshake
4.2","San Francisco, CA",-1,51 to 200 Employees,2014,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
57,Principal Data Engineer,$79k-$143k (Glassdoor Est.),"Primary Location: 195 Technology Dr, Irvine, CA, USA

Division: Cox Automotive

Job Level: Individual Contributor

Travel: No

Schedule: Full-time

Shift: Day Job

Requisition Number: 205877
ThePrincipal Data Engineer role is part of the Analytics team at Cox Automotive Retail Consumer Solutions and is responsible for creating and maintaining very high-quality business critical datasets enabling Analytics teams and other peer team within the Cox Automotive Retail Consumer Solutions to perform and scale their work.

This position reports to Director, Data Science Advertising Ops and interacts with a variety of other internal teams (e.g., Data Science/Data Analysts, Data Foundations, Data Visualization, Marketing Technology and Ad Ops) to represent Analytics needs (e.g., proper tagging, ingestion/integration of key data sources, etc.) to ensure that downstream analytics and insights generation processes are enabled.

Responsibilities:
Responsible for creating and maintaining very high-quality business critical datasets in Snowflake that the analytics specialists can query for their analysis.
Designs, develops and maintains reliable automated data solutions based on the identification, collection and evaluation of business requirements. Including but not limited to data models, database objects, stored procedures and views.
Builds tools that help data scientists and analysts work more efficiently
Develops new and enhances existing data processing post the initial Data Ingestion & Basic ETL Phases (Data Transformation, Data Store, Data Management, Data Quality) components
Creates and maintains analysis and dashboard friendly tables providing data pipelining as a service to enable other analytics professionals and stakeholders in the company.
Creates advanced SQL queries and ensures they are optimized for speed, efficiency and scale
Provides development and oversite of data modeling and data mining
Performs data cleansing and linking across multiple disparate data sources
Establishes a process for delivery of data and key metrics to the analytics team
Maintains an awareness of trends in the field; research and suggest new methodologies to support efficiency and scale.
Collaborates with Data Foundations team Data Engineers on infrastructure projects, advocating for database architecture that supports the Analytics function
Coaches analysts on data engineering best practices
Other duties as needed or required
Qualifications:

Bachelors Degree (B.S) or Masters Degree (preferred) in either Information Systems, Computer Science oran equivalent combination of education and work-related experience.
10+ years of related analytics data engineering experience.
2+ years with digital marketing & web analytics data sources
Strong problem-solving skills with an emphasis on scaling Analytic Operations.
Ability to create and store JavaScript functions in Snowflake
Expert SQL experience is required
Data wrangling and employing a variety of Big Data tools to improve data reliability and quality
Experience working in Snowflake or Apache Hadoop & Impala is strongly preferred
Intermediate knowledge and experience with business intelligence & data visualization systems (e.g. Microstrategy, Microsoft Power BI, Google Data Studio and/or Tableau)
Knowledge of web / digital analysis and related software preferred (e.g., Adobe Analytics / Omniture and Google Analytics)
Strong communication skills, including experience in clearly and effectively presenting to internal stakeholders.
A drive to learn and master new technologies and techniques.
Ability to consult and influence as a Subject Matter Expert for the best outcomes to drive broad business successes.
Ability to anticipate stakeholders needs and recognize the opportunity to provide proactive insights to build tight thought partnership
Strong organizational skills and the ability to effectively multi-task and prioritize in a deadline-driven atmosphere
Experience successfully collaborating on complex analytics projects involving a matrix of cross-functional teams
Requires physical ability and mental acuity to execute the duties of the position successfully within required timeframes in order to meet business requirements.
Core Competencies Critical to Success in this Role:
Drive for results
Focus on customers
Build relationships
Organizational Position:

Does this position have direct reports? NO YES If Yes, estimated #

Reports to: Supervisor Manager Director/AVP level VP or above

Who We Are

About Cox Automotive

There’s nothing ordinary about Cox Automotive. We are people of every background driven by our passion for mobility, innovation, client success and community outreach. We make buying, selling and owning (or simply using) cars easier for everyone. Touching more than 40,000 clients across five continents, we bring together the best brands and the best teams to propel the automotive industry forward. Some of those team members work for our iconic consumer brands like Autotrader and Kelley Blue Book, while others are creating the future of automotive at industry-facing brands like Dealer.com, Manheim and vAuto.

About Cox

We are the Cox family of businesses. We’ve been making our mark since 1898 by building and evolving world-class businesses, staying true to our values, and encouraging top talent to always look for growth and impact while building a career with us. Our primary divisions – Cox Communications and Cox Automotive – are driving a new wave of innovation, powering smart cities with powerhouse broadband communications and pioneering greener, more progressive transportation alternatives for individuals and fleet operators. We’re also expanding into new spaces like cleantech and healthcare to rev up our momentum toward building a better future for the next generation. We’re looking for the talent today who will be our leaders tomorrow. Sound intriguing? Learn more about where we are today, where we hope you’ll be going with us, and the common purpose that unites us at coxenterprises.com.

Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual’s age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.",3.6,"Cox Automotive
3.6","Irvine, CA",-1,10000+ Employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
58,Sr. Data Engineer,$79k-$143k (Glassdoor Est.),"Job Summary:

As part of the Factory of the Future analytics team, the Sr. Data Engineer will support development of the analytics platform for Global Quality and Operations (GQO) that include design, development and maintenance of data assets , leveraging various enterprise and transactional systems data. GQO is the largest department in Illumina, encompassing manufacturing, product development, operations, quality, supply chain and other functions.

Responsibilities:
Create, construct, test and maintain data architectures integrating the various data sources servicing GQO. This will include enterprise level systems (SAP, Salesforce) and manufacturing transactional systems such as LIMS and MES.
The role will require working directly with the business owner(s) to aid in requirement setting of client’s issues. It will involve integrating different operational enterprise data sources into a wholistic architecture to enable insights into cost, yield, root cause analysis and other operational metrics.
The role is focused on providing the foundational data and data services for a variety of teams within GQO. You will need to be able to maintain queries and views for the above, with the ability to design and build efficient and effective solutions to very complex query and analytical scenarios. You will work closely with stakeholders, SMEs and analysts to create and refine the requirements and ensure the deliverables match their expectations.
The role will involve integrating different operational enterprise solutions into a wholistic architecture to unlock and enable data analysts and data scientists to drive to opportunistic insights into cost and impact of poor quality, supply chain, manufacturing issues, root cause analysis of customer complaints and other key metrics for management reporting.
You will have opportunities to recommend and assist in data acquisition, data quality and reliability improvements and other areas to improve not only the data but the business processes / systems generating the data.
Extremely detail oriented person with strong organization skills to manage multiple projects and ability to effectively to work across the organization and interpret needs into a solution.
Collaboration across the organization will be essential and ability to clearly communicate up to executive team is required. Excellent analytical, problem solving skills, combined with strong business judgment, and an ability to present your solution(s) in a clear and compelling manner.
Requirements:
7+ years of enterprise data experience using standard platforms that include SQL Server, Postgres, Hana and Denodo.
Expert level proficiency in data modeling, SQL query solution design and coding, query optimization and performance tuning, and Denodo view development.
Strong ETL Tools expertise (Informatica, SQL Server Integration Services).
Experience with large, complex relational data models and very large data sets (billions of rows).
Expert level proficiency in database architecture and design.
Demonstrated ability to work with ambiguous requirements, adapt, and learn
Must be able to work independently or as part of a larger group.
High degree of initiative and ownership, as well as a proven history of delivering results while working with several different departments in a fast-paced environment.
Education:
Minimum of a BS degree in Computer Science, Information Architecture, System Integration or equivalent degree or equivalent job experience, with a MS Preferred.
Illumina believes that everyone has the ability to make an impact, and we are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf",3.9,"Illumina
3.9","San Diego, CA",-1,5001 to 10000 Employees,1998,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD),-1
59,Senior Software Engineer: Data Engineering,$79k-$143k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.
Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for Data Analytics at Joby Aviation in support of design, test and flight operations. You should be able to work cohesively inside of a team, understand large data analytics systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on our Analytics platforms. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.

The successful candidate will assist in architecting, designing, and implementing systems to:
Design, deploy, and support leading edge technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Develop common code in support of Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Analytics infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of scalable data analytics architectures, including event streaming -- specific experience with Kafka considered a strong plus.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Databricks and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
60,Senior Data Engineer,$79k-$143k (Glassdoor Est.),"About Us

Kiva (kiva.org) is an international nonprofit with a mission to expand financial access to help underserved communities thrive. We run a global marketplace platform to crowdfund microloans for financially excluded entrepreneurs, farmers and students around the world. Our organization combines the culture and technological passion of an internet start-up with the compassion and empathy of a non-profit to create impact and opportunity at global scale. Since 2005, we have raised more than $1.4 billion in loan capital for 3.6 million borrowers in 95 countries. Our lenders fund over $13 million in loans every month. With offices in San Francisco, Portland, New York, Nairobi, and Bangkok, Kiva's team includes 100+ employees and 400+ volunteers worldwide. Our team is growing as we pursue exciting new opportunities to create a financially inclusive world.

About Data Science @Kiva

The Data Science team at Kiva creates impact by using data to solve problems around financial inclusion. This translates to a host of exciting and challenging technical problems spanning analytics, machine learning, data engineering, and infrastructure. The team is currently building out a new analytics stack, algorithms to power personalization on kiva.org, and is looking to scale analytics & data science for other kinds of problems. Our current ecosystem of infrastructure, tools, and skillsets include AWS, GCP, Kubernetes, Snowflake, Fivetran, Looker, DBT, Google Cloud Composer (Airflow), Snowplow, Python, Kotlin, and PHP.

About the Role

The team is looking for a strong engineer to help architect, design, build, maintain, and evolve our analytics platform. This is an opportunity to be an early influencer and a significant contributor to the direction and growth of the team. As a Senior Data Engineer, you will:
Own an analytics platform that will influence the experience of millions of lenders and borrowers around the world.
Work with internal stakeholders to identify their analytics needs, and drive the analytics engineering roadmap.
Collaborate with analysts, data scientists & engineers to write data transforms/pipelines to generate reliable insights, and build data-driven products.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Work with various parts of the organization (Analytics, Engineering, Product, Operations, etc.) to support self-service analytics.
Help foster a spirit of innovation and collaboration both within the engineering team and across the organization.
Work to create impactful and sustainable solutions to complex problems by taking bold and measured risks.
Balance your technical excellence with a high E.Q., showing up with a sense of empathy, awareness, and responsibility.
Share the knowledge you gain generously with your peers to perpetuate a culture of engineering excellence.
This role will be based in San Francisco or Portland and will report to the Director of Data Science based in San Francisco. At this time, we can only consider applicants with authorization to work in the United States on a permanent, full-time basis; unfortunately, we cannot provide visa sponsorship.

About You
You have a BS in a quantitative discipline (computer science, engineering, physics, mathematics, or a related field) or comparable work experience.
You have built data platforms to enable analytics and data-driven products using agile software development principles.
You have 5+ years of data warehousing experience (data modeling, ETL/ELT, data cleansing, systems & database administration) on a modern data warehouse (like Redshift / Snowflake / etc.).
You have experience working with modern analytics tools (like Looker / Tableau / Metabase, etc.) to design user-facing analytics.
You have strong coding (SQL & Python) and report design skills.
You have worked with various internal stakeholders to gather business requirements and translate them into technical solutions.
You can communicate findings and recommendations to technical and non-technical audiences.
You are willing to learn, take initiative, and wear multiple hats as required.
What We Offer:
An opportunity to improve real lives, solve hard problems, and change the world
Friendly, supportive, and adventurous environment with a team of engaged colleagues
A comprehensive, industry-leading benefits package
Opportunities to connect with and learn from colleagues and partners around the world
A diverse and inclusive workplace where we learn from each other is an integral part of Kiva's culture. We actively welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a great place to work. Join us and help us achieve our mission!

We will only accept applications directly from candidates. Kiva will not be responsible for any recruiting agency fees, absent a formal agreement.",4.0,"Kiva.org
4.0","San Francisco, CA",-1,51 to 200 Employees,2005,Nonprofit Organization,Lending,Finance,Unknown / Non-Applicable,-1
61,"Lead Data Engineer, Modeling & Machine Learning",$79k-$143k (Glassdoor Est.),"At Rockstar Games, we create the games we would want to play ourselves.

A career at Rockstar is about being part of a team working on some of the most creatively rewarding, large-scale projects to be found in any entertainment medium. You would be welcomed to a friendly, inclusive environment where you can learn, and collaborate with some of the most talented people in the industry.

Rockstar San Diego is seeking a Lead Data Engineer to join a team focused on building a cutting-edge game analytics platform and tools to better understand our players and enhance their experience in our games. This is a full-time permanent position based out of Rockstar's unique game development studio in Carlsbad, CA.

The ideal candidate will be skilled in developing complex ingestion and transformation processes with an emphasis on reliability and performance. In collaboration with other data engineers, database administrators, and developers, the candidate will empower the team of analysts and data scientists to deliver data driven insights and applications to company stakeholders.

WHAT WE DO
The Rockstar Analytics team provides insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making.
We partner with multiple departments across the company to design and implement data and pipelines.
We collaborate as a global team to develop cutting-edge data pipelines, data products, data models, reports, analyses, and machine learning applications.
RESPONSIBILITIES
Lead the development of data models/aggregations, machine learning pipelines, machine learning feature stores and data products for the Analytics team and partner groups.
Assure Rockstar's ongoing competitive advantage through best-in-class data model designs, machine learning pipelines and data products that have a high business value.
Identify and lead projects aligned with long-term, strategic initiatives.· Lead the development, maintenance, and improvement of new and existing algorithms and their underlying systems.
Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation.
Lead the implementation of end-to-end solutions for batch and real-time algorithms along with requisite tooling around monitoring, logging, automated testing, performance testing and A/B testing with a team of analysts and data scientists who create insights and analytics applications for our stakeholders.
Contribute to and promote good software engineering practices across the team.
Lead, manage and inspire a team of world class data engineers, providing leadership through coaching and mentorship on a regular basis.
Influence the analytics and technology roadmap.
Participates in the recruitment of the best in class data engineers.
QUALIFICATIONS
3+ years of experience managing and supervising a team.
5+ years of work experience with ETL, data modeling, and business intelligence big data architectures.
5+ years of experience with the Hadoop ecosystem (Map Reduce, Spark, Spark-Streaming, Oozie, Impala, etc.) and big data ecosystems (Kafka, Cassandra, etc.).
Expert in at least one SQL language such as T-SQL or PL/SQL.
Experience developing and managing data warehouses on a terabyte or petabyte scale.
Strong experience in massively parallel processing & columnar databases.
Experience working with Real-Time, Near-Real-Time streaming pipelines.
Experience with Python and shell scripting.
Experience working in a Linux environment.
SKILLS
Strong problem-solving skills.
Proven ability to reconcile technical and business perspectives.
Proven ability to develop and maintain good relations and communicate with people at all hierarchical levels.
Autonomy and entrepreneurship.
Strong mentoring abilities.
Strong team spirit.
Passion for Rockstar Games and our titles.
PLUSES


Please note that these are desirable skills and are not required to apply for the position.
Experience with event processing frameworks.
Experience with Java or Scala programming languages.
Familiar with Restful APIs.
Experience with Artifact Repositories.
Game industry experience.
HOW TO APPLY


Please apply with a resume and cover-letter demonstrating how you meet the skills above. If we would like to move forward with your application, a Rockstar recruiter will reach out to you to explain next steps and guide you through the process.

Rockstar is proud to be an equal opportunity employer, and we are committed to hiring, promoting, and compensating employees based on their qualifications and demonstrated ability to perform job responsibilities.

If you've got the right skills for the job, we want to hear from you. We encourage applications from all suitable candidates regardless of age, disability, gender identity, sexual orientation, religion, belief, or race.",4.1,"Rockstar Games
4.1","Carlsbad, CA",-1,1001 to 5000 Employees,1998,Subsidiary or Business Segment,Video Games,Media,$10 to $25 million (USD),-1
62,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
63,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
64,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
65,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
66,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
67,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
68,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
69,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
70,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
71,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
72,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
73,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
74,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
75,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
76,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
77,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
78,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
79,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
80,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
81,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
82,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
83,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
84,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
85,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
86,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
87,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
88,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
89,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
90,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
91,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
92,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
93,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
94,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
95,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
96,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
97,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
98,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
99,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
100,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
101,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
102,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
103,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
104,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
105,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
106,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
107,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
108,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
109,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
110,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
111,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
112,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
113,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
114,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
115,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
116,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
117,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
118,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
119,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
120,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
121,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
122,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
123,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
124,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
125,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
126,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
127,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
128,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
129,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
130,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
131,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
132,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
133,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
134,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
135,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
136,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
137,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
138,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
139,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
140,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
141,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
142,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
143,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
144,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
145,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
146,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
147,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
148,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
149,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
150,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
151,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
152,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
153,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
154,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
155,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
156,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
157,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
158,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
159,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
160,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
161,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
162,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
163,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
164,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
165,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
166,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
167,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
168,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
169,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
170,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
171,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
172,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
173,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
174,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
175,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
176,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
177,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
178,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
179,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
180,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
181,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
182,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
183,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
184,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
185,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
186,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
187,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
188,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
189,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
190,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
191,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
192,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
193,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
194,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
195,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
196,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
197,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
198,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
199,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
200,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
201,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
202,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
203,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
204,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
205,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
206,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
207,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
208,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
209,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
210,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
211,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
212,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
213,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
214,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
215,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
216,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
217,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
218,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
219,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
220,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
221,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
222,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
223,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
224,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
225,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
226,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
227,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
228,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
229,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
230,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
231,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
232,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
233,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
234,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
235,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
236,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
237,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
238,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
239,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
240,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
241,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
242,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
243,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
244,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
245,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
246,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
247,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
248,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
249,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
250,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
251,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
252,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
253,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
254,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
255,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
256,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
257,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
258,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
259,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
260,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
261,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
262,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
263,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
264,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
265,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
266,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
267,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
268,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
269,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
270,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
271,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
272,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
273,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
274,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
275,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
276,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
277,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
278,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
279,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
280,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
281,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
282,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
283,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
284,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
285,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
286,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
287,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
288,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
289,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
290,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
291,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
292,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
293,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
294,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
295,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
296,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
297,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
298,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
299,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
300,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
301,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
302,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
303,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
304,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
305,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
306,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
307,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
308,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
309,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
310,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
311,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
312,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
313,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
314,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
315,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
316,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
317,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
318,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
319,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
320,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
321,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
322,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
323,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
324,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
325,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
326,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
327,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
328,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
329,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
330,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
331,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
332,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
333,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
334,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
335,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
336,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
337,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
338,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
339,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
340,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
341,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
342,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
343,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
344,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
345,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
346,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
347,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
348,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
349,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
350,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
351,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
352,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
353,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
354,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
355,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
356,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
357,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
358,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
359,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
360,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
361,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
362,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
363,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
364,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
365,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
366,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
367,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
368,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
369,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
370,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
371,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
372,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
373,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
374,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
375,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
376,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
377,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
378,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
379,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
380,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
381,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
382,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
383,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
384,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
385,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
386,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
387,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
388,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
389,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
390,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
391,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
392,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
393,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
394,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
395,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
396,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
397,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
398,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
399,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
400,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
401,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
402,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
403,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
404,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
405,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
406,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
407,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
408,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
409,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
410,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
411,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
412,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
413,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
414,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
415,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
416,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
417,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
418,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
419,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
420,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
421,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
422,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
423,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
424,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
425,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
426,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
427,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
428,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
429,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
430,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
431,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
432,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
433,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
434,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
435,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
436,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
437,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
438,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
439,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
440,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
441,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
442,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
443,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
444,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
445,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
446,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
447,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
448,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
449,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
450,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
451,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
452,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
453,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
454,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
455,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
456,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
457,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
458,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
459,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
460,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
461,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
462,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
463,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
464,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
465,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
466,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
467,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
468,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
469,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
470,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
471,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
472,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
473,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
474,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
475,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
476,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
477,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
478,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
479,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
480,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
481,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
482,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
483,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
484,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
485,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
486,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
487,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
488,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
489,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
490,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
491,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
492,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
493,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
494,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
495,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
496,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
497,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
498,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
499,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
500,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
501,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
502,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
503,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
504,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
505,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
506,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
507,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
508,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
509,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
510,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
511,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
512,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
513,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
514,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
515,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
516,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
517,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
518,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
519,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
520,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
521,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
522,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
523,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
524,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
525,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
526,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
527,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
528,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
529,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
530,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
531,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
532,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
533,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
534,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
535,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
536,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
537,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
538,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
539,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
540,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
541,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
542,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
543,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
544,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
545,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
546,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
547,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
548,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
549,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
550,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
551,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
552,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
553,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
554,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
555,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
556,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
557,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
558,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
559,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
560,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
561,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
562,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
563,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
564,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
565,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
566,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
567,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
568,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
569,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
570,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
571,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
572,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
573,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
574,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
575,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
576,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
577,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
578,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
579,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
580,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
581,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
582,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
583,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
584,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
585,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
586,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
587,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
588,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
589,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
590,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
591,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
592,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
593,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
594,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
595,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
596,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
597,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
598,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
599,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
600,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
601,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
602,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
603,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
604,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
605,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
606,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
607,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
608,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
609,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
610,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
611,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
612,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
613,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
614,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
615,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
616,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
617,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
618,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
619,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
620,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
621,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
622,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
623,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
624,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
625,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
626,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
627,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
628,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
629,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
630,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
631,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
632,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
633,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
634,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
635,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
636,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
637,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
638,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
639,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
640,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
641,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
642,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
643,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
644,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
645,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
646,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
647,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
648,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
649,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
650,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
651,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
652,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
653,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
654,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
655,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
656,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
657,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
658,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
659,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
660,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
661,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
662,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
663,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
664,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
665,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
666,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
667,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
668,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
669,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
670,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
671,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
672,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
673,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
674,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
675,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
676,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
677,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
678,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
679,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
680,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
681,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
682,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
683,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
684,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
685,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
686,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
687,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
688,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
689,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
690,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
691,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
692,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
693,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
694,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
695,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
696,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
697,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
698,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
699,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
700,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
701,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
702,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
703,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
704,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
705,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
706,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
707,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
708,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
709,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
710,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
711,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
712,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
713,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
714,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
715,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
716,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
717,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
718,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
719,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
720,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
721,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
722,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
723,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
724,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
725,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
726,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
727,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
728,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
729,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
730,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
731,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
732,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
733,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
734,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
735,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
736,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
737,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
738,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
739,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
740,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
741,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
742,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
743,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
744,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
745,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
746,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
747,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
748,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
749,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
750,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
751,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
752,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
753,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
754,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
755,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
756,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
757,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
758,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
759,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
760,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
761,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
762,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
763,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
764,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
765,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
766,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
767,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
768,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
769,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
770,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
771,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
772,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
773,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
774,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
775,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
776,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
777,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
778,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
779,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
780,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
781,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
782,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
783,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
784,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
785,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
786,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
787,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
788,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
789,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
790,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
791,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
792,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
793,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
794,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
795,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
796,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
797,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
798,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
799,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
800,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
801,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
802,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
803,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
804,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
805,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
806,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
807,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
808,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
809,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
810,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
811,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
812,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
813,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
814,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
815,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
816,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
817,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
818,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
819,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
820,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
821,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
822,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
823,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
824,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
825,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
826,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
827,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
828,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
829,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
830,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
831,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
832,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
833,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
834,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
835,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
836,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
837,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
838,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
839,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
840,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
841,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
842,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
843,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
844,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
845,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
846,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
847,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
848,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
849,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
850,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
851,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
852,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
853,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
854,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
855,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
856,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
857,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
858,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
859,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
860,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
861,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
862,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
863,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
864,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
865,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
866,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
867,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
868,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
869,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
870,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
871,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
872,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
873,Senior Software Engineer - Data - Pandora,$105k-$182k (Glassdoor Est.),"Data engineers at Pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day. Data Engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections (billions of events per day). At Pandora the data platform team supports a variety of business functions including our science, marketing, product, finance and sales teams. You should have a solid understanding of Java and Python software development, and take personal responsibility for testing the code you write. You should have strong academic credentials and a degree in Computer Science or a related field. You should be enthusiastic about learning new technologies and skills. You must be capable of managing your time well and working collaboratively. Excellent communication skills, both written and verbal, are required.

Supervisory Responsibilities:
None
Minimum Qualifications:
5+ years experience developing back-end server software, preferably in Java
Experience with data streaming technologies - Kafka, Kafka Connect, KStreams, KSQL
Experience with cloud computing - Google Cloud Platform, Amazon Web Services
Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server side software for deployment
Experience developing service oriented architectures/orchestration
Experience with API design/development -- RPC, REST, JSON
Significant experience unit testing with frameworks -- JUnit
Plus Requirements:
Experience developing with additional languages - Python, Scala, pyTest, pyUnit
Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Scoop
Experience developing SQL applications of significant complexity
Experience with workflow tools -- Airflow, Composer
Experience with full stack development -- React, SpringBoot, Django
Experience with data serialization system - Avro, Protobuf
Experience with automated deployment procedures using dev-ops tooling - Ansible, Terraform
BA/BS or above in Computer Science or a related field
""We're considering candidates for multiple positions and levels. Successful candidates will be placed at appropriate level depending on their qualifications or experience.""

Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.2,"SiriusXM
3.2","Oakland, CA",-1,1001 to 5000 Employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
874,Senior Software Engineer - Data,$105k-$182k (Glassdoor Est.),"Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We're looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We're building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a Senior Data Engineer, you'll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we're looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We're not just building a platform to make the world programmable. We're also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Perks

Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco's Fair Chance Ordinance.

Forbes 30 Under 30 - Enterprise Technology 2017
#61 on Y Combinator's Top Companies List 2018
#26 2018 Fastest-Growing Private Companies, The Business Journals",4.4,"Lob
4.4","San Francisco, CA",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
875,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist leveraging modern cloud database technologies like Redshift and Snowflake
5+ years of experience and savviness with complex SQL queries as well as knowledge of database technologies including window and analytical functions
1+years of experience with Python analytic libraries and Business Intelligence (BI) tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",4.1,"Splunk
4.1","San Jose, CA",-1,1001 to 5000 Employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
876,Remote SN Data Engineer with Snowflake,$105k-$182k (Glassdoor Est.),"RESPONSIBILITIES:

Kforce has a client seeking a Remote SN Data Engineer with Snowflake in Newport Beach, CA.

Responsibilities:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies
Create low-level design artifacts, including architecture diagrams and mapping specifications
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment
Participate in code reviews to ensure standards and best practices
Work to deploy, monitor, and maintain production systems
Analyze and organize raw data for ingestion
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
REQUIREMENTS:
Preferred Skills: AWS Glue, Shell Scripting, SnoPro Core Certification
Minimum of 1 year of hands on experience working in Snowflake (preferably migrating on-premise databases like Oracle to Snowflake in Cloud)
Experience in Python, Java Script, AWS Lambda
CI/CD: Data Ops Experience (Terraform, Azure Dev Ops, Git repositories, Build and Release pipelines)
Hands on experience with ELT tools (e.g. Matillion or DBT or Fivetran or Stitch etc.)
Applicants must be fully authorized to work in the U.S. without sponsorship
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Newport Beach, CA",-1,10000+ Employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
877,Data QA Engineer,$105k-$182k (Glassdoor Est.),"Job Description: Data QA Engineer
Location: San Jose, CA
Department: Quality Engineering
Hours/Shift: Full Time
Reports To: VP, Software Engineering
Job Description:
Affinity Solutions is looking for a self-motivated mid-level Data QA Engineer to lead the testing framework design, development, automation for our big data infrastructure leveraging latest technologies such as Hadoop and Spark, both on-premise and in the cloud. This position requires experience in testing and automation of data pipelines, data services, data warehouses, business intelligence and machine learning platforms, especially around unified consumer transactional, demographic and behavioral data.
The ideal candidate is a passionate and highly skilled individual, who can utilize programming and analytics tools/technologies such as SQL/NoSQL, Python, and Tableau to validate products, data pipelines and data deliverables. If you have experience in automation, quality engineering of data centric applications/systems, especially around credit/debit card transactions, unified consumer behavioral and profile data, and excited about leveraging your experience to catapult into hyper-growth, this job is for you.
Responsibilities:
Design and implement Test Automation frameworks using Python, node.js, SQL, javascript and React JS.
Develop test strategies, plans, test cases and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality
Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability.
Building and automating testing frameworks around data ingestion pipelines for master data management, deep-learning, and predictive analytics
Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies.
Lead data governance and data profiling efforts to ensure data quality and proper meta data documentation for data lineage.
Creating quality metrics to evaluate data pipelines, products and customer deliverables.
Collaborate with diverse technical and non-technical teams located across multiple time-zones on client deliverables and technical support
Participate-in and contribute to design and code reviews
Qualifications:
Bachelor’s or Master’s degree in Computer Science or related field such as Mathematics and Statistics, preferably with focus on data analytics.
3+ years of experience in data integration / data engineering
3+ years of experience in data modeling and architecture
3+ years of experience in QA automation
Experience in working with large scale Enterprise data warehouse, data integration, data migration and data quality verification
Hands-on testing experience in working Hadoop, Spark and other Big data technologies is highly preferred
Knowledge of data pipelines using SQL, Hive, Spark, Spark ML
Excellent analytics, problem-solving and debugging skills",3.0,"Affinity Solutions
3.0","San Jose, CA",-1,51 to 200 Employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
878,"Senior Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will have at least 5+ years of experience, and will always be on the lookout for the balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",4.0,"Carta
4.0","San Francisco, CA",-1,501 to 1000 Employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
879,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Senior Data Engineer

Location/City: Playa Vista, CA or Any Where in the Unites States

Responsibilities

Steady is seeking sharp, highly-motivated data engineers who are excited to play a major role in our product and engineering evolution. We are looking for product focused, results-oriented engineers who thrive in a collaborative, team-focused culture. You will work closely with data scientists, analysts, product managers, business stakeholders, and your team to help define, implement, and ship significant increments to the data infrastructure that powers Steady's mission-driven product offering.

As a Senior Data Engineer, you will:
Work across all phases of the software development lifecycle in a cross-functional, agile development team setting
Collaborate with data scientists and analysts to prepare complex data sets that can be used to solve difficult problems
Administer, maintain, and improve Steady's data infrastructure and data processing pipeline, including ETL jobs, events processing, and job monitoring and alerting.
Deliver high-quality, well-tested technical solutions that make sense for the problem at hand
Fearlessly work across components, services, and concerns to deliver business value
Partner with engineers, data scientists, and the CDO to define and refine our data architecture and technology choices
Help define, implement, and reinforce data engineering best practices and processes
Contribute to Steady's technical vision
Skills & Requirements
Significant data engineering and/or software development experience (5-7 years minimum)
Experience with ingesting, processing, and transforming data at scale
Demonstrated proficiency with SQL, relational database, and data warehousing concepts
Demonstrated aptitude with ETL concepts and tools such as Airflow or AWS Glue
Experience of the AWS data ecosystem (Glue, Kinesis, S3, Lambda, EMR, Redshift, etc.)
Understanding of event-driven and/or streaming workflows with tools like Kafka and Spark
Experience administering cloud-based analytics databases (like Snowflake or Redshift)
Knowledge of Python, R or other common languages used in data science
Ability to thrive in a fast-paced and dynamic environment
Ability to work well in teams of all sizes with representatives from a diverse set of technical backgrounds.
Preferred: Experience with infrastructure automation through tools like Terraform or CloudFormation
Preferred: Experience with indexing and search technologies like elasticsearch, SOLR, etc.
Preferred: Experience building or maintaining a data science modeling environment such as Sagemaker or Databricks, including deployment and monitoring using tools like MLFlow
Bachelor's or Master's degree in Computer Science or equivalent experience
Benefits

We value our Steady Team Members and are committed to their success. We are located in downtown Atlanta near MARTA, and in the heart of Playa Vista, CA. We offer competitive compensation packages and a 100% company-paid benefits package including medical, dental, and vision. Steady is a relaxed, casual work environment with flexible hours in addition to a weekly meal stipend. We also offer a generous PTO plan, 401K, and future growth opportunities within the company. We strive to maintain a positive and fun environment for our employees where people can learn and grow with the company.

About Steady

Steady is a mission-driven business that helps people earn more. Through the free Steady app users can build & track income, networks, and buying power – allowing them to augment retirement savings, work around childcare responsibilities, pay down debt, save for purchases, and supplement their income from primary employers, while limiting their income volatility and better positioning themselves for access to a sustainable financial services ecosystem.

Every Steady member will build something different. We celebrate those who take the initiative to create a path that works for them. Whatever that looks like, Steady is there to support it, providing a stable foundation that allows people to build financial success over a lifetime.

Mission: Steady turns the tables by putting workers back in charge of their financial future with an income-building platform that creates financial stability and helps its users to take charge of their future.

For more information, visit us at www.steadyapp.com or on Twitter @TheSteadyApp.

Steady, Platform Inc. (Steady) is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Steady accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Steady employees, Steady hiring manager, or send to any Steady facility. Steady is not responsible for any fees or charges associated with unsolicited resumes.",4.0,"Steady Platform
4.0",California,-1,1 to 50 Employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
880,Cost Analyst Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID: 56833

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is looking for a Full-Time Cost Analyst. The qualified candidate will become part of the Integrated Cost and Schedule Analysis (iCASA) Department. iCASA conducts highly informative parametric and engineering buildup cost and schedule assessments, trade studies, and estimates for a wide variety of government and commercial space, ground, and launch systems.

Key Functions
Provide research and analysis of cost and technical data to support the government in the procurement of cost-effective space systems for a wide customer base: DOD, Civil and Commercial, and the Intelligence Community.
Lead support to space and/or ground acquisition program offices, cost groups, and independent review teams in a wide range of programmatic and technical analyses, with an emphasis in the following areas: cost data collection, cost analysis and estimation, cost risk analysis, cost research, cost engineering, and programmatic studies.
Specific activities may include support to engineering trade studies and program technical baseline development; proposal evaluations; independent cost estimates/assessments; cost-benefit analysis; peer reviews of estimates; data collection, normalization, database development, and model development for in-house tools.
Candidate must be able to communicate sophisticated concepts to the customer and be responsible for ensuring Aerospace technical quality in terms of completeness, relevance, accuracy, and timeliness.
Candidates must be able to work effectively as part of a team and react quickly to changing requirements and schedules.
Candidates must be able to think critically and work effectively to synthesize information from multiple sources.
Mentor junior level staff charged with similar duties.
Travel when required.
This position is available as an Engineering Specialist or Senior Engineering Specialist
Qualifications
Required for Engineering Specialist
Bachelor’s degree in Engineering, Mathematics, Science, or related field.
Minimum of eight years of relevant experience including, knowledge of space and launch systems; ground systems knowledge highly desirable.
Familiarity with industry cost models and standard cost methodologies.
Strong foundations in statistical techniques including probability, regression, correlation, and basic statistical inference.
Excellent verbal and written communication skills.
Demonstrated ability to manage multiple tasks and collaborate effectively with staff.
Strong written and oral communication skills; excellent presentation and interpersonal skills.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Experience developing and maintaining cost models and conducting schedule risk assessments.
Familiarity with industry cost models.
Extensive knowledge of the DoD acquisition process.
Experience building cost models and advanced programming skills.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Required for Senior Engineering Specialist
Meets all Engineering Specialist requirements.
Minimum of 12 years of relevant experience, including detailed experience with space, launch and ground systems acquisition.
Experience leading the development of cost estimates and assessments.
Extensive knowledge of the DoD acquisition process.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred for Senior Engineering Specialist
Advanced degree in Engineering, Mathematics, Science, or related field from an accredited university.
Familiarity with the National Intelligence Community budget cycle.
Certification in cost estimating by a recognized professional society/educational organization (i.e., ICEAA).
Active DoD Top Secret and/or SSBI/SCI Clearance.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA",-1,1001 to 5000 Employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
881,Staff Software Engineer - Data Platform,$105k-$182k (Glassdoor Est.),"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA",-1,51 to 200 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
882,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Title
Senior Data Engineer

18-Jun-2020

Division
Life Insurance

Job Description

Pacific Life is embarking on a multi-year initiative to invest in dynamic people and technology, ensuring a bright future for our customers and community. To support this process, we are looking for a skilled Sr. Data Engineer to join our team in Newport Beach, CA.

As a Senior Data Engineer you’ll play a key role in Pacific Life’s digital and workplace transformation by working directly with the Advanced Analytics and Data Management teams to deliver data products in a collaborative and high-impact environment. You’ll design, build, and maintain processes and components of a data pipeline to support analytics across LID, focusing on data quality and governance, pipeline performance, and best practices for democratized data access.

If you’re an expert in data engineering, traditional data warehousing, ETL and/or big data pipeline and processing, you’re exactly who we’re seeking. Technical capabilities aside, if you’re a self-starter who’s comfortable with ambiguity, able to think big without overlooking minute details, and who thrives in a fast-paced environment, you’re perfect for our team.

What You’ll Do
Develop compelling PoCs for data solutions using emerging technologies for real-time and big data ingestion and processing
Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)
Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues
Collaborate with data scientists and analysts to design and develop processes to further business unit and company-wide data science initiatives on a common data platform
Align with the systems engineering team to propose and deploy new hardware and software environments required and expand existing environments
Diligently team with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Tech & Tools You’ll Use

NoSQL databases (Cassandra, HBase, Mongo), Python, Scala and/or Java, SQL, Data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce), Data warehouses (Greenplum, Snowflake, Redshift

Factors for Success
8+ years of data engineering experience in traditional data warehousing, ETL and/or big data pipeline & processing environments
Strong data modeling and SQL experience
Strong programming experience with Python, Scala and/or Java
Experience with big data processing technologies (Spark, Storm, Kafka, Flume, Pig, Hive, Sqoop, Hadoop/MapReduce, etc.)
Experience with columnar storage and massive parallel processing data warehouses (Greenplum, Snowflake, Redshift preferred)
Hands on experience with building CI/CO
Experience modeling and querying for NoSQL databases (Cassandra, HBase, Mongo)
Experience working within agile software engineering methodologies
A career at Pacific Life is more than a job. You’ll find those who work passionately each day to drive our company forward enjoy job security, flexible scheduling and great opportunities for career growth. If you’re seeking a thriving career doing the type of meaningful work that’s all too rare at a Fortune 200 Company, you’re the perfect cultural fit for our team. See how we harness the Power of Pacific to fulfill our shared purpose – apply for one of our positions and grow your career with Pacific Life today!

#LI-DD1

#LI-DD1

Req Number
5303BR

Full Time / Part Time
full time

Benefits
Join the Pacific Life team and watch your career grow! We offer a competitive compensation and benefits package that includes: • Competitive salary and bonus program • Medical, dental, and vision as part our commitment in investing in the health and wellbeing of our employees • Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) • Generous vacation time and holiday pay • And much more!

EEO Statement
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.

About Pacific Life
Pacific Life is fully committed to supporting our team with a safe and healthy work environment. During these challenging times, we’re using digital technology and remote work options to ensure every employee is empowered to contribute to their full potential while growing their careers at Pacific Life.

Pacific Life is a growth-oriented company with a strong and competitive position within the life insurance, retirement savings, and reinsurance markets. It holds top 15 market positions in almost all of its key products and has a diverse product portfolio serving the key markets of the highly affluent, broad market, small and mid-size businesses, and the institutional space. It has a global presence through its reinsurance business, with key markets in the U.K., Asia, and Australia. Pacific Life’s structure as a mutual holding company is a competitive advantage, allowing the company to make decisions with a long-term view for the best interests of the organization and its policyholders. Pacific Life has a stellar reputation for service and value to the financial intermediaries and distribution channels that distribute our products.

We firmly believe each of our employees play a part in our continued growth and success, and we pride ourselves in providing a work environment that is challenging, inclusive, collaborative, and results-oriented. With a powerful past and a strong future, Pacific Life provides an exciting work environment where your energy, enthusiasm, and ideas are valued. We are committed to giving you the resources and space to do your best work and feel good about the impact you make.

Pacific Life is ranked 298th on the 2019 Forbes Fortune 500 list, has been named one of the 2019 World’s Most Ethical Companies® by the Ethisphere Institute, and was named by Forbes as one of America's Best Midsize Employers for 2019.

Position Location(s)
Aliso Viejo, CA",3.8,"Pacific Life
3.8","Aliso Viejo, CA",-1,1001 to 5000 Employees,1868,Company - Private,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
883,"Staff Data Engineer, eComm, Web Analytics",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Web Analytics, you will help the Worlds largest omnichannel retailer instrument tagging and tracking in Omniture (Adobe Analytics) to collect user clickstream data. You will Architect Web Analytics data infrastructure including Omniture instrumentation both client and server-side integration. You will partner with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Subject matter expert in Adobe Analytics (Omniture)
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
884,"Staff Data Engineer, eComm, Backend",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Backend, you will help the Worlds largest omnichannel retailer model, collect, process, transform, organize and leverage robust data sets that will be used to manage and optimize the business. This Staff Data Engineer will Architect, Design, Develop and Deliver end-to-end data pipelines in a Cloud and Hybrid environment to calculate aggregate core Marketing metrics that help track and measure Marketing media performance. This Staff Data Engineer partners with channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities
Lead specific areas of Marketing domain from Data Engineering standpoint
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Architect, Design, Develop and Maintain multiple robust, scalable and generic data pipelines to support Marketing Channel performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Design and Build realtime analytics platform by leveraging Apache Flume, Kafka, and Spark Structured Streaming or similar technologies
Enhance and Maintain a Google Cloud based data platform built using DataProc, PubSub, Cloud Storage, Jupyter Hub (Jupyter Notebooks) and Livy
Build API connectors to source in Marketing spend and performance data from external partners
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Work with machine learning/data science team on implementation of data with AI models
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, address speed/performance issues
Work with BI and data science team members to assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency
Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
885,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"WHO WE ARE

NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world's top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.

WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?
We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.
We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.
We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren't shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.
We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.
WHAT YOU'LL DO

As a Senior Data Engineer, you'll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.
Understanding data source (10%)
Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)
Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)
Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)
Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)
WHAT YOU'LL NEED TO BE SUCCESSFUL
BS in Computer Science or equivalent experience
5+ years of day-to-day working experience as data engineer
Experience with object-oriented and functional programming languages: Python, Scala etc.
Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)
Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.
Experience with ETL and data integration tool : Airflow, Informatica PowerCenter
Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.
Proficiency in general database administration concepts and efficient query writing
Excellent verbal and written communication skills
An eagerness to continually improve their skills, learn new technologies and is willing to take initiative beyond basic responsibilities
This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.",3.0,"NCSOFT
3.0","Aliso Viejo, CA",-1,1001 to 5000 Employees,1997,Company - Public,Video Games,Media,$10+ billion (USD),-1
886,Senior Software Engineer: Data Infrastructure,$105k-$182k (Glassdoor Est.),"Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.

Working as a Senior Software Engineer you will be responsible for further development of infrastructure and platforms for wrangling data produced by Joby Aviation test and flight operations. You should be able to work cohesively inside of a team, understand large data systems, and have an eye for scalable and flexible designs. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.


The successful candidate will assist in architecting, designing, and implementing systems to:
Wrangle data from a multitude of telemetry sources.
Employ standard database technologies in a modern, scalable data mining and analytics system.
Efficiently push, pull, and process Joby Aviation data in support of Data Analytics and Machine Learning.
Provide robust analytics platforms to Joby Data Scientists and Analysts.
Support visualization and presentation tools that help Scientists and Engineers realize value from data.
Monitor performance, reliability, and trends to efficiently scale our Data Services infrastructure.

University degree in computer science, computer engineering, physics, mathematics, or similar field.
5+ years experience in relevant industry.
Expert knowledge of data system architectures.
Expert knowledge of database technologies oriented towards time-series data and platforms for scientific computing and analytics.
Expert knowledge of big-data and cloud methodologies, including extensive experience with Unix or Linux for development and deployment -- specific experience with Kubernetes and AWS considered a strong plus.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, data analytics, and machine learning.

POSITION MAY INCLUDE ACCESS TO TECHNOLOGY THAT IS SUBJECT TO U.S. EXPORT CONTROLS.",3.8,"Joby Aviation
3.8","Santa Cruz, CA",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
887,"Staff Data Engineer, eComm- Visualization (Tableau SME)",$105k-$182k (Glassdoor Est.),"Position Summary...
What you'll do...


As a Staff Data Engineer, Visualization, you will help the Worlds largest omni-channel retailer structure, collect, organize and display robust data sets that will be used to manage and optimize the business. The Staff Data Engineer will work closely with database architects, channel and category BI analysts, the campaign measurement team, and data scientists on data initiatives and will ensure data is consistent and accurate at scale.

Responsibilities:
•Maintain robust visualizations to support Marketing Vehicle performance, Category performance, Customer cohort activity, and Financial Plan/Forecast reporting.
•Define the BI Architecture for dynamic and real time updates of dashboards.
•Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
•Deliver ongoing and accurate reporting of KPIs for Weekly Business Review reporting.
•Define optimized DB schemas that power the snappy dashboards.
•Publish KPI definitions and ensure they are consistent with Marketing Analytics, Marketing Finance, and Retail Operations expectations.
•Work with BI and data science team members to assist them in accessing and leveraging key data sets.
•Provide analytics tools and training to drive actionable insights into key business performance metrics, including campaign and category performance, marketing vehicle performance, customer funnel metrics, and operational efficiency.
•Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data accuracy and consistency.

Minimum Qualifications...


Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related
field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...


Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Masters degree in Computer Science or related field and 4 years' experience in software engineering",3.3,"Walmart
3.3","San Bruno, CA",-1,1001 to 5000 Employees,1962,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD),-1
888,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Roofstock is the leading marketplace for investing in single-family rental homes that cash flow day one. With over $2B in transactions, our mission is to make real estate investing radically accessible, cost effective and simple. We want to use technology to transform the way real estate is bought and sold and make real estate investing as simple as investing in stocks. Simply put, we are passionate about helping our customers build wealth through real estate.

Roofstock has been recognized as a great workplace by Glassdoor and Great Place to Work® and was recently named to the Forbes Fintech 50 and the Red Herring 100 lists of most innovative companies. Roofstock has raised over $83M to date, is based in Oakland, CA and Dallas,TX with approximately 200 people and is growing rapidly. Check out our reviews and see why our employees love working here!

We are looking for a talented Senior Data Engineer to join our established, small but quickly growing company, working on a wide range of data projects in close collaboration with other data engineers, data scientists, and data analysts in an integrated Data Team. We use a modern all-cloud data stack including Airflow, Docker, DBT, Python, Snowflake, Tableau, Sigma, and our old friend SQL.

If you thrive in a team environment, are willing to pitch in wherever needed to help the team succeed, are passionate about data and excited about empowering users with data to drive decision making, Roofstock is the place for you.
What you will do:
Improve and maintain the data infrastructure
Design, implement and deploy, scalable, fault-tolerant pipelines that ingest, and refine large diverse (structured, semi-structured and unstructured datasets) into simplified accessible data models in production
Built departmental data-marts for supporting analytics across the company
Collaborate with cross-functional teams to understand data flows and processes to enable design and creation of the best possible solutions to each engineering challenge
Provide quality data solutions in a timely manner and be responsible for data governance and integrity while meeting objectives and maintaining SLAs
Build tools and fundamental data sets that encourage self-service
What you bring with you:
BS or MS in a technical field: computer science, engineering or similar
8+ years professional experience working with both relational and analytical databases (preferably SQL Server, PostgresSQL, Snowflake)
5+ years professional experience in building robust data pipelines (beyond simple API pulls) and writing ETL/ELT code (SSIS, Informatica, python code, shell scripts, complex SQL)
3+ years of experience working with Airflow, AWS/Azure
Expert understanding of the SDLC, data warehousing concepts and dimensional data modeling
Advanced skills related to database management, administration and security
Experience building and deploying data-related infrastructure (messaging, storage, compute, transform, execution via docker, and/or CI/CD pipelines across dev/stage/prod)
Experience in DBT is a plus
Strong communication and interpersonal skills
Roofstock is an equal opportunity employer. In keeping with the values of Roofstock, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.",4.2,"Roofstock
4.2","Oakland, CA",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,$10 to $25 million (USD),-1
889,"Senior Software Engineer, Data",$105k-$182k (Glassdoor Est.),"Role Summary

You will help build the core technology and algorithms that drive the newest addition to our suite: Usage Intelligence. This position will have the opportunity to contribute greatly to both our company by producing quality actionable data that our users can derive insight from, as well as to your career - through the work you will do in this leading area of technology.

You have worked at a startup before, and are used to working in a fast paced environment and making a big impact on the projects you work on and lead.

If you're this purple squirrel we speak of - that has strong data science skills, even stronger coding skills and great product/business acumen, our co-founders are ready to talk.

Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy and are looking to increase app downloads through app store optimization.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Read more about some of our Technical challenges here (written by members of our engineering team):
https://sensortower.com/blog/speeding-up-the-backend-with-graph-theory
https://sensortower.com/blog/how-we-scaled-to-thousands-of-sidekiq-workers

Read more about our Engineering Culture here: https://www.keyvalues.com/sensor-tower
Responsibilities
Execute on the development of data modeling algorithms with a focus on: analyzing large sets of data, building models, ensuring data accuracy, reliability and consistency.
Developing, refining and bringing data models to production. This role will work on models that are consumed by our end users: you’re not building internal tools or one time reports, but working on the actual product that our users consume and rely on every day.
Embrace a quick build, measure and iterate cycle to bring products to market and work alongside world class engineers, and data scientists.
Requirements
You have experience working on engineering, data analysis and data modelling problems at scale, and producing data models that drive meaningful business impact.
You are comfortable and fluent with high level Math and Statistics concepts.
You have experience designing and fine tuning algorithms. You are challenge driven and enjoy solving difficult problems while ensuring data accuracy.
4+ Years working and coding in a programing language like Python, Ruby, etc.
BS or Advanced degree in CS or related field.
Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team, please visit our Key Values profile.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","San Francisco, CA",-1,1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
890,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Requisition ID # 55671

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively in order to deliver high quality technology solutions.

The Data & Analytics Team within IT is responsible for working collaboratively with the lines of business (e.g., Electric Operations, Gas Operations, etc.) to implement consumer-grade data platforms and products across various user groups (e.g., asset strategists, inspectors, emergency operations, etc.). This includes, but is not limited to:
Deploying best-in-class / rapid delivery capabilities for data solutions and self-service enablement for highly skilled analysts and data scientists
Simplifying, improving, and standardizing processes to promote data-driven decisions and drive the digital transformation of the utility.
Rapid delivery of back-end solutions for a multitude of applications
Position Summary

We are looking for a Senior Data Engineer to be part of our exciting and growing team. Your primary focus is to build data products to support risk reduction and digital transformation of the company. As a productive member of a motivated group of engineers, product teams, and technical analysts, you will be producing ground-breaking, forward thinking, and revolutionary projects that are industry changing.

What you will get:
The opportunity to contribute to a best-in-class digital organization that ships real products to real users that have a direct impact to company operations and improvements to the safety of California
Extreme leadership support for your development and your day to day success
Autonomy to make decisions in a rapidly growing team
Best in class perks and benefits
Responsibilities:
Build awesome big data products within a fun team where culture is the foundation for success
Provide input on technical feasibility while collaborating with teams to guide features and provide technical know-how
Provide subject matter expertise to design data products and workflows that are robust and fault tolerant
Evolve technical solutions to incorporate new technologies
Debug and optimize complex applications that have real impacts
Build best-in-class cloud-native data products in AWS
Effectively communicate the solution to non-technical stakeholders
Maintain a productive working environment while fostering an open and honest culture of trust, accountability, and humbleness
Be a strong advocate for a culture of quality
Follow an agile development methodology
Qualifications:

Minimum:
BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
5 years of programming analysis experience
Desired:
10 years of IT/Software Engineering experience
7 years of experience working in application development and architecture
5 years of experience developing solution architecture for complex technical problems
Hands on experience working with multiple technologies and platforms
Exposure to enterprise applications and ERP systems (e.g. SAP)
Strong Data Engineering experience specifically including AWS Glue, Python, PySpark and SQL
Experience in building and deploying through CI/CD (e.g. Jenkins)
Working knowledge of Docker and Kubernetes
Experience working in an Agile environment
Experience with developing solutions for data driven applications in the cloud
Experience in developing fault-tolerant applications
Experience with instrumenting applications with health checks and proactive monitoring
Excellent communication and collaboration skills and a strong work ethic
Very strong analytical and problem-solving skills
Experience with GIS
Knowledge of SAP
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Able to further community & elevate team performance
Brings a high-energy and passionate outlook to the role and has strong sense of ownership",3.5,"Pacific Gas And Electric Company
3.5","San Francisco, CA",-1,10000+ Employees,1905,Company - Public,Utilities,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
891,GCP Data Engineer,$105k-$182k (Glassdoor Est.),"GCP Data Engineer

San Jose, CA (OR) RTP, North Carolina

Salary – Open, but please keep it as low as possible

Must Have:

Data Warehousing

Data Modeling

GCP

Snowflake

Responsibilities
Architect & build data pipelines from snowflake to GCP
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into snowflake and GCPdata warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Automation of data pipelines and ensure it’s scalable and performant as well as creating and maintaining service to connect data products.
Hands on, sleeves up development to conduct proof of concepts where required to enable DataOps methodologies. Automating data provisioning activities, etc.
Ensure DataOps and automation initiatives are implemented considering operational requirements and the solutions deployed in production are fit for purpose and ease operational activities.
Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show incremental value.
Collaborate with Architects, DevOps engineers, Data Scientists, Data Analysts, Ops teams, and Product Vendors to drive a common DataOps framework for continuous delivery and quality attainment.
Support any engineering effort it takes to make DSDR useful and adopted by all targeted data science & analytics teams.
Supporting multiple data science teams in getting access to data in Snowflake, & troubleshooting Snowflake platform issues.
Assisting with enabling and executing on cross-functional shared data science team workflow architecture.
WHAT YOU WILL NEED:
8+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS & GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ETL based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill
Job Type: Contract

Schedule:
Day shift
Work Remotely:
Temporarily due to COVID-19",3.1,"SSIT
3.1","San Jose, CA",-1,201 to 500 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
892,Data Frameworks Engineer,$105k-$182k (Glassdoor Est.),"Summary:
We are looking for a savvy Data Frameworks Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Frameworks Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Job Responsibilities:
Create and maintain data pipeline frameworks with the optimal architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Skills:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science. They should also have experience using the following software/tools:
Solid Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with data pipeline and workflow management tools: Airflow.
Experience with AWS cloud services: EC2, EMR
Experience with Vertica
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Education/Experience:
Bachelor's degree in computer science or equivalent training required.
5+ years related experience required.",4.1,"APN Software Services Inc.
4.1","Mountain View, CA",-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
893,Cyber System Administrator-Network Security Engineer Analyst,$105k-$182k (Glassdoor Est.),"Cyber System Administrator-Network Security Engineer Analyst

Company:

The Boeing Company

Job ID:

00000206733

Date Posted:

2020-08-28-07:00

Location:

USA - Seal Beach, CA

Job Description Summary:

Researches, analyzes, and compiles basic technical data for company products and system-level concepts in the projected operational environments to optimize effectiveness over the program lifecycle. Applies systems engineering processes, methodologies and tools to the design of basic system of systems, systems and new product development. Derives and develops basic architectures, functional requirements, refinements and product designs. Assists in the integration of technical, cost, value, risks and specialty engineering considerations into definition of the product. Interfaces with other members of the project or program teams, management, sales and marketing staff, customers and suppliers to meet group, organization and company objectives. Works under general supervision.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:

At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

Boeing Defense, Space & Security (BDS) is looking for a Cyber System Administrator-Network Security Engineer Analyst (Level 2) to join the team at Seal Beach in California. Periodic Frequent Travel is expected, (up to 50%) for short periods of time, based on program needs. This is a 1st shift position.

Boeing Defense, Space & Security Experimental Systems Group (ESG), a unit of Boeing Space and Launch Systems is a flexible unit of The Boeing Company and headquartered in St. Louis. BDS is one of the world's largest defense, space and security businesses specializing in innovative and capabilities-driven customer solutions, and the world's largest and most versatile producer of military aircraft and commercial/civil/government space systems.

Position Responsibilities:
Ensure performance of existing network, maintain configuration of network devices (routers, switches, firewalls) and trouble shoot network as necessary to resolve issues.
Ensure performance of existing terrestrial communications devices and trouble shoot as necessary to resolve issues.
Maintain network documentation.
Add/delete devices on network as required.
Install/replace hardware and cabling as required.
Comply with cybersecurity requirements (RMF) by performing hardening and patching on network devices and PCs, installing & maintaining required monitoring software and providing CONOPS as required.
Regular on-console work as responsible engineer for facility network and terrestrial communications devices.
Work with multi-skill team to accomplish team objectives.
Managing end of service life status on all network and PC hardware and software and developing mitigation plans as needed.
This position requires an active Top Secret U.S. Security Clearance. (A U.S. Security Clearance that has been active in the past 24 months is considered active.) Special Program Access is required pre-start.

Basic Qualifications (Required Skills/Experience):
Associate's degree or related certification and 2 years of related experience or an equivalent combination of technical education and experience.
Preferred Qualifications (Desired Skills/Experience):
Engineering or Computer Science degree
Windows and Linux systems administration experience, Windows 10, RHEL 7
Network & related skills : Cisco router/switch/firewall configuration, Wireshark, Active Directory, NetApp, VM Ware
Familiarity with cybersecurity monitoring software (Splunk, McAfee, etc.)
On-console operational experience
Team player
Translate security policies and procedures into technical architectures
At least 5 years of experience installing, monitoring, and maintaining network security solutions
CISSP, Security+, CEH, CISA or other DOD 8570.01 IAT certification
The following are highly desired:
CCNA, CCNP or other Cisco certification
MCSA, MCSE or other Microsoft certification
RHCE, RHSA or other RedHat Certification
VCP, VCAP or other VMWare certification
NCDA, NCSA or other NetApp certification
Typical Education & Experience:
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master, 6 year's related work experience, etc.).

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Additional Information:

All information provided will be checked and may be verified.

Please apply as soon as possible for this role as recruitment may commence before the end date.

Experience Level:

Individual Contributor - 2

Job Type:

Regular

Job Code:

6K8DI2 (648)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","Seal Beach, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
894,"Senior/Staff Software Engineer, Data Infrastructure",$105k-$182k (Glassdoor Est.),"Senior/Staff Software Engineer, Data Infrastructure

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.4,"Earnin
3.4","Palo Alto, CA",-1,201 to 500 Employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
895,JPSC-8648 - Senior Data Engineer/Architect,$105k-$182k (Glassdoor Est.),"Overview

Job Description
8-10 years of experience in data engineering and working with big data
Experience coming from companies managing big data sets and content.
Qualifications
10 years of hands-on experience in data engineering
4 years of experience leading data engineering teams for AI/ML platforms that serve real-time products
4 years of experience leading data engineering recruitment, mentoring and conducted hands-on training sessions to data scientists, analysts and BI engineers.
2 years of experience collaborating to design standards, championing data engineering culture and developing world-class technical talent.
2 years of experience as a Data Architect for AI/ML platforms and driving engineering roadmap.
Track record of being a hands-on contributor for various data science and engineering projects
Track record of bringing 2 enterprise products to market from conception to deployment
Experience building and delivering a cloud-based analytics solution
Proven track record of meeting aggressive release schedules; demonstrated ability to balance multiple priorities in a complex environment and manage teams to successful project completion.",4.5,"Avani Technology Solutions
4.5","San Mateo, CA",-1,501 to 1000 Employees,2008,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
896,"Senior Business Intelligence Data Engineer, Cash App",$105k-$182k (Glassdoor Est.),"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Job Description

As a Senior BI Engineer at Cash App, you will work alongside analysts, data scientists, engineers, product managers, and business leads to lay the foundation for the analysis of our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, and informing product development. You will build, curate, document, and manage key datasets using ETL to increase the leverage of the entire team.

You will:
Be an expert on the ins and outs of our products, customers, and data
Work directly with data scientists, analysts, and product/business owners to create new data models for the most widely used Cash App events, entities, and processes using ETL
Standardize and enshrine business and product metric definitions in highly curated and optimized datasets using ETL in our data warehouse
Teach and encourage others to self-serve while building tools that make it simpler and faster for them to do so
Evangelize data, analytics, and data model design best practices.
Develop and manage our current set of BI tools and analytics/ETL infrastructure
Qualifications

You have:
A degree in software engineering, computer science or a similar technical field
Experience building complex, scalable ETLs for a variety of different business and product use cases
Technical initiative and a desire to perform and grow as an individual
Technologies we use and teach:
SQL (MySQL, Snowflake, BigQuery, etc.)
Airflow, Tableau
Python, Java
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
897,Software Development Engineer in Test (SDET) – GIS Data Management,$105k-$182k (Glassdoor Est.),"Overview
Are you a geographer, GIS/data analyst, engineer, or computer scientist who has a passion for building great high-quality commercial software? We are looking for individuals with a dedication to quality and software engineering to join our team and help advance Esri's cutting-edge ArcGIS software. Your work will involve discovering innovative ways to improve the products we deliver to our customers worldwide, finding ways to stress our code, implementing new tests, and even developing new test frameworks.This challenging opportunity allows you to leverage your skills to design and build new and innovative software product capabilities. As a member of the ArcGIS Desktop, ArcGIS Pro, and ArcGIS Enterprise teams, you will work with a diverse group of engineers and developers to implement creative solutions to complex problems for creating and managing GIS data. You will also learn best practices from individuals who have decades of combined experience building ArcGIS, a premiere GIS platform.
Requirements
1+ years of software testing experience
1+ years of experience using an application development language, such as C#, Java, C++, or Python
Strong analytical and problem-solving skills
A self-motivated team player with an interest in continuous learning and building software products
Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level
The Company


Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.",3.6,"Esri
3.6","Redlands, CA",-1,1001 to 5000 Employees,1969,Company - Private,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
898,Experienced Payload Systems Engineer Analyst,$105k-$182k (Glassdoor Est.),"Experienced Payload Systems Engineer Analyst

Company:

The Boeing Company

Job ID:

00000194755

Date Posted:

2020-08-17-07:00

Location:

USA - El Segundo, CA

Job Description Summary:

Applies an interdisciplinary, collaborative approach to plan, design, develop and verify a lifecycle balanced system of systems and system solutions. Evaluates customer and /operational needs to define and coordinate system performance requirements, integrate technical parameters and assure compatibility of all physical, functional and program interfaces. Performs various analyses to optimize total system of systems and/or system architecture. Performs analyses for affordability, safety, reliability, maintainability, testability, human systems integration, survivability, vulnerability, susceptibility, system security, regulatory, certification, product assurance and other specialties quality factors into a preferred configuration to ensure mission success. Develops the planning, organization, implementation and monitoring of requirements management processes, tools, risk, issues, opportunity management and technology readiness assessment processes. Resolves cross-functional technical issues.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Relocation:

Relocation is available for eligible candidates, if authorized

Export Control Requirement:

Safety Sensitive:

This is not a safety sensitive position

Contingent Upon Award Program

This position is not contingent upon program award

Job Description Qualifications:
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. From the seabed to outer space, you’ll learn and grow, contributing to work that shapes the world. Find your future with us.

As an Experienced Payload Systems Engineer Analyst (Level 3), you will design and develop state-of-the-art satellite systems for commercial, civil and/or national security programs. You will be part of a highly motivated team that works with domestic or international customers on their latest satellite systems.

Project assignments typically span the complete program life cycle, from internal trades, concept studies and system definition, to satellite development and on-orbit operations.

Candidates will belong to a systems engineering team interacting with customers, suppliers, program management, subsystem engineers, and senior technologists.

Relocation:

This position offers relocation based on candidate eligibility. (Basic relocation is available for internal candidates, based on candidate eligibility.)

Primary Responsibilities:
Support development of satellite payload system architectures
Define satellite payload and ground system requirements
Develop performance analyses for space systems, including: link analysis, signal quality, system capacity, availability, etc.
Develop models and simulations of space systems including space, ground and user segments in support of architecture trade studies
Develop software based analysis and simulation tools using MATLAB and object-oriented software platforms
Perform waveform development and characterization.
This position requires an active/current U.S. Security Clearance with successful completion of a Single Scope Background Investigation (SSBI) by the federal government within the last 5 years (A U.S. Security Clearance that has been active in the past 24 months is considered active.).

Basic (Required) Qualifications
Bachelor's Degree or higher from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry.
3+ years experience using MATLAB.
Experience performing digital payload systems analyses.
Preferred (Desired) Qualifications
Experience developing software applications using C++, Python, Visual Basic.
Knowledge of modeling and simulation techniques for digital systems.
Familiarity with statistical analysis as well as data analytics techniques for large data sets.
Experience with satellite payloads.
Degree and typical experience in engineering classification: Bachelor's and 5 or more years' experience, Master's with 3 or more years' experience or PhD. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.

At Boeing, diversity, equity, and inclusion are enduring company values. We strive to live these values every day not only because it’s the right thing to do, but because our success depends on it. The company’s commitment to diversity and inclusion means providing a work environment for all employees that is welcoming, respectful and equitable, with opportunities for personal and professional development.

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Experience Level:

Individual Contributor - 3

Job Type:

Regular

Job Code:

6K8CI3 (6G1)

Equal Employment Opportunity:

Stay safe from recruitment fraud! The only way to apply for a position at Boeing is via our Careers website.

Learn how to protect yourself from recruitment fraud - Recruitment Fraud Warning

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.

Request an Accommodation - Requesting Interview Accommodations

Applicant Privacy - Applicant Privacy

EEO is the law Poster - EEO is the law

Boeing Policy on EEO - Boeing EEO Policy

Affirmative Action and Harassment - Boeing Affirmative Action and Harassment

Boeing Participates in E – Verify
English - E-Verify (English)
Spanish - E-Verify (Spanish)
Right to Work Statement
English - Right to Work (English)
Spanish - Right to Work (Spanish)",3.7,"Boeing
3.7","El Segundo, CA",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
899,Senior Data Engineer,$105k-$182k (Glassdoor Est.),"Job Description:
Build scalable and reliable data pipelines to support data ingestions (batch/streaming) and transformation from multiple data sources using SQL, AWS, Snowflake, and data integration technologies.
Create low-level design artifacts, including architecture diagrams and mapping specifications.
Work with engineering, technology, and business stakeholders to understand data requirements
Create unit/integration tests and implement automated build and deployment.
Participate in code reviews to ensure standards and best practices.
Work to deploy, monitor, and maintain production systems.
Analyze and organize raw data for ingestion.
Build proof-of-concepts and prototypes as needed to evaluate new tools and technologies
Create and update user stories in backlog
Collaborate with product owner, data analysts, data scientists and architects
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.
To apply please email your resume to fmohammed@rothstaffing.com
Job Snapshot
Employee Type:Contractor
Location:Newport Beach, CA
Job Type:I.T.
Experience:None
Education:None
Date Posted:8/21/2020
Contact: Farooq Mohammed (949) 265-6070
Pay Range: $0.00 - $0.00 Annually",3.0,"ULTIMATE STAFFING SERVICES
3.0","Newport Beach, CA",-1,501 to 1000 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
