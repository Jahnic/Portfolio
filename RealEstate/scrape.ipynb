{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on June 2020\n",
    "author: Jahnic Beck-Joseph\n",
    "url: https://github.com/Jahnic/Portfolio/tree/master/RealEstate\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Scraping through Chrome webdriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting URLs\n",
    "centris_url = \"https://www.centris.ca/en/properties~for-sale?view=Thumbnail\"\n",
    "duproprio = \"https://duproprio.com/en/search/list?search=true&is_for_sale=1&with_builders=1&parent=1&pageNumber=1&sort=-published_at\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Centris:\n",
    "    \"\"\"\n",
    "    This class represents a chrome webdriver object with access to centris.ca.\n",
    "    \n",
    "    Attr:\n",
    "    self.url - starting url for scraping process\n",
    "    self.data - pandas.DataFrame object containing scraped data\n",
    "    self.driver - Chrome webdriver\n",
    "    self.DRIVER_PATH - path to Chrome webdriver\n",
    "    self.old_DOM - web elements found in previous DOM \n",
    "    \"\"\"\n",
    "     \n",
    "    def __init__(self, url=centris_url): \n",
    "        self.url = url\n",
    "        self.data = pd.DataFrame()\n",
    "        # Path to Chromedriver\n",
    "        self.DRIVER_PATH = \"/usr/bin/chromedriver\"\n",
    "        self.driver = None\n",
    "        # Verification of new DOM\n",
    "        self.old_DOM = {\\\n",
    "                        'title' : [],\\\n",
    "                        'address' : [],\\\n",
    "                        'price' : [],\\\n",
    "                        'lat' : [],\\\n",
    "                        'long' : [],\\\n",
    "                        'descriptions' : [],\\\n",
    "                        'neighbourhood_top' : [],\\\n",
    "                        'neighbourhood_mid' : [],\\\n",
    "                        'neighbourhood_buttom' : [],\\\n",
    "                        'demographics_buttons' : [],\\\n",
    "                    }\n",
    "        \n",
    "    def reset_old_DOM(self):\n",
    "        self.old_DOM = {\\\n",
    "                        'title' : [],\\\n",
    "                        'address' : [],\\\n",
    "                        'price' : [],\\\n",
    "                        'lat' : [],\\\n",
    "                        'long' : [],\\\n",
    "                        'descriptions' : [],\\\n",
    "                        'neighbourhood_top' : [],\\\n",
    "                        # 'neighbourhood_mid' : [],\\\n",
    "                        # 'neighbourhood_buttom' : [],\\\n",
    "                        'demographics_buttons' : [],\\\n",
    "                    }\n",
    "\n",
    "    def append_data(self, title, address, price,\\\n",
    "            lat, long, descriptions, neighbourhood_indicators,\\\n",
    "            population, demographics):\n",
    "        \"\"\"Appends new data to existing data frame.\n",
    "        \n",
    "        Args:\n",
    "        title - string\n",
    "        address - string \n",
    "        price - \n",
    "        lat - \n",
    "        long - \n",
    "        descriptions - \n",
    "        neighbourhood_indicators -\n",
    "        population - \n",
    "        demographics - \n",
    "        \"\"\"\n",
    "        new_data = pd.DataFrame({\\\n",
    "                        'title': title,\\\n",
    "                        'address': address,\\\n",
    "                        'price': price,\\\n",
    "                        'lat': lat,\\\n",
    "                        'long': long\\\n",
    "                    }, index=[0])\n",
    "\n",
    "        # DESCRIPTIONS\n",
    "        description_table = pd.DataFrame()\n",
    "        for key in descriptions.keys():\n",
    "            header = key\n",
    "            value = descriptions[header]\n",
    "            description_table[header] = pd.Series(value)\n",
    "        \n",
    "        # POPULATION AND DEMOGRAPHICS\n",
    "        new_data = pd.concat([new_data, neighbourhood_indicators, description_table,\\\n",
    "                             population, demographics], axis=1)\n",
    "\n",
    "        # URL\n",
    "        new_data['url'] = self.url\n",
    "\n",
    "        # LOGGING --------------------------     \n",
    "        #print(new_data)\n",
    "        self.data = self.data.append(new_data, sort=False,\\\n",
    "                                     ignore_index=True)\n",
    "        \n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "        \n",
    "    def start_driver(self):\n",
    "        \"\"\"\n",
    "        Starts and returns Crome webdriver. \n",
    "        The page link in the url attribute \n",
    "        is opened in headless mode.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Activate headless mode for fastest response\n",
    "        options = Options()\n",
    "        options.add_argument('--start-maximized') # open Browser in maximized mode\n",
    "        options.add_argument('--incognito')\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\"); # overcome limited resource problems\n",
    "        \n",
    "        # Start driver with url\n",
    "        self.driver = webdriver.Chrome(executable_path=self.DRIVER_PATH)\n",
    "        self.driver.set_window_size(1120, 1000)\n",
    "        self.driver.get(self.url)\n",
    "\n",
    "    def sort_listings(self):\n",
    "        \"\"\"Sorts listings in webdriver from newest to oldest.\"\"\"\n",
    "        \n",
    "        # Click drop down menu\n",
    "        drop_down = self.driver.find_element_by_xpath(\\\n",
    "                                    \"//button[@id='dropdownSort']\")\n",
    "        drop_down.click()\n",
    "        \n",
    "        # Sort by most recent listings\n",
    "        sort_by = self.driver.find_element_by_xpath(\"//a[@data-option-value='3']\")\n",
    "        sort_by.click()\n",
    "    \n",
    "    def goto_first_page(self):\n",
    "        try:\n",
    "            next_page = self.driver.find_element_by_xpath(\\\n",
    "                                        \"//li[@class='goFirst']\")\n",
    "            next_page.click()\n",
    "        except:\n",
    "            print(\"goFirst button not available\")\n",
    "    \n",
    "    def next_page(self):\n",
    "        try:\n",
    "            next_page = self.driver.find_element_by_xpath(\\\n",
    "                                        \"//li[@class='next']\")\n",
    "            next_page.click()\n",
    "            pass\n",
    "        except:\n",
    "            time.sleep(0.5)\n",
    "            # Try again after waiting 0.5 sec.\n",
    "            try:\n",
    "                next_page = self.driver.find_element_by_xpath(\\\n",
    "                                            \"//li[@class='next']\")\n",
    "                next_page.click()\n",
    "                pass\n",
    "            except:\n",
    "                print(\"Next-page button not found!\")\n",
    "                \n",
    "    def get_page_position(self):\n",
    "        '''Returns the first and last page of the current search.\n",
    "        \n",
    "        Returns\n",
    "        tuple - (current_page, last_page), '''\n",
    "        \n",
    "        pages = self.driver.find_element_by_xpath(\\\n",
    "                                    \"//li[@class='pager-current']\").text.\\\n",
    "                                    split(\" / \")\n",
    "        \n",
    "        current_page, last_page = (int(page.replace(\",\",\"\")) for page in pages)\n",
    "        \n",
    "        return (current_page, last_page)\n",
    "    \n",
    "    def refresh_page(self):\n",
    "        \"Refreshes current webdriver page.\"\n",
    "        self.driver.refresh()\n",
    "        print(\"Page is being refreshed.\")\n",
    "        # Wait until page fully loaded\n",
    "        time.sleep(2)\n",
    "        \n",
    "    def distance(origin, destination):\n",
    "        \"\"\"Calculates distances from latitudinal/longitudinal data using\n",
    "        the haversine formula\"\"\"\n",
    "        lat1, lon1 = origin\n",
    "        lat2, lon2 = destination\n",
    "        radius = 6371 # km\n",
    "        \n",
    "        #Convert from degrees to radians\n",
    "        dlat = math.radians(lat2-lat1)\n",
    "        dlon = math.radians(lon2-lon1)\n",
    "        \n",
    "        # Haversine formula\n",
    "        a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
    "            * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "        d = radius * c\n",
    "\n",
    "        return d\n",
    "                \n",
    "                                                 \n",
    "# Instantiate class object\n",
    "centris = Centris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions need to be outside of the Class. wait_for_xpath() determined the approptiate time to call get_data(). Initially, both fuctions were part of the class object. It seems that after the get_data() call, the driver does not get updated within the class. This leads in some cases to old DOM's being accessed after the browser has already switched to the next page. To circumvent this issue, elements are called outside the class and tried until accessible. This allows the entire new DOM to be loaded before get_data() is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " def wait_for_xpath(xpath: str, old_element):\n",
    "        \"\"\"\n",
    "        Wait until elements in new DOM are accessible.\n",
    "        \n",
    "        Arg.\n",
    "        xpath - xpath to new element \n",
    "        old_element - element at xpath from previous DOM (found in centris.old_DOM)\n",
    "        \n",
    "        Returns:\n",
    "        current_element - the element found in the new DOM at xpath\n",
    "        \"\"\"\n",
    "        \n",
    "        centris_driver = centris.driver\n",
    "        element_at_xpath = []\n",
    "        \n",
    "        # Ensure that the NEW rather than the previous or no DOM is active\n",
    "        # Maximum wait time 10 sec.\n",
    "        time_passed = 0\n",
    "        # ---------------------- LOGGING\n",
    "        print('Waiting for xpath')\n",
    "        while (\\\n",
    "            (element_at_xpath == old_element or  element_at_xpath == [])\\\n",
    "            and (time_passed <= 10)\\\n",
    "              ):\n",
    "            # ------------------------- LOGGING\n",
    "            print(\"Old element:\", element_at_xpath == old_element)\n",
    "            print(\"Empty element:\", element_at_xpath == [])\n",
    "            # Wait for DOM to load\n",
    "            time.sleep(0.2)\n",
    "            time_passed += 0.2\n",
    "            \n",
    "            # Print every 2 seconds\n",
    "            if time_passed%2 == 0:\n",
    "                print(\"Waiting for new DOM...\")\n",
    "            \n",
    "            # Attempt to load new DOM\n",
    "            try: \n",
    "                element_at_xpath = centris_driver.find_elements_by_xpath(xpath)\n",
    "            except: pass\n",
    "        \n",
    "        # After 10 seconds unlikely to load at all -> restart entire process\n",
    "        if time_passed > 10:\n",
    "            print(\"RuntimeError: element not found.\")\n",
    "            centris.refresh_page()\n",
    "            get_data_from_centris()\n",
    "            wait_for_xpath(xpath, old_element)\n",
    "            \n",
    "        return element_at_xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_description(old_DOM):\n",
    "    \"\"\" Requires instantiated centris object. Scrapes and returns\n",
    "    description data: Year build, price, Net area, etc.\"\"\"\n",
    "    \n",
    "    descriptions = wait_for_xpath(\"//div[@class='col-lg-12 description']\",\\\n",
    "                                 old_DOM)\n",
    "    #First three elements not relevant\n",
    "    descriptions_list = descriptions[0].text.split(\"\\n\")[3:]\n",
    "    \n",
    "    #LOGGING------------------------\n",
    "    #print(\"DESCRIPTION:\", descriptions_list)\n",
    "    \n",
    "    # Update old_DOM dictionary with new element for next verification\n",
    "    centris.old_DOM['descriptions'] = descriptions\n",
    "    \n",
    "    return extract_descriptions(descriptions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data_dict found on this part of the page is inconsistent across listings\n",
    "    # The first row may contain the number of rooms, bedrooms and bathrooms without headers or may be missing\n",
    "    # Following rows have heathers with associated values after a line break\n",
    "    # The very last element may be a walking score without header\n",
    "    # Listings without first row may supply first row information in subsequent rows with headers\n",
    "    # Because of these inconsistencies, two seperate extractions need to be implemented: one for\n",
    "    # first row lements (if they exist) and another for subsequent rows\n",
    "\n",
    "def extract_descriptions(descriptions_list):\n",
    "    \"\"\"Takes in data from scrape_description() and returns it \n",
    "    as a dictionary\"\"\"\n",
    "    \n",
    "    # Transformed data\n",
    "    data_dict = {}\n",
    "    # Distinguish between elements from first and subsequent rows if first row exists\n",
    "    first_row = True\n",
    "    # Starting point for second part of transformation\n",
    "    second_row_index = 0\n",
    "    \n",
    "    # First Part\n",
    "    while first_row == True:\n",
    "        for description in descriptions_list:\n",
    "            numeric = re.findall(\"\\(*[0-9]+\\)*\", description) # numbers\n",
    "            text = re.findall(\"[A-Za-z]+[A-Za-z\\s\\-]*\", description) # text after/inbetween numbers \n",
    "\n",
    "            # Initial elements with numeric values correspond to first row\n",
    "            if (numeric != []):\n",
    "                # For each value there must be one text description\n",
    "                if (len(numeric) == len(text)):\n",
    "                    for description,value in zip(text, numeric):\n",
    "                        # Save as column in data_dict\n",
    "                        description_clean = description.replace(\"and\", \"\").strip()\n",
    "                        data_dict[description_clean] = value\n",
    "                    second_row_index += 1 \n",
    "                else:\n",
    "                    print(\"Unequal number of first row keys and values!\")\n",
    "                    print(\"Numbers:\", numeric)\n",
    "                    print(\"Text:\", text)\n",
    "                    break\n",
    "            else:\n",
    "                first_row = False # No numeric information implies header\n",
    "                break\n",
    "    \n",
    "    # Index range of second extraction\n",
    "    # Headers are found at every second index (0,2,4,...)\n",
    "    # Values are one index apart from their corresponding header (1,3,5,...)\n",
    "    list_length = len(descriptions_list)\n",
    "    if (list_length - second_row_index)%2 == 1: # Implies presence of element without header -> Walk Score\n",
    "        walk_score_listed = True\n",
    "        end_point = list_length -1\n",
    "    else:\n",
    "        walk_score_listed = False\n",
    "        end_point = list_length\n",
    "    # Indices corresponding to headers\n",
    "    extraction_range = range(second_row_index, end_point, 2)\n",
    "    \n",
    "    #LOGGING----------------------\n",
    "#     print(\"Second row index:\", second_row_index)\n",
    "#     print(\"Extraction range:\", extraction_range)\n",
    "#     print(\"List:\", descriptions_list)\n",
    "    \n",
    "    # Second Part\n",
    "    for header_index in extraction_range:\n",
    "        # Headers as column names\n",
    "        header = descriptions_list[header_index]\n",
    "        # Values corresponding to headers are found at subsequent indices\n",
    "        information = descriptions_list[header_index + 1] \n",
    "        data_dict[header] = information\n",
    "    \n",
    "    if walk_score_listed:\n",
    "        data_dict[\"walk_score\"] = descriptions_list[-1]\n",
    "        #LOGGING----------------------\n",
    "        #print(\"Walk Score:\", descriptions_list[-1])\n",
    "        \n",
    "    #LOGGING--------------------------\n",
    "#     print(\"Descriptions:\", data_dict)\n",
    "        \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_neighbourhood(old_DOM_top, old_DOM_mid, old_DOM_buttom):\n",
    "#     \"\"\" Scrapes and returns a list of ratings \n",
    "#     between 0-10 for a set of neighborhood indicators\n",
    "#     such as groceries, parks, noise, etc.)\n",
    "#     \"\"\"\n",
    "#     driver = centris.driver\n",
    "    \n",
    "#     # Extract elements from top section of scrollable list\n",
    "#     neighbourhood_top = wait_for_xpath(\\\n",
    "#                             \"//div[@class='ll-list ps ps--active-y']\",\\\n",
    "#                             old_DOM_top)\n",
    "#     # Split into indicators and ranking values\n",
    "#     top = [x.text for x in neighbourhood_top][0].split(\"\\n\")\n",
    "    \n",
    "#     # LOGGING----------------------\n",
    "#     print(\"Top neighbourhood:\", top)\n",
    "    \n",
    "#     # Extract middle section - only one element\n",
    "#     # Scroll and activate scrollable bar container\n",
    "#     scrollable_bar = driver.find_element_by_xpath(\\\n",
    "#                                             \"//div[@class='ps__thumb-y']\")\n",
    "#     ActionChains(driver).\\\n",
    "#         move_to_element(scrollable_bar).\\\n",
    "#         send_keys(Keys.PAGE_DOWN).\\\n",
    "#         click(scrollable_bar).perform()\n",
    "\n",
    "#     # Elements from buttom of scrollable list\n",
    "#     neighbourhood_mid = wait_for_xpath(\\\n",
    "#                             \"//div[@class='ll-list ps ps--active-y']\",\\\n",
    "#                             old_DOM_mid)\n",
    "#     # Split into indicators and ranking values\n",
    "    \n",
    "#     # LOGGING----------------------\n",
    "#     print(\"Neighbourhoud mid section:\", neighbourhood_mid)\n",
    "    \n",
    "#     middle = [x.text for x in neighbourhood_mid][0].split(\"\\n\")\n",
    "    \n",
    "#     # Extract buttom section\n",
    "#     # Scroll and load remaining elements\n",
    "# #     scrollable_bar = driver.find_element_by_xpath(\\\n",
    "# #                                             \"//div[@class='ps__thumb-y']\")\n",
    "#     ActionChains(driver).\\\n",
    "#         move_to_element(scrollable_bar).\\\n",
    "#         send_keys(Keys.PAGE_DOWN).\\\n",
    "#         click(scrollable_bar).perform()\n",
    "    \n",
    "#     # Elements from buttom of scrollable list\n",
    "#     neighbourhood_buttom = wait_for_xpath(\\\n",
    "#                             \"//div[@class='ll-list ps ps--active-y']\",\\\n",
    "#                             old_DOM_buttom)\n",
    "#     # Split into indicators and ranking values\n",
    "#     buttom = [x.text for x in neighbourhood_buttom][0].split(\"\\n\")\n",
    "    \n",
    "#     # LOGGING----------------------\n",
    "#     print(\"Buttom neighbourhood:\", buttom)\n",
    "    \n",
    "#     # Unite all three sections by storing tuples of indicator names and corresponding values\n",
    "#     united_list = []\n",
    "#     list_length = len(top)\n",
    "#     for i in range(0, list_length, 2):\n",
    "#         united_list.append((top[i], top[i+1]))\n",
    "#         united_list.append((middle[i], middle[i+1]))\n",
    "#         united_list.append((buttom[i], buttom[i+1]))\n",
    "    \n",
    "#     # Create set of unique tuples\n",
    "#     neighbourhood_indicators = set(united_list)\n",
    "    \n",
    "#     # LOGGING----------------------\n",
    "#     print(\"Number of neighborhood indicators: \", len(neighbourhood_indicators))\n",
    "#     print(\"UNITED:\", united_list)\n",
    "#     print(\"SET:\", neighbourhood_indicators)\n",
    "    \n",
    "#     # Verify size and extract information as list\n",
    "#     # If size unexpected, refresh page and restart process\n",
    "#     if len(neighbourhood_indicators) < 8:\n",
    "#             centris.refresh_page()\n",
    "#             scrape_neighbourhood(old_DOM_top, old_DOM_buttom)\n",
    "\n",
    "#     # Update old_DOM dictionary with new elements for next verification\n",
    "#     centris.old_DOM['neighbourhood_top'] = neighbourhood_top\n",
    "#     centris.old_DOM['neighbourhood_mid'] = neighbourhood_mid\n",
    "#     centris.old_DOM['neighbourhood_buttom'] = neighbourhood_buttom\n",
    "\n",
    "#     return extract_neighbourhood_indicators(neighbourhood_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_neighbourhood(old_DOM_top):\n",
    "    \"\"\" Scrapes and returns a list of ratings \n",
    "    between 0-10 for a set of neighborhood indicators\n",
    "    such as groceries, parks, noise, etc.)\n",
    "    \"\"\"\n",
    "    driver = centris.driver\n",
    "    \n",
    "    # Extract elements from top section of scrollable list\n",
    "    neighbourhood_top = wait_for_xpath(\\\n",
    "                            \"//ul[@class='ll-module__list']\",\\\n",
    "                            old_DOM_top)\n",
    "    print('TEST:', neighbourhood_top[0])\n",
    "    # Split into indicators and ranking values\n",
    "    top = [x.text for x in neighbourhood_top][0].split(\"\\n\")\n",
    "    \n",
    "    # Create set of unique tuples\n",
    "    neighbourhood_indicators = list(top)\n",
    "    \n",
    "    # LOGGING----------------------\n",
    "    print(\"Number of neighborhood indicators: \", len(neighbourhood_indicators))\n",
    "    print(\"SET:\", neighbourhood_indicators)\n",
    "    \n",
    "    # Verify size and extract information as list\n",
    "    # If size unexpected, refresh page and restart process\n",
    "    if len(neighbourhood_indicators) < 8:\n",
    "            centris.refresh_page()\n",
    "            scrape_neighbourhood(old_DOM_top, old_DOM_buttom)\n",
    "\n",
    "    # Update old_DOM dictionary with new elements for next verification\n",
    "    centris.old_DOM['neighbourhood_top'] = neighbourhood_top\n",
    "    # return indicators\n",
    "    return extract_neighbourhood_indicators(neighbourhood_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_neighbourhood_indicators(indicators):\n",
    "    \"\"\"Takes in neighbourhood data from scrape_neighbourhood() and returns it \n",
    "    in tabular form as a DataFrame object\"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    n_indicators = len(indicators)\n",
    "    for index in range(0, n_indicators, 2):\n",
    "        header = indicators[index]\n",
    "        value = indicators[index + 1]\n",
    "        data[header] = pd.Series(value)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_population():\n",
    "    \"\"\"Scrapes and returns population summary data (density, variation etc.)\"\"\"\n",
    "    population_summaries =  centris.driver.find_element_by_id('info')\n",
    "    population_summaries_list = population_summaries\\\n",
    "                        .text.split(\"\\n\")\n",
    "    \n",
    "    # LOGGING-----------------------\n",
    "    #print(\"Population:\", population_summaries_list)\n",
    "    \n",
    "    return extract_population(population_summaries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_population(population):\n",
    "    \"\"\"Takes in population data from scrape_population() and returns it \n",
    "    in tabular form as a DataFrame object\"\"\"\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    for info in population:\n",
    "        units_removed =  info.replace(\"hab/km2\", \"\").strip()\n",
    "        # Numeric data\n",
    "        numeric = re.findall(\"[0-9]+[0-9,]*\", units_removed)\n",
    "        numeric_clean = numeric[-1].replace(\",\",\"\")\n",
    "\n",
    "        # Text data for column names\n",
    "        header = re.findall(\"[a-zA-Z\\s]+\", units_removed)\n",
    "        header_clean = header[0]\n",
    "        # Add numeric data to header excluding the value at index -1\n",
    "        for numeric_head_data in numeric[:-1]:\n",
    "            header_clean = header_clean + str(numeric_head_data) + \" \"\n",
    "\n",
    "        data[header_clean] = pd.Series(numeric_clean).astype(\"int\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_demographics(old_DOM):\n",
    "    \"\"\"Scrapes and return demographic data found in a clickable list\"\"\"\n",
    "    \n",
    "    driver = centris.driver\n",
    "    # Clickable list containing demographic data\n",
    "    menu = driver.find_element_by_id(\"menu\")\n",
    "    # Load menu by moving browser to it\n",
    "    ActionChains(driver).\\\n",
    "    move_to_element(menu).perform()\n",
    "    \n",
    "    #Buttons to access demographics data (education, incomes, etc.)\n",
    "    demographics_buttons = wait_for_xpath(\\\n",
    "                        \"//div[@class='centrisSocioDemobutton']\",\\\n",
    "                                                 old_DOM)\n",
    "\n",
    "    # LOGGING------------------------\n",
    "    # print(\"DEMO. BUTTONS:\", demographics_buttons)\n",
    "\n",
    "    # First entry on clickable demographics list (pre-selected)\n",
    "    demographics = []\n",
    "\n",
    "    # Click buttons to access next demogrpahics elements\n",
    "    for button in demographics_buttons:\n",
    "        try: \n",
    "            button.click()\n",
    "        except: \n",
    "            print(\"Demographics button missing!\")\n",
    "            # Reattempt loading buttons\n",
    "            centris.refresh_page()\n",
    "            ActionChains(driver).\\\n",
    "            move_to_element(menu).\\\n",
    "            perform()\n",
    "            time.sleep(2) # extra time to load\n",
    "            demographics_buttons = wait_for_xpath(\\\n",
    "                        \"//div[@class='centrisSocioDemobutton']\",\\\n",
    "                                                 old_DOM)\n",
    "            \n",
    "        # Get and append data after button click\n",
    "        demographic_data = driver.find_element_by_class_name(\\\n",
    "                         \"socioDemoLabel\")\n",
    "        demographics.append(demographic_data.text)\n",
    "    \n",
    "    # Split each demographic component into separate list\n",
    "    # Example: splits \"Occupation\" data into -> [\"Owners\", \"35%\", \"Renters\", \"65%\"]\n",
    "    demographics = [demo.split(\"\\n\") for demo in demographics]\n",
    "    \n",
    "    #LOGGING------------------------\n",
    "#     print(\"DEMO. DATA:\", demographics)\n",
    "#     print(\"-\"*50)\n",
    "    \n",
    "    # Update old_DOM dictionary with new elements for next verification\n",
    "    centris.old_DOM['demographics_buttons'] = demographics_buttons\n",
    "    return extract_demographics(demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_demographics(demographics):\n",
    "    \"\"\"Takes in demographic data from extract_demographics() and returns it \n",
    "    in tabular form as a DataFrame object\"\"\"\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    # ------------------------ LOGGING\n",
    "    print(demographics)\n",
    "    for demographic in demographics:\n",
    "        # Remove empty stings from splitting double line breaks \\n\\n\n",
    "        removed_empty_strings = [x for x in demographic if x != \"\"]\n",
    "        demographic = removed_empty_strings\n",
    "        # Format of demographic: [header, value, header, value, ...]\n",
    "        header_index = range(0, len(demographic), 2)\n",
    "        for i in header_index:\n",
    "            header = demographic[i] + \" (%)\" # add units to column names\n",
    "            value = demographic[i+1].replace(\"%\", \"\") # remove units from values \n",
    "            data[header] = pd.Series(value).astype(\"int\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_centris():\n",
    "        \"\"\"\n",
    "        Requires instantiate Centris object. Scrapes information from the\n",
    "        webdriver and appends it to the Centris object.\n",
    "        \"\"\"\n",
    "        driver = centris.driver\n",
    "        old_DOM = centris.old_DOM\n",
    "        \n",
    "        # Data from headers\n",
    "        print(\"Start scraping new page...\")\n",
    "        title = wait_for_xpath(\"//span[@data-id='PageTitle']\", old_DOM['title'])\n",
    "        address = wait_for_xpath(\"//h2[@itemprop='address']\", old_DOM['address'])\n",
    "        price = wait_for_xpath(\"//span[@itemprop='price']\", old_DOM['price'])\n",
    "        lat = wait_for_xpath(\"//meta[@itemprop='latitude']\", old_DOM['lat'])\n",
    "        lon = wait_for_xpath(\"//meta[@itemprop='longitude']\", old_DOM['long'])\n",
    "\n",
    "        # Save new elements as old DOM\n",
    "        centris.old_DOM['title'] = title\n",
    "        centris.old_DOM['address'] = address\n",
    "        centris.old_DOM['lat'] = lat\n",
    "        centris.old_DOM['long'] = lon\n",
    "        \n",
    "        # Scrape remaining elements and store in dataframe\n",
    "        print('Start TESTING')\n",
    "        descriptions = scrape_description(old_DOM['descriptions'])\n",
    "        print('Descriptions:', descriptions)\n",
    "        neighbourhood_indicators = scrape_neighbourhood(old_DOM['neighbourhood_top'],\\\n",
    "                                                        # old_DOM['neighbourhood_mid'],\\\n",
    "                                                        # old_DOM['neighbourhood_buttom']\n",
    "                                                            )\n",
    "        print('Neighborhood')\n",
    "        population = scrape_population()\n",
    "        demographics = scrape_demographics(old_DOM['demographics_buttons'])\n",
    "                \n",
    "        # Unify data in single dataframe and append to results table\n",
    "        centris.append_data(\n",
    "            title[0].text,\\\n",
    "            address[0].text,\\\n",
    "            price[0].text,\\\n",
    "            lat[0].get_attribute(\"content\"),\\\n",
    "            lon[0].get_attribute(\"content\"),\\\n",
    "            descriptions,\\\n",
    "            neighbourhood_indicators,\\\n",
    "            population,\\\n",
    "            demographics\\\n",
    "        )\n",
    "        \n",
    "        # LOGGING--------------------------\n",
    "        # print(\"GET DATA: DESCRIPTIONS:\", descriptions)\n",
    "        \n",
    "        # Return to top of page, to access next-page button\n",
    "        body = driver.find_element_by_tag_name(\"body\")\n",
    "        body.send_keys(Keys.HOME)\n",
    "#         for i in range(7):\n",
    "#             body.send_keys(Keys.PAGE_UP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Execution time: 7.196816682815552\n"
     ]
    }
   ],
   "source": [
    "# Create driver object\n",
    "centris = Centris()\n",
    "start = time.time()\n",
    "centris.start_driver()\n",
    "centris.sort_listings()\n",
    "print(\"Execution time:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the next cell, search for the region(s) you want to scrape in the webdriver window.\n",
    "This is not required but will narrow results and reduce runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not include already scraped listings\n",
    "already_scraped = pd.read_csv('data/centris_montreal_complete.csv')\n",
    "already_scraped = set(already_scraped.address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scraping initiated.\n",
      "Total number of pages to scrape: 39268\n",
      "Estimated runtime: 104.71 hours\n",
      "==================================================\n",
      "==================================================\n",
      "Page: 1\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Start scraping new page...\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: True\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Start TESTING\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Descriptions: {'rooms': '12', 'bedrooms': '3', 'in basement': '(1', 'bathroom': '1', 'powder room': '1', 'Building style': 'Bungalow, Detached', 'Year built': '1998', 'Lot area': '4,921 sqft', 'Parking (total)': 'Driveway (2), Garage (1)', 'Pool': 'Heated, Inground', 'Fireplace/Stove': 'Wood stove', 'Additional features': 'Basement 6 feet or +', 'walk_score': '32'}\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "TEST: <selenium.webdriver.remote.webelement.WebElement (session=\"a9b0f2e110eea7ec2f5d18699b6c1677\", element=\"393207bc-1268-4f26-9854-3083f7852be5\")>\n",
      "Number of neighborhood indicators:  32\n",
      "SET: ['Car friendly', '9', 'Quiet', '8', 'Grocery stores', '8', 'Elementary schools', '7', 'High schools', '7', 'Parks', '7', 'Daycares', '5', 'Transit friendly', '4', 'Pedestrian friendly', '4', 'Greenery', '3', 'Restaurants', '3', 'Shopping', '3', 'Nightlife', '2', 'Coffee Shops', '2', 'Vibrancy', '1', 'Historic', '0']\n",
      "Neighborhood\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "[['Less than $50,000', '19%', '', 'Between $50,000 and $80,000', '20%', '', 'Between $80,000 and $100,000', '13%', '', 'Between $100,000 and $150,000', '25%', '', 'More than $150,000', '22%'], ['1-person households', '20%', '', '2-person households', '35%', '', '3-person households', '17%', '', '4-person households', '20%', '', '5-person or more households', '8%'], ['Couples without children at home', '36%', '', 'Couples with children at home', '48%', '', 'Single-parent families', '16%'], ['Owners', '84%', '', 'Renters', '16%'], ['Before 1960', '2%', '', 'Between 1961 and 1980', '36%', '', 'Between 1981 and 1990', '21%', '', 'Between 1991 and 2000', '23%', '', 'Between 2001 and 2010', '14%', '', 'Between 2011 and 2016', '3%'], ['Single-family homes', '69%', '', 'Semi-detached or row houses', '7%', '', 'Buildings with less than 5 floors', '24%', '', 'Buildings with 5 or more floors', '0%', '', 'Mobile homes', '0%'], ['University', '28%', '', 'College', '20%', '', 'Secondary (high) school', '22%', '', 'Apprentice or trade school diploma', '15%', '', 'No diploma', '14%'], ['Non-immigrant population', '96%', '', 'Immigrant population', '4%'], ['French', '97%', '', 'English', '1%', '', 'Others languages', '2%']]\n",
      "==================================================\n",
      "Page: 2\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Start scraping new page...\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: True\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Start TESTING\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Descriptions: {'rooms': '12', 'bedrooms': '3', 'bathroom': '1', 'powder room': '1', 'Building style': 'Two or more storey, Detached', 'Year built': '2008', 'Lot area': '8,665 sqft', 'Parking (total)': 'Driveway (4), Garage (1)', 'Additional features': 'Basement 6 feet or +'}\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "Old element: True\n",
      "Empty element: False\n",
      "RuntimeError: element not found.\n",
      "Page is being refreshed.\n",
      "Start scraping new page...\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: True\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Start TESTING\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "Descriptions: {'rooms': '12', 'bedrooms': '3', 'bathroom': '1', 'powder room': '1', 'Building style': 'Two or more storey, Detached', 'Year built': '2008', 'Lot area': '8,665 sqft', 'Parking (total)': 'Driveway (4), Garage (1)', 'Additional features': 'Basement 6 feet or +'}\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "TEST: <selenium.webdriver.remote.webelement.WebElement (session=\"a9b0f2e110eea7ec2f5d18699b6c1677\", element=\"e7a961eb-ff52-4b53-bb5d-637c0c8384e3\")>\n",
      "Number of neighborhood indicators:  32\n",
      "SET: ['Quiet', '10', 'Car friendly', '9', 'Elementary schools', '7', 'Parks', '5', 'Greenery', '4', 'Transit friendly', '2', 'Daycares', '2', 'Pedestrian friendly', '2', 'Restaurants', '2', 'Grocery stores', '1', 'Vibrancy', '1', 'Coffee Shops', '1', 'Shopping', '1', 'High schools', '0', 'Historic', '0', 'Nightlife', '0']\n",
      "Neighborhood\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "[['Less than $50,000', '17%', '', 'Between $50,000 and $80,000', '17%', '', 'Between $80,000 and $100,000', '11%', '', 'Between $100,000 and $150,000', '26%', '', 'More than $150,000', '28%'], ['1-person households', '13%', '', '2-person households', '33%', '', '3-person households', '18%', '', '4-person households', '24%', '', '5-person or more households', '12%'], ['Couples without children at home', '35%', '', 'Couples with children at home', '55%', '', 'Single-parent families', '10%'], ['Owners', '92%', '', 'Renters', '8%'], ['Before 1960', '4%', '', 'Between 1961 and 1980', '14%', '', 'Between 1981 and 1990', '24%', '', 'Between 1991 and 2000', '20%', '', 'Between 2001 and 2010', '32%', '', 'Between 2011 and 2016', '5%'], ['Single-family homes', '94%', '', 'Semi-detached or row houses', '1%', '', 'Buildings with less than 5 floors', '4%', '', 'Buildings with 5 or more floors', '0%', '', 'Mobile homes', '0%'], ['University', '29%', '', 'College', '23%', '', 'Secondary (high) school', '24%', '', 'Apprentice or trade school diploma', '12%', '', 'No diploma', '12%'], ['Non-immigrant population', '90%', '', 'Immigrant population', '10%'], ['French', '51%', '', 'English', '47%', '', 'Others languages', '2%']]\n",
      "Waiting for xpath\n",
      "Old element: False\n",
      "Empty element: True\n",
      "TEST: <selenium.webdriver.remote.webelement.WebElement (session=\"a9b0f2e110eea7ec2f5d18699b6c1677\", element=\"393207bc-1268-4f26-9854-3083f7852be5\")>\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=87.0.4280.66)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-4e045c12c97f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcurrent_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait_for_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"//h2[@itemprop='address']\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_DOM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurrent_address\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malready_scraped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mget_data_from_centris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Retrieve data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'was already scraped!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-23ac5d3e4cd1>\u001b[0m in \u001b[0;36mget_data_from_centris\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdescriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_DOM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'descriptions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Descriptions:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         neighbourhood_indicators = scrape_neighbourhood(old_DOM['neighbourhood_top'],\\\n\u001b[0m\u001b[1;32m     28\u001b[0m                                                         \u001b[0;31m# old_DOM['neighbourhood_mid'],\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                         \u001b[0;31m# old_DOM['neighbourhood_buttom']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-bebdebd20bdc>\u001b[0m in \u001b[0;36mscrape_neighbourhood\u001b[0;34m(old_DOM_top)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TEST:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbourhood_top\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Split into indicators and ranking values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbourhood_top\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Create set of unique tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-bebdebd20bdc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TEST:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbourhood_top\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Split into indicators and ranking values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbourhood_top\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Create set of unique tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m\"\"\"The text of the element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_ELEMENT_TEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=87.0.4280.66)\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "current_page, last_page = centris.get_page_position() \n",
    "pages_to_scrape = last_page - current_page + 1 # in case scraping is interupted\n",
    "one_to_100 = range(1,100) # to print message each 1% completion\n",
    "\n",
    "print(\"Scraping initiated.\")\n",
    "print(\"Total number of pages to scrape:\", pages_to_scrape)\n",
    "print(\"Estimated runtime:\", round(pages_to_scrape*((9.6)/(60*60)), 2), \"hours\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i in range(pages_to_scrape):\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"Page:\", i+1)\n",
    "    time_passed = 0 # to exit while loop after 10 seconds\n",
    "    \n",
    "    #Refresh every 20 pages to clear memory build-up\n",
    "    if (i+1)%20 == 0:\n",
    "        print(\"Clearing memory\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        # Each refresh frees some memory. Four seem to work best.\n",
    "        for i in range(4):\n",
    "            centris.refresh_page()\n",
    "            # Extra time for last refresh\n",
    "            # Ensures that DOM is fully loaded\n",
    "            if i == 3:\n",
    "                time.sleep(2)\n",
    "\n",
    "    # Check listing was already scraped\n",
    "    current_address = wait_for_xpath(\"//h2[@itemprop='address']\", centris.old_DOM['address'])[0]           \n",
    "    if current_address.text not in already_scraped:          \n",
    "        get_data_from_centris() # Retrieve data\n",
    "    else:\n",
    "        print(current_address, 'was already scraped!') \n",
    "    \n",
    "    # Short delay for chrome to respond to PAGE_UP command\n",
    "    time.sleep(0.5)\n",
    "    centris.next_page()\n",
    "    \n",
    "    # Percent completed of scraping \n",
    "    percent_complete = round(100*((i)/last_page),2)      \n",
    "    # Print after every 1% mark\n",
    "    if percent_complete in one_to_100:\n",
    "        execution_time = (time.time() - start)/(i+1) # seconds per page\n",
    "        print(percent_complete, \"%\", \"completed\")\n",
    "        print(\"Average execution time per page:\", round(execution_time, 2), \"sec.\")\n",
    "        print(\"Estimated remaining runtime:\", round(\\\n",
    "                                (total_pages - (i+1))\\\n",
    "                                *(execution_time\\\n",
    "                                /(60*60)), 1\\\n",
    "                                ), \"hours <\", \"-\"*50)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "\n",
    "print(\"Total runtime:\", execution_time/(60*60), \"hours\")\n",
    "centris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "# centris.data.to_csv(\"centris_montreal_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}