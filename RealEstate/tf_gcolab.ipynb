{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_gcolab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0D9c1N1cHFu"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "import matplotlib\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# Saves model as file\n",
        "import pickle\n",
        "# Verify computational environment\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "# Outlier detection\n",
        "from sklearn.ensemble import IsolationForest"
      ],
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRWjoIT1-hlm"
      },
      "source": [
        "# Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW8t0RFlfNZT",
        "outputId": "e9ba94d8-9779-47fb-9ce2-95f9af5865b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import data to google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwh7_zVjcKWS",
        "outputId": "1eff5254-7228-47bb-ed73-7a3b7cd928f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "# Verify GPU\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 17839670704884365514, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 14100077527878823060\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 8365057245607729415\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14640891840\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 10385897261651684216\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k6lk1Z-cXIU",
        "outputId": "4e5db9a4-9b7b-4f74-a02c-c6fdd4158126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# Load data\n",
        "path = \"/content/gdrive/My Drive/Colab Notebooks/data/complete_data.csv\"\n",
        "data = pd.read_csv(path).iloc[:, 4: ]\n",
        "data.head()"
      ],
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>restaurants</th>\n",
              "      <th>shopping</th>\n",
              "      <th>vibrant</th>\n",
              "      <th>cycling_friendly</th>\n",
              "      <th>car_friendly</th>\n",
              "      <th>historic</th>\n",
              "      <th>quiet</th>\n",
              "      <th>elementary_schools</th>\n",
              "      <th>high_schools</th>\n",
              "      <th>parks</th>\n",
              "      <th>nightlife</th>\n",
              "      <th>groceries</th>\n",
              "      <th>daycares</th>\n",
              "      <th>pedestrian_friendly</th>\n",
              "      <th>cafes</th>\n",
              "      <th>transit_friendly</th>\n",
              "      <th>greenery</th>\n",
              "      <th>year_built</th>\n",
              "      <th>population_2016_</th>\n",
              "      <th>population_variation_between_2011_2016_</th>\n",
              "      <th>population_density_</th>\n",
              "      <th>unemployment_rate_2016_</th>\n",
              "      <th>less_than_$50,000_(%)</th>\n",
              "      <th>between_$50,000_and_$80,000_(%)</th>\n",
              "      <th>between_$80,000_and_$100,000_(%)</th>\n",
              "      <th>between_$100,000_and_$150,000_(%)</th>\n",
              "      <th>more_than_$150,000_(%)</th>\n",
              "      <th>1-person_households_(%)</th>\n",
              "      <th>2-person_households_(%)</th>\n",
              "      <th>3-person_households_(%)</th>\n",
              "      <th>4-person_households_(%)</th>\n",
              "      <th>5-person_or_more_households_(%)</th>\n",
              "      <th>couples_without_children_at_home_(%)</th>\n",
              "      <th>couples_with_children_at_home_(%)</th>\n",
              "      <th>single-parent_families_(%)</th>\n",
              "      <th>owners_(%)</th>\n",
              "      <th>renters_(%)</th>\n",
              "      <th>before_1960_(%)</th>\n",
              "      <th>between_1961_and_1980_(%)</th>\n",
              "      <th>between_1981_and_1990_(%)</th>\n",
              "      <th>between_1991_and_2000_(%)</th>\n",
              "      <th>between_2001_and_2010_(%)</th>\n",
              "      <th>between_2011_and_2016_(%)</th>\n",
              "      <th>single-family_homes_(%)</th>\n",
              "      <th>semi-detached_or_row_houses_(%)</th>\n",
              "      <th>buildings_with_less_than_5_floors_(%)</th>\n",
              "      <th>buildings_with_5_or_more_floors_(%)</th>\n",
              "      <th>mobile_homes_(%)</th>\n",
              "      <th>university_(%)</th>\n",
              "      <th>college_(%)</th>\n",
              "      <th>secondary_(high)_school_(%)</th>\n",
              "      <th>apprentice_or_trade_school_diploma_(%)</th>\n",
              "      <th>no_diploma_(%)</th>\n",
              "      <th>non-immigrant_population_(%)</th>\n",
              "      <th>immigrant_population_(%)</th>\n",
              "      <th>french_(%)</th>\n",
              "      <th>english_(%)</th>\n",
              "      <th>others_languages_(%)</th>\n",
              "      <th>walk_score</th>\n",
              "      <th>rooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>basement_bedroom</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>powder_rooms</th>\n",
              "      <th>total_area</th>\n",
              "      <th>new_area_from_price</th>\n",
              "      <th>new_area_from_rooms</th>\n",
              "      <th>river_proximity</th>\n",
              "      <th>has_pool</th>\n",
              "      <th>n_parking</th>\n",
              "      <th>has_garage</th>\n",
              "      <th>is_devided</th>\n",
              "      <th>mr_distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>409000</td>\n",
              "      <td>45.5</td>\n",
              "      <td>-73.6</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>69229</td>\n",
              "      <td>5</td>\n",
              "      <td>7181</td>\n",
              "      <td>8</td>\n",
              "      <td>45</td>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>42</td>\n",
              "      <td>34</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>36</td>\n",
              "      <td>18</td>\n",
              "      <td>37</td>\n",
              "      <td>63</td>\n",
              "      <td>46</td>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>69</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>75</td>\n",
              "      <td>25</td>\n",
              "      <td>64.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>5.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>680000</td>\n",
              "      <td>45.4</td>\n",
              "      <td>-73.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>69229</td>\n",
              "      <td>5</td>\n",
              "      <td>7181</td>\n",
              "      <td>8</td>\n",
              "      <td>45</td>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>42</td>\n",
              "      <td>34</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>36</td>\n",
              "      <td>18</td>\n",
              "      <td>37</td>\n",
              "      <td>63</td>\n",
              "      <td>46</td>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>69</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>75</td>\n",
              "      <td>25</td>\n",
              "      <td>64.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1249.0</td>\n",
              "      <td>1249.0</td>\n",
              "      <td>1249.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>283000</td>\n",
              "      <td>45.5</td>\n",
              "      <td>-73.6</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2007.0</td>\n",
              "      <td>134245</td>\n",
              "      <td>6</td>\n",
              "      <td>5545</td>\n",
              "      <td>10</td>\n",
              "      <td>49</td>\n",
              "      <td>23</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>41</td>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>34</td>\n",
              "      <td>46</td>\n",
              "      <td>20</td>\n",
              "      <td>39</td>\n",
              "      <td>61</td>\n",
              "      <td>37</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>73</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>16</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>59</td>\n",
              "      <td>41</td>\n",
              "      <td>65.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>848.0</td>\n",
              "      <td>848.0</td>\n",
              "      <td>848.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>5.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>339000</td>\n",
              "      <td>45.5</td>\n",
              "      <td>-73.6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>80153</td>\n",
              "      <td>9</td>\n",
              "      <td>5070</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>32</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>44</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>35</td>\n",
              "      <td>65</td>\n",
              "      <td>43</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>71</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>74</td>\n",
              "      <td>26</td>\n",
              "      <td>59.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>621.0</td>\n",
              "      <td>621.0</td>\n",
              "      <td>621.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>3.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>177800</td>\n",
              "      <td>45.6</td>\n",
              "      <td>-73.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>42796</td>\n",
              "      <td>2</td>\n",
              "      <td>3103</td>\n",
              "      <td>10</td>\n",
              "      <td>45</td>\n",
              "      <td>26</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>38</td>\n",
              "      <td>31</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>38</td>\n",
              "      <td>41</td>\n",
              "      <td>21</td>\n",
              "      <td>44</td>\n",
              "      <td>56</td>\n",
              "      <td>15</td>\n",
              "      <td>49</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>65</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>66</td>\n",
              "      <td>34</td>\n",
              "      <td>76.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>11.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    price  lat  long  ...  has_garage  is_devided  mr_distance\n",
              "0  409000 45.5 -73.6  ...        True           1          5.7\n",
              "1  680000 45.4 -73.6  ...        True           1          7.1\n",
              "2  283000 45.5 -73.6  ...        True           1          5.2\n",
              "3  339000 45.5 -73.6  ...       False           1          3.3\n",
              "4  177800 45.6 -73.6  ...       False           1         11.3\n",
              "\n",
              "[5 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 460
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv3fPw1Pryxe"
      },
      "source": [
        "# Transform is_devided into boolean feature\n",
        "data.is_devided = data.is_devided.astype('bool')"
      ],
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nuNb6Uvemew"
      },
      "source": [
        "# # Drop redundant data\n",
        "# redundant = ['more_than_$150,000_(%)', '5-person_or_more_households_(%)', \n",
        "#             'single-parent_families_(%)', 'renters_(%)', 'before_1960_(%)',\n",
        "#             'mobile_homes_(%)', 'university_(%)', 'non-immigrant_population_(%)',\n",
        "#             'french_(%)', 'new_area_from_price', 'new_area_from_rooms',\n",
        "#             'basement_bedroom']\n",
        "# data.drop(redundant, axis=1, inplace=True)\n",
        "\n",
        "# Drop demographics data\n",
        "demographics = ['less_than_$50,000_(%)', 'between_$50,000_and_$80,000_(%)', \n",
        "                'between_$80,000_and_$100,000_(%)', 'between_$100,000_and_$150,000_(%)',\n",
        "                'more_than_$150,000_(%)', '1-person_households_(%)', \n",
        "                '2-person_households_(%)', '3-person_households_(%)', \n",
        "                '4-person_households_(%)', '5-person_or_more_households_(%)', \n",
        "                'couples_without_children_at_home_(%)', 'couples_with_children_at_home_(%)',\n",
        "                'single-parent_families_(%)', 'owners_(%)', 'renters_(%)',\n",
        "                'before_1960_(%)', 'between_1961_and_1980_(%)',\n",
        "                'between_1981_and_1990_(%)', 'between_1991_and_2000_(%)',\n",
        "                'between_2001_and_2010_(%)', 'between_2011_and_2016_(%)',\n",
        "                'single-family_homes_(%)', 'semi-detached_or_row_houses_(%)',\n",
        "                'buildings_with_less_than_5_floors_(%)',\n",
        "                'buildings_with_5_or_more_floors_(%)', 'mobile_homes_(%)',\n",
        "                'university_(%)', 'college_(%)', 'secondary_(high)_school_(%)',\n",
        "                'apprentice_or_trade_school_diploma_(%)', 'no_diploma_(%)',\n",
        "                'non-immigrant_population_(%)', 'immigrant_population_(%)',\n",
        "                'french_(%)', 'english_(%)', 'others_languages_(%)',\n",
        "                'new_area_from_price', 'new_area_from_rooms', 'basement_bedroom']\n",
        "data.drop(demographics, axis=1, inplace=True)"
      ],
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdXUPRvj_O7w",
        "outputId": "1eaed150-e137-4fde-8084-b047d1bfbfe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Remove symbols violating tf scope naming conventions\n",
        "valid_column_names = [col.replace('_(%)', '').replace('$', 'CAD').\n",
        "                      replace(',', '.').\n",
        "                      replace('(', '').replace(')', '') for col in data.columns]\n",
        "data.columns = valid_column_names\n",
        "data.columns"
      ],
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['price', 'lat', 'long', 'restaurants', 'shopping', 'vibrant',\n",
              "       'cycling_friendly', 'car_friendly', 'historic', 'quiet',\n",
              "       'elementary_schools', 'high_schools', 'parks', 'nightlife', 'groceries',\n",
              "       'daycares', 'pedestrian_friendly', 'cafes', 'transit_friendly',\n",
              "       'greenery', 'year_built', 'population_2016_',\n",
              "       'population_variation_between_2011_2016_', 'population_density_',\n",
              "       'unemployment_rate_2016_', 'walk_score', 'rooms', 'bedrooms',\n",
              "       'bathrooms', 'powder_rooms', 'total_area', 'river_proximity',\n",
              "       'has_pool', 'n_parking', 'has_garage', 'is_devided', 'mr_distance'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ztlVY8Ufx90",
        "outputId": "45cbc6fe-b48c-4f60-ed0d-8b5be681be85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# Random index shuffling for train/test split\n",
        "df = data.copy().sample(frac=1, random_state=0)\n",
        "# Prepare train and test data\n",
        "train_size = round(0.8*df.shape[0])\n",
        "train = df[: train_size]\n",
        "test = df[train_size : ]\n",
        "\n",
        "# Inspect training data\n",
        "print('Shape of the train data with all features:', train.shape)\n",
        "print(\"\")\n",
        "print(\"List of features:\")\n",
        "print(list(train.columns))"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the train data with all features: (2142, 37)\n",
            "\n",
            "List of features:\n",
            "['price', 'lat', 'long', 'restaurants', 'shopping', 'vibrant', 'cycling_friendly', 'car_friendly', 'historic', 'quiet', 'elementary_schools', 'high_schools', 'parks', 'nightlife', 'groceries', 'daycares', 'pedestrian_friendly', 'cafes', 'transit_friendly', 'greenery', 'year_built', 'population_2016_', 'population_variation_between_2011_2016_', 'population_density_', 'unemployment_rate_2016_', 'walk_score', 'rooms', 'bedrooms', 'bathrooms', 'powder_rooms', 'total_area', 'river_proximity', 'has_pool', 'n_parking', 'has_garage', 'is_devided', 'mr_distance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MekiDUOrf6Gy",
        "outputId": "dd5fddfc-10be-466d-bb0a-6d2755e71f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Outlier detection\n",
        "clf = IsolationForest(max_samples = 100, random_state = 0)\n",
        "clf.fit(train)\n",
        "y_noano = clf.predict(train)\n",
        "y_noano = pd.DataFrame(y_noano, columns = ['Top'])\n",
        "# Indices of non-outliers\n",
        "noano_indices = y_noano[y_noano['Top'] == 1].index.values\n",
        "\n",
        "# Remove anomalies\n",
        "train_ano_rm = train.iloc[noano_indices]\n",
        "train_ano_rm.reset_index(drop = True, inplace = True)\n",
        "print(\"Number of Outliers:\", y_noano[y_noano['Top'] == -1].shape[0])\n",
        "print(\"Number of rows without outliers:\", train_ano_rm.shape[0])"
      ],
      "execution_count": 465,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Outliers: 699\n",
            "Number of rows without outliers: 1443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkoSsWFmg82y"
      },
      "source": [
        "## Z-score normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLKOyl6pqFCM"
      },
      "source": [
        "boolean_features = ['river_proximity', 'has_pool',\n",
        "                    'has_garage', 'is_devided']"
      ],
      "execution_count": 466,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5cqMqQEgiK-"
      },
      "source": [
        "# Calculate the Z-scores of each column in the training set:\n",
        "train_df_mean = train_ano_rm.mean()\n",
        "train_df_std = train_ano_rm.std()\n",
        "train_df_norm = (train_ano_rm - train_df_mean)/train_df_std\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "test_df_mean = test.mean()\n",
        "test_df_std = test.std()\n",
        "test_df_norm = (test - test_df_mean)/test_df_std\n",
        "\n",
        "# Add unnormalized boolean features back\n",
        "for bool_feature in boolean_features:\n",
        "    train_df_norm[bool_feature] = train_ano_rm[bool_feature]\n",
        "    test_df_norm[bool_feature] = test[bool_feature]"
      ],
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw_Z0_NhSVwj"
      },
      "source": [
        ""
      ],
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgLm7P2cmh1O"
      },
      "source": [
        "## Represent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG5NOvXRlop4"
      },
      "source": [
        "# Create an empty list that will eventually hold all created feature columns.\n",
        "feature_columns = []\n",
        "\n",
        "# We scaled all the columns, including latitude and longitude, into their\n",
        "# Z scores. So, instead of picking a resolution in degrees, we're going\n",
        "# to use resolution_in_Zs.  A resolution_in_Zs of 1 corresponds to \n",
        "# a full standard deviation. \n",
        "resolution_in_Zs = 0.25  # 3/10 of a standard deviation.\n",
        "\n",
        "# Create a bucket feature column for latitude.\n",
        "latitude_as_a_numeric_column = tf.feature_column.numeric_column(\"lat\")\n",
        "latitude_boundaries = list(np.arange(int(min(train_df_norm['lat'])), \n",
        "                                     int(max(train_df_norm['lat'])), \n",
        "                                     resolution_in_Zs))\n",
        "latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column, latitude_boundaries)\n",
        "\n",
        "# Create a bucket feature column for longitude.\n",
        "longitude_as_a_numeric_column = tf.feature_column.numeric_column(\"long\")\n",
        "longitude_boundaries = list(np.arange(int(min(train_df_norm['long'])), \n",
        "                                      int(max(train_df_norm['long'])), \n",
        "                                      resolution_in_Zs))\n",
        "longitude = tf.feature_column.bucketized_column(longitude_as_a_numeric_column, \n",
        "                                                longitude_boundaries)\n",
        "\n",
        "# Create a feature cross of latitude and longitude.\n",
        "latitude_x_longitude = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size=100)\n",
        "crossed_feature = tf.feature_column.indicator_column(latitude_x_longitude)\n",
        "feature_columns.append(crossed_feature)\n",
        "\n",
        "feature_names = data.drop(['price', 'lat', 'long'], axis=1).columns\n",
        "for feature in feature_names:\n",
        "    if data[feature].dtype == bool:\n",
        "        train_df_norm[feature] = data[feature].astype('str') # bool raises value error\n",
        "        test_df_norm[feature] = data[feature].astype('str') # bool raises value error\n",
        "        categorical_feature = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            feature, ['True', 'False']\n",
        "        )\n",
        "        new_feature = tf.feature_column.indicator_column(categorical_feature)\n",
        "    else:\n",
        "        new_feature = tf.feature_column.numeric_column(feature)\n",
        "    feature_columns.append(new_feature)\n",
        "\n",
        "# Convert list of feature columns into a layer that will be fed into the model. \n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6VAf7qw2EXE"
      },
      "source": [
        "## Plotting functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tynBAM6M2IbG",
        "outputId": "dece943f-1235-477c-eb21-47794183450c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def plot_loss_curve(epochs, mse):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, mse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_loss_curve function.\")"
      ],
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeXu9YmR2zVd"
      },
      "source": [
        ""
      ],
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hUsbjDT23Ua"
      },
      "source": [
        "## Linear Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJNsGvor2-KY",
        "outputId": "015c0bdd-c2b3-4e42-ef2d-944357b7f0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def create_model(my_learning_rate, feature_layer, l2=0):\n",
        "    \"\"\"Create and compile a linear regression model with l2 regularization.\"\"\"\n",
        "    # Most simple tf.keras models are sequential.\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Add the layer containing the feature columns to the model.\n",
        "    model.add(feature_layer)\n",
        "\n",
        "    # Add one linear layer to the model to yield a simple linear regressor.\n",
        "    model.add(tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
        "                                    kernel_regularizer=tf.keras.regularizers.l2(l2)))\n",
        "\n",
        "    # Construct the layers into a model that TensorFlow can execute.\n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "    return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size, label_name):\n",
        "    \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "    # Split the dataset into features and label.\n",
        "    features = {name:np.array(value) for name, value in dataset.items()}\n",
        "    label = np.array(features.pop(label_name))\n",
        "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                        epochs=epochs, shuffle=True)\n",
        "\n",
        "    # Get details that will be useful for plotting the loss curve.\n",
        "    epochs = history.epoch\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    rmse = hist[\"mean_squared_error\"]\n",
        "\n",
        "    return epochs, rmse   \n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": 470,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZy2fjeP5fe7",
        "outputId": "03cd926d-8f01-4d12-c952-b8610dbd7c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Hyperparameters.\n",
        "learning_rate = 0.002\n",
        "epochs = 100\n",
        "batch_size = 1000\n",
        "l2 = 0.1\n",
        "label_name = \"price\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer, l2)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse = train_model(my_model, train_df_norm, epochs, batch_size, label_name)\n",
        "plot_loss_curve(epochs, mse)\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4196 - mean_squared_error: 1.2483\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2484 - mean_squared_error: 1.0947\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1566 - mean_squared_error: 1.0138\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0901 - mean_squared_error: 0.9560\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0372 - mean_squared_error: 0.9102\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9936 - mean_squared_error: 0.8730\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9560 - mean_squared_error: 0.8410\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9228 - mean_squared_error: 0.8129\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8926 - mean_squared_error: 0.7874\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8650 - mean_squared_error: 0.7645\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8405 - mean_squared_error: 0.7442\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8173 - mean_squared_error: 0.7250\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7950 - mean_squared_error: 0.7064\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7741 - mean_squared_error: 0.6891\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7543 - mean_squared_error: 0.6725\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7357 - mean_squared_error: 0.6571\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7183 - mean_squared_error: 0.6429\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7014 - mean_squared_error: 0.6287\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6847 - mean_squared_error: 0.6148\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6682 - mean_squared_error: 0.6009\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6526 - mean_squared_error: 0.5880\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6379 - mean_squared_error: 0.5757\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6240 - mean_squared_error: 0.5643\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6105 - mean_squared_error: 0.5527\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5979 - mean_squared_error: 0.5421\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5857 - mean_squared_error: 0.5320\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5740 - mean_squared_error: 0.5220\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5626 - mean_squared_error: 0.5121\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5527 - mean_squared_error: 0.5039\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5425 - mean_squared_error: 0.4949\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5324 - mean_squared_error: 0.4864\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5231 - mean_squared_error: 0.4782\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5144 - mean_squared_error: 0.4709\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5067 - mean_squared_error: 0.4641\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4981 - mean_squared_error: 0.4567\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4898 - mean_squared_error: 0.4493\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4824 - mean_squared_error: 0.4427\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4757 - mean_squared_error: 0.4370\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4680 - mean_squared_error: 0.4297\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4616 - mean_squared_error: 0.4243\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4554 - mean_squared_error: 0.4189\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4491 - mean_squared_error: 0.4130\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4433 - mean_squared_error: 0.4079\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4379 - mean_squared_error: 0.4029\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4321 - mean_squared_error: 0.3979\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4271 - mean_squared_error: 0.3932\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4223 - mean_squared_error: 0.3886\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4173 - mean_squared_error: 0.3841\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4124 - mean_squared_error: 0.3797\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4080 - mean_squared_error: 0.3754\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4034 - mean_squared_error: 0.3713\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3991 - mean_squared_error: 0.3669\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3953 - mean_squared_error: 0.3634\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3912 - mean_squared_error: 0.3592\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3874 - mean_squared_error: 0.3555\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3842 - mean_squared_error: 0.3527\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3807 - mean_squared_error: 0.3491\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3773 - mean_squared_error: 0.3459\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3745 - mean_squared_error: 0.3434\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3715 - mean_squared_error: 0.3404\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3691 - mean_squared_error: 0.3379\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3658 - mean_squared_error: 0.3344\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3631 - mean_squared_error: 0.3317\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3605 - mean_squared_error: 0.3297\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3583 - mean_squared_error: 0.3270\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3561 - mean_squared_error: 0.3252\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3536 - mean_squared_error: 0.3229\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3515 - mean_squared_error: 0.3207\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3494 - mean_squared_error: 0.3189\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3471 - mean_squared_error: 0.3164\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3454 - mean_squared_error: 0.3148\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3433 - mean_squared_error: 0.3124\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3416 - mean_squared_error: 0.3108\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3399 - mean_squared_error: 0.3093\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3385 - mean_squared_error: 0.3082\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3369 - mean_squared_error: 0.3067\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3352 - mean_squared_error: 0.3052\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3332 - mean_squared_error: 0.3029\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3317 - mean_squared_error: 0.3013\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3305 - mean_squared_error: 0.3002\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3290 - mean_squared_error: 0.2988\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3277 - mean_squared_error: 0.2974\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3264 - mean_squared_error: 0.2959\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3255 - mean_squared_error: 0.2949\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3245 - mean_squared_error: 0.2939\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3230 - mean_squared_error: 0.2926\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3223 - mean_squared_error: 0.2916\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3211 - mean_squared_error: 0.2900\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3200 - mean_squared_error: 0.2887\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3192 - mean_squared_error: 0.2880\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3183 - mean_squared_error: 0.2870\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3178 - mean_squared_error: 0.2867\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3170 - mean_squared_error: 0.2854\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3158 - mean_squared_error: 0.2845\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3149 - mean_squared_error: 0.2838\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3142 - mean_squared_error: 0.2827\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3134 - mean_squared_error: 0.2819\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3125 - mean_squared_error: 0.2808\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3121 - mean_squared_error: 0.2805\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3113 - mean_squared_error: 0.2792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd62d9b6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3497 - mean_squared_error: 0.3178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3497476875782013, 0.31780192255973816]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 471
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRphzOlVVcMY"
      },
      "source": [
        "Data including demographics:   \n",
        "**Training:** loss: 0.2409 - mean_squared_error: 0.2409   \n",
        "**Validation:** loss: 0.4419 - mean_squared_error: 0.4419\n",
        "  \n",
        "---\n",
        "\n",
        "Data excluding demographics:   \n",
        "**Training:** loss: 0.2290 - mean_squared_error: 0.2290    \n",
        "**Validation:** loss: 0.3215 - mean_squared_error: 0.3215  \n",
        "\n",
        "---\n",
        "\n",
        "The linear model appears to perform better without the demographic data. The\n",
        "difference between training and validation metrics remains rather large. More stringent regularization may be advisable.\n",
        "\n",
        "---\n",
        "\n",
        "After Regularization of model with data excluding demographics:  \n",
        "**Training:** loss: 0.3113 - mean_squared_error: 0.2792  \n",
        "**Validation:** loss: 0.3497 - mean_squared_error: 0.3178"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOOl09u7eG6Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}