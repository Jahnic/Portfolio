{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_gcolab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRWjoIT1-hlm"
      },
      "source": [
        "# Run on TensorFlow 2.x\n",
        "# %tensorflow_version 2.x\n",
        "# from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0D9c1N1cHFu"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "import matplotlib\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# Saves model as file\n",
        "import pickle\n",
        "# Verify computational environment\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.client import device_lib\n",
        "# Outlier detection\n",
        "from sklearn.ensemble import IsolationForest\n",
        "# Feature importance\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "keras.__version__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW8t0RFlfNZT",
        "outputId": "f60da5f7-de08-4e84-f4e2-b12320ab4b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import data to google colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwh7_zVjcKWS",
        "outputId": "2976606d-7ad5-4d94-9ac3-7b6e015d5078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "# Verify GPU\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 4317733520874195888,\n",
              " name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 10644186388901344153\n",
              " physical_device_desc: \"device: XLA_CPU device\"]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k6lk1Z-cXIU",
        "outputId": "9d7df90b-d40c-41ff-865d-1a2570b2e18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# Load data\n",
        "path = \"data/complete_data.csv\"\n",
        "data = pd.read_csv(path).iloc[:, 4: ]\n",
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    price  lat  long  restaurants  shopping  vibrant  cycling_friendly  \\\n",
              "0  409000 45.5 -73.6          7.0       8.0      5.0               9.0   \n",
              "1  680000 45.4 -73.6          3.0       3.0      1.0               7.0   \n",
              "2  283000 45.5 -73.6          8.0      10.0      5.0               3.0   \n",
              "3  339000 45.5 -73.6         10.0      10.0      9.0               9.0   \n",
              "4  177800 45.6 -73.6          6.0       7.0      3.0               4.0   \n",
              "\n",
              "   car_friendly  historic  quiet  ...  powder_rooms  total_area  \\\n",
              "0           6.0       5.0    8.0  ...           0.0      1014.0   \n",
              "1          10.0       0.0   10.0  ...           0.0      1249.0   \n",
              "2           6.0       2.0    0.0  ...           0.0       848.0   \n",
              "3           5.0       6.0    7.0  ...           0.0       621.0   \n",
              "4           9.0       0.0    6.0  ...           0.0       586.0   \n",
              "\n",
              "   new_area_from_price  new_area_from_rooms  river_proximity  has_pool  \\\n",
              "0               1014.0               1014.0            False     False   \n",
              "1               1249.0               1249.0            False      True   \n",
              "2                848.0                848.0            False     False   \n",
              "3                621.0                621.0            False      True   \n",
              "4                586.0                586.0            False     False   \n",
              "\n",
              "   n_parking  has_garage  is_devided  mr_distance  \n",
              "0        1.0        True           1          5.7  \n",
              "1        2.0        True           1          7.1  \n",
              "2        1.0        True           1          5.2  \n",
              "3        0.0       False           1          3.3  \n",
              "4        1.0       False           1         11.3  \n",
              "\n",
              "[5 rows x 76 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>restaurants</th>\n      <th>shopping</th>\n      <th>vibrant</th>\n      <th>cycling_friendly</th>\n      <th>car_friendly</th>\n      <th>historic</th>\n      <th>quiet</th>\n      <th>...</th>\n      <th>powder_rooms</th>\n      <th>total_area</th>\n      <th>new_area_from_price</th>\n      <th>new_area_from_rooms</th>\n      <th>river_proximity</th>\n      <th>has_pool</th>\n      <th>n_parking</th>\n      <th>has_garage</th>\n      <th>is_devided</th>\n      <th>mr_distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>409000</td>\n      <td>45.5</td>\n      <td>-73.6</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1014.0</td>\n      <td>1014.0</td>\n      <td>1014.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>True</td>\n      <td>1</td>\n      <td>5.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>680000</td>\n      <td>45.4</td>\n      <td>-73.6</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1249.0</td>\n      <td>1249.0</td>\n      <td>1249.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>1</td>\n      <td>7.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>283000</td>\n      <td>45.5</td>\n      <td>-73.6</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>848.0</td>\n      <td>848.0</td>\n      <td>848.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>True</td>\n      <td>1</td>\n      <td>5.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>339000</td>\n      <td>45.5</td>\n      <td>-73.6</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>621.0</td>\n      <td>621.0</td>\n      <td>621.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>3.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>177800</td>\n      <td>45.6</td>\n      <td>-73.6</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>586.0</td>\n      <td>586.0</td>\n      <td>586.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>11.3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 76 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.417212"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.lat.min()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv3fPw1Pryxe"
      },
      "source": [
        "# Transform is_devided into boolean feature\n",
        "data.is_devided = data.is_devided.astype('bool')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['price', 'lat', 'long', 'restaurants', 'shopping', 'vibrant',\n",
              "       'cycling_friendly', 'car_friendly', 'historic', 'quiet',\n",
              "       'elementary_schools', 'high_schools', 'parks', 'nightlife', 'groceries',\n",
              "       'daycares', 'pedestrian_friendly', 'cafes', 'transit_friendly',\n",
              "       'greenery', 'year_built', 'population_2016_',\n",
              "       'population_variation_between_2011_2016_', 'population_density_',\n",
              "       'unemployment_rate_2016_', 'less_than_$50,000_(%)',\n",
              "       'between_$50,000_and_$80,000_(%)', 'between_$80,000_and_$100,000_(%)',\n",
              "       'between_$100,000_and_$150,000_(%)', 'more_than_$150,000_(%)',\n",
              "       '1-person_households_(%)', '2-person_households_(%)',\n",
              "       '3-person_households_(%)', '4-person_households_(%)',\n",
              "       '5-person_or_more_households_(%)',\n",
              "       'couples_without_children_at_home_(%)',\n",
              "       'couples_with_children_at_home_(%)', 'single-parent_families_(%)',\n",
              "       'owners_(%)', 'renters_(%)', 'before_1960_(%)',\n",
              "       'between_1961_and_1980_(%)', 'between_1981_and_1990_(%)',\n",
              "       'between_1991_and_2000_(%)', 'between_2001_and_2010_(%)',\n",
              "       'between_2011_and_2016_(%)', 'single-family_homes_(%)',\n",
              "       'semi-detached_or_row_houses_(%)',\n",
              "       'buildings_with_less_than_5_floors_(%)',\n",
              "       'buildings_with_5_or_more_floors_(%)', 'mobile_homes_(%)',\n",
              "       'university_(%)', 'college_(%)', 'secondary_(high)_school_(%)',\n",
              "       'apprentice_or_trade_school_diploma_(%)', 'no_diploma_(%)',\n",
              "       'non-immigrant_population_(%)', 'immigrant_population_(%)',\n",
              "       'french_(%)', 'english_(%)', 'others_languages_(%)', 'walk_score',\n",
              "       'rooms', 'bedrooms', 'basement_bedroom', 'bathrooms', 'powder_rooms',\n",
              "       'total_area', 'new_area_from_price', 'new_area_from_rooms',\n",
              "       'river_proximity', 'has_pool', 'n_parking', 'has_garage', 'is_devided',\n",
              "       'mr_distance'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nuNb6Uvemew"
      },
      "source": [
        "# # Drop redundant data\n",
        "# redundant = ['more_than_$150,000_(%)', '5-person_or_more_households_(%)', \n",
        "#             'single-parent_families_(%)', 'renters_(%)', 'before_1960_(%)',\n",
        "#             'mobile_homes_(%)', 'university_(%)', 'non-immigrant_population_(%)',\n",
        "#             'french_(%)', 'new_area_from_price', 'new_area_from_rooms',\n",
        "#             'basement_bedroom']\n",
        "# data.drop(redundant, axis=1, inplace=True)\n",
        "\n",
        "# Drop demographics data\n",
        "drop_cols = ['less_than_$50,000_(%)', 'between_$50,000_and_$80,000_(%)', \n",
        "                'between_$80,000_and_$100,000_(%)', 'between_$100,000_and_$150,000_(%)',\n",
        "                'more_than_$150,000_(%)', '1-person_households_(%)', \n",
        "                '2-person_households_(%)', '3-person_households_(%)', \n",
        "                '4-person_households_(%)', '5-person_or_more_households_(%)', \n",
        "                'couples_without_children_at_home_(%)', 'couples_with_children_at_home_(%)',\n",
        "                'single-parent_families_(%)', 'owners_(%)', 'renters_(%)',\n",
        "                'before_1960_(%)', 'between_1961_and_1980_(%)',\n",
        "                'between_1981_and_1990_(%)', 'between_1991_and_2000_(%)',\n",
        "                'between_2001_and_2010_(%)', 'between_2011_and_2016_(%)',\n",
        "                'single-family_homes_(%)', 'semi-detached_or_row_houses_(%)',\n",
        "                'buildings_with_less_than_5_floors_(%)',\n",
        "                'buildings_with_5_or_more_floors_(%)', 'mobile_homes_(%)',\n",
        "                'university_(%)', 'college_(%)', 'secondary_(high)_school_(%)',\n",
        "                'apprentice_or_trade_school_diploma_(%)', 'no_diploma_(%)',\n",
        "                'non-immigrant_population_(%)', 'immigrant_population_(%)',\n",
        "                'french_(%)', 'english_(%)', 'others_languages_(%)',\n",
        "                'new_area_from_price', 'new_area_from_rooms', 'basement_bedroom',\n",
        "                'n_parking', 'population_2016_', 'population_density_', 'n_parking',\n",
        "                'rooms', 'river_proximity', 'unemployment_rate_2016_',\n",
        "                'elementary_schools', 'high_schools', 'daycares', 'shopping',                               'pedestrian_friendly','has_pool', 'has_garage', 'is_devided',\n",
        "                'nightlife', 'population_variation_between_2011_2016_',]\n",
        "data.drop(drop_cols, axis=1, inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdXUPRvj_O7w",
        "outputId": "3527eff9-6787-4a41-b505-eef53b0c604d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Remove symbols violating tf scope naming conventions\n",
        "valid_column_names = [col.replace('_(%)', '').replace('$', 'CAD').\n",
        "                      replace(',', '.').\n",
        "                      replace('(', '').replace(')', '') for col in data.columns]\n",
        "data.columns = valid_column_names"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ztlVY8Ufx90",
        "outputId": "ae2244b3-07f8-44c6-9da9-ec2dc1d095f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# Random index shuffling for train/test split\n",
        "df = data.copy().sample(frac=1, random_state=0)\n",
        "# Prepare train and test data\n",
        "train_size = round(0.8*df.shape[0])\n",
        "train = df[: train_size]\n",
        "test = df[train_size : ]\n",
        "\n",
        "# Remove price outliers above 1.5 million\n",
        "train = train[train.price < 1500000]\n",
        "test = test[test.price < 1500000]\n",
        "\n",
        "# Inspect training data\n",
        "print('Shape of the train data with all features:', train.shape)\n",
        "print(\"\")\n",
        "print(\"List of features:\")\n",
        "print(list(train.columns))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the train data with all features: (2190, 21)\n\nList of features:\n['price', 'lat', 'long', 'restaurants', 'vibrant', 'cycling_friendly', 'car_friendly', 'historic', 'quiet', 'parks', 'groceries', 'cafes', 'transit_friendly', 'greenery', 'year_built', 'walk_score', 'bedrooms', 'bathrooms', 'powder_rooms', 'total_area', 'mr_distance']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MekiDUOrf6Gy",
        "outputId": "0ca56181-aa41-493a-f2d9-234d7a1ef32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Outlier detection\n",
        "clf = IsolationForest(max_samples = 100, random_state = 0)\n",
        "clf.fit(train)\n",
        "y_noano = clf.predict(train)\n",
        "y_noano = pd.DataFrame(y_noano, columns = ['Top'])\n",
        "# Indices of non-outliers\n",
        "noano_indices = y_noano[y_noano['Top'] == 1].index.values\n",
        "\n",
        "# Remove anomalies\n",
        "train_ano_rm = train.iloc[noano_indices]\n",
        "train_ano_rm.reset_index(drop = True, inplace = True)\n",
        "print(\"Number of Outliers:\", y_noano[y_noano['Top'] == -1].shape[0])\n",
        "print(\"Number of rows without outliers:\", train_ano_rm.shape[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Outliers: 668\nNumber of rows without outliers: 1522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkoSsWFmg82y"
      },
      "source": [
        "## Z-score normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLKOyl6pqFCM"
      },
      "source": [
        "# boolean_features = ['river_proximity', 'has_pool',\n",
        "#                     'has_garage', 'is_devided']\n",
        "boolean_features = []"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5cqMqQEgiK-"
      },
      "source": [
        "# Calculate the Z-scores of each column in the training set:\n",
        "train_df_mean = train_ano_rm.mean()\n",
        "train_df_std = train_ano_rm.std()\n",
        "# train_df_norm = (train_ano_rm - train_df_mean)/train_df_std\n",
        "train_df_norm = train_ano_rm.apply(lambda x: (x - x.mean()) / x.std() if x.name != 'price' else x )\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "# test_df_mean = test.mean()\n",
        "# test_df_std = test.std()\n",
        "# test_df_norm = (test - test_df_mean)/test_df_std\n",
        "test_df_norm = test.apply(lambda x: (x - x.mean()) / x.std() if x.name != 'price' else x )\n",
        "\n",
        "# Add unnormalized boolean features back\n",
        "for bool_feature in boolean_features:\n",
        "    train_df_norm[bool_feature] = train_ano_rm[bool_feature]\n",
        "    test_df_norm[bool_feature] = test[bool_feature]"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       price  lat  long  restaurants  vibrant  cycling_friendly  car_friendly  \\\n",
              "2615  519000  0.0   0.3          0.7      1.0               1.3          -0.6   \n",
              "753   520000  0.2   0.8          0.7      1.0               1.3          -1.1   \n",
              "462   445000  1.3   0.3         -0.3     -0.7               0.0          -0.6   \n",
              "1938  220000  0.7  -1.7         -0.8     -1.1              -1.3           0.5   \n",
              "673   339000  0.9   0.9         -0.3     -0.0               0.5          -0.6   \n",
              "...      ...  ...   ...          ...      ...               ...           ...   \n",
              "1033  329000  0.4   0.8          0.7      0.6               1.3          -0.6   \n",
              "763   180000  3.5   0.2         -2.4     -1.7              -0.8           1.6   \n",
              "835   460883 -0.3   0.4          0.7      1.0              -1.3          -0.6   \n",
              "1653  299900 -1.8  -1.8         -1.9     -1.4               0.5           1.0   \n",
              "2607  639000 -0.3   0.5          0.7      1.0              -0.4          -1.1   \n",
              "\n",
              "      historic  quiet  parks  ...  cafes  transit_friendly  greenery  \\\n",
              "2615       0.9   -0.4    0.7  ...    0.9               0.8      -0.1   \n",
              "753        0.9   -0.7    0.7  ...    0.9               0.8      -0.1   \n",
              "462       -0.3    1.2    0.7  ...   -0.8               0.2       1.0   \n",
              "1938      -2.0    1.2   -0.4  ...   -1.7              -0.5       0.4   \n",
              "673        0.5    0.6    0.7  ...   -0.8               0.2       1.0   \n",
              "...        ...    ...    ...  ...    ...               ...       ...   \n",
              "1033       0.5    0.2    0.7  ...    0.5               0.8      -0.7   \n",
              "763       -2.0   -0.1   -2.4  ...   -0.8              -1.8       0.4   \n",
              "835        0.9   -1.4    0.7  ...    0.9               0.8      -1.2   \n",
              "1653       0.1    1.2   -0.4  ...   -1.2              -2.4       0.4   \n",
              "2607       0.5   -1.4    0.7  ...    0.9               0.8      -0.1   \n",
              "\n",
              "      year_built  walk_score  bedrooms  bathrooms  powder_rooms  total_area  \\\n",
              "2615        -1.8         0.8       0.1       -0.6          -0.3        -0.0   \n",
              "753          0.8         0.7       0.1       -0.6          -0.3        -0.8   \n",
              "462          0.4        -0.5       0.1       -0.6          -0.3         0.3   \n",
              "1938        -0.1        -1.3      -1.1       -0.6          -0.3        -0.7   \n",
              "673          0.4         0.5       0.1       -0.6          -0.3        -0.2   \n",
              "...          ...         ...       ...        ...           ...         ...   \n",
              "1033         0.6         0.5      -1.1       -0.6          -0.3        -0.9   \n",
              "763         -0.2        -1.7       0.1       -0.6          -0.3         0.0   \n",
              "835          0.8         1.1      -1.1       -0.6          -0.3        -1.0   \n",
              "1653         0.7        -0.6      -1.1       -0.6          -0.3        -0.5   \n",
              "2607         0.8         0.9       0.1        1.5          -0.3        -0.7   \n",
              "\n",
              "      mr_distance  \n",
              "2615         -0.9  \n",
              "753          -0.3  \n",
              "462           0.5  \n",
              "1938          0.6  \n",
              "673           0.4  \n",
              "...           ...  \n",
              "1033         -0.1  \n",
              "763           3.2  \n",
              "835          -0.8  \n",
              "1653          1.5  \n",
              "2607         -0.6  \n",
              "\n",
              "[548 rows x 21 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>restaurants</th>\n      <th>vibrant</th>\n      <th>cycling_friendly</th>\n      <th>car_friendly</th>\n      <th>historic</th>\n      <th>quiet</th>\n      <th>parks</th>\n      <th>...</th>\n      <th>cafes</th>\n      <th>transit_friendly</th>\n      <th>greenery</th>\n      <th>year_built</th>\n      <th>walk_score</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>powder_rooms</th>\n      <th>total_area</th>\n      <th>mr_distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2615</th>\n      <td>519000</td>\n      <td>0.0</td>\n      <td>0.3</td>\n      <td>0.7</td>\n      <td>1.0</td>\n      <td>1.3</td>\n      <td>-0.6</td>\n      <td>0.9</td>\n      <td>-0.4</td>\n      <td>0.7</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>0.8</td>\n      <td>-0.1</td>\n      <td>-1.8</td>\n      <td>0.8</td>\n      <td>0.1</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>-0.0</td>\n      <td>-0.9</td>\n    </tr>\n    <tr>\n      <th>753</th>\n      <td>520000</td>\n      <td>0.2</td>\n      <td>0.8</td>\n      <td>0.7</td>\n      <td>1.0</td>\n      <td>1.3</td>\n      <td>-1.1</td>\n      <td>0.9</td>\n      <td>-0.7</td>\n      <td>0.7</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>0.8</td>\n      <td>-0.1</td>\n      <td>0.8</td>\n      <td>0.7</td>\n      <td>0.1</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>-0.8</td>\n      <td>-0.3</td>\n    </tr>\n    <tr>\n      <th>462</th>\n      <td>445000</td>\n      <td>1.3</td>\n      <td>0.3</td>\n      <td>-0.3</td>\n      <td>-0.7</td>\n      <td>0.0</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>1.2</td>\n      <td>0.7</td>\n      <td>...</td>\n      <td>-0.8</td>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>0.4</td>\n      <td>-0.5</td>\n      <td>0.1</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>0.3</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1938</th>\n      <td>220000</td>\n      <td>0.7</td>\n      <td>-1.7</td>\n      <td>-0.8</td>\n      <td>-1.1</td>\n      <td>-1.3</td>\n      <td>0.5</td>\n      <td>-2.0</td>\n      <td>1.2</td>\n      <td>-0.4</td>\n      <td>...</td>\n      <td>-1.7</td>\n      <td>-0.5</td>\n      <td>0.4</td>\n      <td>-0.1</td>\n      <td>-1.3</td>\n      <td>-1.1</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>-0.7</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>673</th>\n      <td>339000</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>-0.3</td>\n      <td>-0.0</td>\n      <td>0.5</td>\n      <td>-0.6</td>\n      <td>0.5</td>\n      <td>0.6</td>\n      <td>0.7</td>\n      <td>...</td>\n      <td>-0.8</td>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>0.4</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>-0.2</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1033</th>\n      <td>329000</td>\n      <td>0.4</td>\n      <td>0.8</td>\n      <td>0.7</td>\n      <td>0.6</td>\n      <td>1.3</td>\n      <td>-0.6</td>\n      <td>0.5</td>\n      <td>0.2</td>\n      <td>0.7</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.8</td>\n      <td>-0.7</td>\n      <td>0.6</td>\n      <td>0.5</td>\n      <td>-1.1</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>-0.9</td>\n      <td>-0.1</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>180000</td>\n      <td>3.5</td>\n      <td>0.2</td>\n      <td>-2.4</td>\n      <td>-1.7</td>\n      <td>-0.8</td>\n      <td>1.6</td>\n      <td>-2.0</td>\n      <td>-0.1</td>\n      <td>-2.4</td>\n      <td>...</td>\n      <td>-0.8</td>\n      <td>-1.8</td>\n      <td>0.4</td>\n      <td>-0.2</td>\n      <td>-1.7</td>\n      <td>0.1</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>0.0</td>\n      <td>3.2</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>460883</td>\n      <td>-0.3</td>\n      <td>0.4</td>\n      <td>0.7</td>\n      <td>1.0</td>\n      <td>-1.3</td>\n      <td>-0.6</td>\n      <td>0.9</td>\n      <td>-1.4</td>\n      <td>0.7</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>0.8</td>\n      <td>-1.2</td>\n      <td>0.8</td>\n      <td>1.1</td>\n      <td>-1.1</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>-1.0</td>\n      <td>-0.8</td>\n    </tr>\n    <tr>\n      <th>1653</th>\n      <td>299900</td>\n      <td>-1.8</td>\n      <td>-1.8</td>\n      <td>-1.9</td>\n      <td>-1.4</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.1</td>\n      <td>1.2</td>\n      <td>-0.4</td>\n      <td>...</td>\n      <td>-1.2</td>\n      <td>-2.4</td>\n      <td>0.4</td>\n      <td>0.7</td>\n      <td>-0.6</td>\n      <td>-1.1</td>\n      <td>-0.6</td>\n      <td>-0.3</td>\n      <td>-0.5</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>2607</th>\n      <td>639000</td>\n      <td>-0.3</td>\n      <td>0.5</td>\n      <td>0.7</td>\n      <td>1.0</td>\n      <td>-0.4</td>\n      <td>-1.1</td>\n      <td>0.5</td>\n      <td>-1.4</td>\n      <td>0.7</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>0.8</td>\n      <td>-0.1</td>\n      <td>0.8</td>\n      <td>0.9</td>\n      <td>0.1</td>\n      <td>1.5</td>\n      <td>-0.3</td>\n      <td>-0.7</td>\n      <td>-0.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>548 rows Ã— 21 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "train_df_norm\n",
        "test_df_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "price          499926.4\n",
              "lat                45.5\n",
              "long              -73.6\n",
              "restaurants         9.4\n",
              "vibrant             8.3\n",
              "                 ...   \n",
              "bedrooms            1.7\n",
              "bathrooms           1.2\n",
              "powder_rooms        0.1\n",
              "total_area        852.9\n",
              "mr_distance         3.7\n",
              "Length: 21, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# # Save means and standard deviations\n",
        "# train_df_std[3:].to_csv('web-app/data/parameter_stds.csv')\n",
        "# train_df_mean[3:].to_csv('web-app/data/parameter_means.csv')\n",
        "\n",
        "train_df_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgLm7P2cmh1O"
      },
      "source": [
        "## Represent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG5NOvXRlop4"
      },
      "source": [
        "# Create an empty list that will eventually hold all created feature columns.\n",
        "feature_columns = []\n",
        "\n",
        "# We scaled all the columns, including latitude and longitude, into their\n",
        "# Z scores. So, instead of picking a resolution in degrees, we're going\n",
        "# to use resolution_in_Zs.  A resolution_in_Zs of 1 corresponds to \n",
        "# a full standard deviation. \n",
        "# resolution_in_Zs = 0.15  # 1.5/10 of a standard deviation.\n",
        "\n",
        "# # Create a bucket feature column for latitude.\n",
        "# latitude_as_a_numeric_column = tf.feature_column.numeric_column(\"lat\", shape=(1,))\n",
        "# latitude_boundaries = list(np.arange(int(min(train_df_norm['lat'])), \n",
        "#                                      int(max(train_df_norm['lat'])), \n",
        "#                                      resolution_in_Zs))\n",
        "# latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column, latitude_boundaries)\n",
        "\n",
        "# # Create a bucket feature column for longitude.\n",
        "# longitude_as_a_numeric_column = tf.feature_column.numeric_column(\"long\", shape=(1,))\n",
        "# longitude_boundaries = list(np.arange(int(min(train_df_norm['long'])), \n",
        "#                                       int(max(train_df_norm['long'])), \n",
        "#                                       resolution_in_Zs))\n",
        "# longitude = tf.feature_column.bucketized_column(longitude_as_a_numeric_column, \n",
        "#                                                 longitude_boundaries)\n",
        "\n",
        "# # Create a feature cross of latitude and longitude.\n",
        "# latitude_x_longitude = tf.feature_column.crossed_column([latitude, longitude],                                                                      hash_bucket_size=100)\n",
        "# crossed_feature = tf.feature_column.indicator_column(latitude_x_longitude)\n",
        "# feature_columns.append(crossed_feature)\n",
        "\n",
        "feature_names = data.drop(['price', 'lat', 'long'], axis=1).columns\n",
        "# feature_names = data.drop(['price'], axis=1).columns\n",
        "for feature in feature_names:\n",
        "    if data[feature].dtype == bool:\n",
        "        train_df_norm[feature] = data[feature].astype('str') # bool raises value error\n",
        "        test_df_norm[feature] = data[feature].astype('str') # bool raises value error\n",
        "        categorical_feature = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            feature, ['True', 'False']\n",
        "        )\n",
        "        new_feature = tf.feature_column.indicator_column(categorical_feature)\n",
        "    else:\n",
        "        new_feature = tf.feature_column.numeric_column(feature, shape=(1,))\n",
        "    feature_columns.append(new_feature)\n",
        "\n",
        "# Convert list of feature columns into a layer that will be fed into the model. \n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6VAf7qw2EXE"
      },
      "source": [
        "## Plotting functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tynBAM6M2IbG",
        "outputId": "5750912d-93ea-44ef-c967-754818360216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def plot_loss_curve(epochs, mse):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, mse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_loss_curve function.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the plot_loss_curve function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hUsbjDT23Ua"
      },
      "source": [
        "## Linear Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJNsGvor2-KY",
        "outputId": "734f154a-eb72-4801-9d6a-427545181309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def create_model(my_learning_rate, feature_layer, l2=0):\n",
        "    \"\"\"Create and compile a linear regression model with l2 regularization.\"\"\"\n",
        "    # Most simple tf.keras models are sequential.\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Add the layer containing the feature columns to the model.\n",
        "    model.add(feature_layer)\n",
        "\n",
        "    # model.add(keras.engine.InputLayer(batch_input_shape=(36, 1)))\n",
        "\n",
        "    # Add one linear layer to the model to yield a simple linear regressor.\n",
        "    model.add(tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
        "                                    kernel_regularizer=tf.keras.regularizers.l2(l2)))\n",
        "\n",
        "    # Construct the layers into a model that TensorFlow can execute.\n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "    return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size, label_name):\n",
        "    \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "    # Split the dataset into features and label.\n",
        "    features = {name:np.array(value) for name, value in dataset.items()}\n",
        "    label = np.array(features.pop(label_name))\n",
        "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                        epochs=epochs, shuffle=True)\n",
        "\n",
        "    # Get details that will be useful for plotting the loss curve.\n",
        "    epochs = history.epoch\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    rmse = hist[\"mean_squared_error\"]\n",
        "\n",
        "    return epochs, rmse   \n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZy2fjeP5fe7",
        "outputId": "76f2e68f-97ca-40d2-ae60-13bdd6e48d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "tags": []
      },
      "source": [
        "# Hyperparameters.\n",
        "learning_rate = 0.002\n",
        "epochs = 150\n",
        "batch_size = 1000\n",
        "l2 = 0.1\n",
        "label_name = \"price\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_linear_model = create_model(learning_rate, my_feature_layer, l2)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse = train_model(my_linear_model, train_df_norm, epochs, batch_size, label_name)\n",
        "plot_loss_curve(epochs, mse)\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_linear_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d6df47d6b4bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Train the model on the normalized training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_linear_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplot_loss_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-1893e7b458ed>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, epochs, batch_size, label_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     history = model.fit(x=features, y=label, batch_size=batch_size,\n\u001b[0m\u001b[1;32m     30\u001b[0m                         epochs=epochs, shuffle=True)\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[1;32m    389\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m     ))\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    602\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m--> 604\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2984\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2986\u001b[0m     variant_tensor = gen_dataset_ops.tensor_dataset(\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mto_tensor_list\u001b[0;34m(element_spec, element)\u001b[0m\n\u001b[1;32m    373\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[0;31m# pylint: disable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m   return _to_tensor_list_helper(\n\u001b[0m\u001b[1;32m    376\u001b[0m       \u001b[0;32mlambda\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m       element_spec, element)\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m_to_tensor_list_helper\u001b[0;34m(encode_fn, element_spec, element)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencode_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m   return functools.reduce(\n\u001b[0m\u001b[1;32m    326\u001b[0m       reduce_fn, zip(nest.flatten(element_spec), nest.flatten(element)), [])\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mreduce_fn\u001b[0;34m(state, value)\u001b[0m\n\u001b[1;32m    321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mencode_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m   return functools.reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRphzOlVVcMY"
      },
      "source": [
        "Data including demographics:   \n",
        "**Training:** loss: 0.2409 - mean_squared_error: 0.2409   \n",
        "**Validation:** loss: 0.4419 - mean_squared_error: 0.4419\n",
        "  \n",
        "---\n",
        "\n",
        "Data excluding demographics:   \n",
        "**Training:** loss: 0.2290 - mean_squared_error: 0.2290    \n",
        "**Validation:** loss: 0.3215 - mean_squared_error: 0.3215  \n",
        "\n",
        "---\n",
        "\n",
        "The linear model appears to perform better without the demographic data. The\n",
        "difference between training and validation metrics remains rather large. More stringent regularization may be advisable.\n",
        "\n",
        "---\n",
        "\n",
        "After Regularization of model with data excluding demographics:  \n",
        "**Training:** loss: 0.3113 - mean_squared_error: 0.2792  \n",
        "**Validation:** loss: 0.3497 - mean_squared_error: 0.3178"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOOl09u7eG6Q",
        "outputId": "23cbcfec-9ddc-4f03-8967-626a8e3ee34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Z-score conversion to $\n",
        "test_mse = my_linear_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)[1]\n",
        "test_mse * train_df_std.price"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3939 - mean_squared_error: 0.3643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "145471.66066183627"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # # Save model as 'h5'\n",
        "# my_linear_model.save('tf_model.h5', 'h5')\n",
        "\n",
        "# # Load model\n",
        "# reconstructed_model = keras.models.load_model('tf_model.h5')\n",
        "# keras.load.model('tf_model.h5')\n",
        "# reconstructed_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ToPIBHYMBPq"
      },
      "source": [
        "## Deep neural net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQI6KtcJMFWT"
      },
      "source": [
        "def create_model(my_learning_rate, my_feature_layer, n_layers, n_nodes):\n",
        "    \"\"\"Create and compile a simple linear regression model.\n",
        "  \n",
        "    Args:\n",
        "    my_learning_rate - integer representing learning rate\n",
        "    my_feature_layer - tf feature columns\n",
        "    n_layers - integer indicating the number of layers\n",
        "    n_nodes - list of integers, indicating the number of nodes for each leayer.\n",
        "        len(n_nodes) must be n_layers\n",
        "    \"\"\"\n",
        "\n",
        "    # Stop if n_nodes as less or more elements than there are layers\n",
        "    if len(n_nodes) != n_layers:\n",
        "        print(\"n_nodes must be of length n_layers!\")\n",
        "        return None\n",
        "\n",
        "    # Most simple tf.keras models are sequential.\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Add the layer containing the feature columns to the model.\n",
        "    model.add(my_feature_layer)\n",
        "\n",
        "  # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
        "  # method once for each layer. We've specified the following arguments:\n",
        "  #   * units specifies the number of nodes in this layer.\n",
        "  #   * activation specifies the activation function (Rectified Linear Unit).\n",
        "  #   * name is just a string that can be useful when debugging.\n",
        "\n",
        "\n",
        "    # Define layers and nodes\n",
        "    for layer in range(n_layers):\n",
        "        nodes = n_nodes[layer]\n",
        "        name = 'Hidden' + str(layer)\n",
        "        # Define hidden layer with n nodes.   \n",
        "        model.add(tf.keras.layers.Dense(units=nodes, \n",
        "                                        activation='tanh',\n",
        "                                        kernel_regularizer=tf.keras.regularizers.l2(0.2), \n",
        "                                        name=name)) \n",
        "        # # Dropout layer\n",
        "        # model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "    # Define the output layer.\n",
        "    model.add(tf.keras.layers.Dense(units=1,  \n",
        "                                    name='Output'))                              \n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhqty7sS6_tJ"
      },
      "source": [
        "def train_model(model, dataset, epochs, label_name,\n",
        "                batch_size=None):\n",
        "    \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "    # Split the dataset into features and label.\n",
        "    features = {name:np.array(value) for name, value in dataset.items()}\n",
        "    label = np.array(features.pop(label_name))\n",
        "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                        epochs=epochs, shuffle=True) \n",
        "\n",
        "    # The list of epochs is stored separately from the rest of history.\n",
        "    epochs = history.epoch\n",
        "\n",
        "    # To track the progression of training, gather a snapshot\n",
        "    # of the model's mean squared error at each epoch. \n",
        "    hist = pd.DataFrame(history.history)\n",
        "    mse = hist[\"mean_squared_error\"]\n",
        "\n",
        "    return epochs, mse"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyZw1CCw7Q6W",
        "outputId": "99ea81a4-ed5b-4e2d-a55c-f8cbc569e212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "# Hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "batch_size = 1000\n",
        "n_layers = 1\n",
        "n_nodes = [15]\n",
        "\n",
        "# Specify the label\n",
        "label_name = \"price\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer, n_layers, n_nodes)\n",
        "\n",
        "# Train the model on the normalized training set. We're passing the entire\n",
        "# normalized training set, but the model will only use the features\n",
        "# defined by the feature_layer.\n",
        "epochs, mse = train_model(my_model, train_df_norm, epochs, \n",
        "                          label_name, batch_size)\n",
        "plot_loss_curve(epochs, mse)\n",
        "\n",
        "# After building a model against the training set, test that model\n",
        "# against the test set.\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_squared_error: 0.7561\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.4526 - mean_squared_error: 0.7148\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.3750 - mean_squared_error: 0.6797\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.3002 - mean_squared_error: 0.6482\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.2296 - mean_squared_error: 0.6215\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1613 - mean_squared_error: 0.5975\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.0961 - mean_squared_error: 0.5769\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0325 - mean_squared_error: 0.5582\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.9709 - mean_squared_error: 0.5417\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.9110 - mean_squared_error: 0.5269\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.8521 - mean_squared_error: 0.5130\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.7946 - mean_squared_error: 0.5006\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.7383 - mean_squared_error: 0.4891\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6834 - mean_squared_error: 0.4789\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6292 - mean_squared_error: 0.4690\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5760 - mean_squared_error: 0.4600\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5242 - mean_squared_error: 0.4520\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4731 - mean_squared_error: 0.4443\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4230 - mean_squared_error: 0.4372\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.3739 - mean_squared_error: 0.4307\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3255 - mean_squared_error: 0.4245\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2781 - mean_squared_error: 0.4188\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2314 - mean_squared_error: 0.4134\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.1855 - mean_squared_error: 0.4082\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.1402 - mean_squared_error: 0.4032\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.0959 - mean_squared_error: 0.3986\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.0520 - mean_squared_error: 0.3941\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0089 - mean_squared_error: 0.3897\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.9664 - mean_squared_error: 0.3855\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.9245 - mean_squared_error: 0.3814\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.8834 - mean_squared_error: 0.3776\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.8429 - mean_squared_error: 0.3739\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.8028 - mean_squared_error: 0.3703\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.7634 - mean_squared_error: 0.3670\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.7246 - mean_squared_error: 0.3637\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6864 - mean_squared_error: 0.3606\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6487 - mean_squared_error: 0.3576\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 2.6116 - mean_squared_error: 0.3548\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.5749 - mean_squared_error: 0.3521\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.5389 - mean_squared_error: 0.3495\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5033 - mean_squared_error: 0.3469\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 2.4683 - mean_squared_error: 0.3445\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4337 - mean_squared_error: 0.3420\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.3996 - mean_squared_error: 0.3396\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.3661 - mean_squared_error: 0.3373\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.3330 - mean_squared_error: 0.3350\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.3004 - mean_squared_error: 0.3329\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2683 - mean_squared_error: 0.3308\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2367 - mean_squared_error: 0.3288\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2055 - mean_squared_error: 0.3268\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.1747 - mean_squared_error: 0.3249\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.1445 - mean_squared_error: 0.3233\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.1147 - mean_squared_error: 0.3216\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.0852 - mean_squared_error: 0.3199\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.0563 - mean_squared_error: 0.3184\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.0277 - mean_squared_error: 0.3168\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 1.9996 - mean_squared_error: 0.3152\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9719 - mean_squared_error: 0.3137\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9447 - mean_squared_error: 0.3122\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9177 - mean_squared_error: 0.3107\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8912 - mean_squared_error: 0.3093\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8651 - mean_squared_error: 0.3078\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8394 - mean_squared_error: 0.3065\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8140 - mean_squared_error: 0.3051\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7890 - mean_squared_error: 0.3037\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7644 - mean_squared_error: 0.3024\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.7402 - mean_squared_error: 0.3011\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7163 - mean_squared_error: 0.2999\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6928 - mean_squared_error: 0.2989\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.6696 - mean_squared_error: 0.2978\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.6469 - mean_squared_error: 0.2968\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.6244 - mean_squared_error: 0.2958\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6023 - mean_squared_error: 0.2949\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5806 - mean_squared_error: 0.2939\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5591 - mean_squared_error: 0.2930\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5380 - mean_squared_error: 0.2921\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5173 - mean_squared_error: 0.2913\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.4968 - mean_squared_error: 0.2904\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.4767 - mean_squared_error: 0.2896\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4569 - mean_squared_error: 0.2889\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.4374 - mean_squared_error: 0.2881\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.4181 - mean_squared_error: 0.2873\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 1.3992 - mean_squared_error: 0.2866\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3806 - mean_squared_error: 0.2858\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.3623 - mean_squared_error: 0.2850\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3442 - mean_squared_error: 0.2842\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3264 - mean_squared_error: 0.2835\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3090 - mean_squared_error: 0.2828\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.2917 - mean_squared_error: 0.2822\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 1.2748 - mean_squared_error: 0.2816\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2582 - mean_squared_error: 0.2810\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2418 - mean_squared_error: 0.2804\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2257 - mean_squared_error: 0.2799\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2098 - mean_squared_error: 0.2794\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 1.1941 - mean_squared_error: 0.2790\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1788 - mean_squared_error: 0.2786\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1637 - mean_squared_error: 0.2781\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1487 - mean_squared_error: 0.2775\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1340 - mean_squared_error: 0.2770\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1197 - mean_squared_error: 0.2765\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1054 - mean_squared_error: 0.2760\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0915 - mean_squared_error: 0.2755\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0777 - mean_squared_error: 0.2751\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0642 - mean_squared_error: 0.2747\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0510 - mean_squared_error: 0.2743\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 1.0379 - mean_squared_error: 0.2739\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0250 - mean_squared_error: 0.2735\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 1.0124 - mean_squared_error: 0.2732\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9999 - mean_squared_error: 0.2728\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9876 - mean_squared_error: 0.2724\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9756 - mean_squared_error: 0.2720\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9638 - mean_squared_error: 0.2716\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9521 - mean_squared_error: 0.2712\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9407 - mean_squared_error: 0.2709\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.9294 - mean_squared_error: 0.2706\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9184 - mean_squared_error: 0.2703\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9075 - mean_squared_error: 0.2701\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8968 - mean_squared_error: 0.2699\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8862 - mean_squared_error: 0.2697\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8759 - mean_squared_error: 0.2694\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8657 - mean_squared_error: 0.2691\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8557 - mean_squared_error: 0.2688\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8459 - mean_squared_error: 0.2687\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8361 - mean_squared_error: 0.2683\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8266 - mean_squared_error: 0.2683\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8172 - mean_squared_error: 0.2681\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8080 - mean_squared_error: 0.2679\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7990 - mean_squared_error: 0.2678\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7901 - mean_squared_error: 0.2676\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7814 - mean_squared_error: 0.2675\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7728 - mean_squared_error: 0.2674\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.7644 - mean_squared_error: 0.2673\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7560 - mean_squared_error: 0.2671\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7479 - mean_squared_error: 0.2670\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7398 - mean_squared_error: 0.2668\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7319 - mean_squared_error: 0.2666\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7242 - mean_squared_error: 0.2664\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7166 - mean_squared_error: 0.2663\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7091 - mean_squared_error: 0.2662\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7017 - mean_squared_error: 0.2661\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6945 - mean_squared_error: 0.2661\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6873 - mean_squared_error: 0.2660\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6803 - mean_squared_error: 0.2659\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6734 - mean_squared_error: 0.2659\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6667 - mean_squared_error: 0.2658\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6600 - mean_squared_error: 0.2657\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6535 - mean_squared_error: 0.2656\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6471 - mean_squared_error: 0.2655\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6408 - mean_squared_error: 0.2654\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6347 - mean_squared_error: 0.2653\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6285 - mean_squared_error: 0.2650\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6225 - mean_squared_error: 0.2648\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6165 - mean_squared_error: 0.2645\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6107 - mean_squared_error: 0.2643\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6050 - mean_squared_error: 0.2641\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5994 - mean_squared_error: 0.2640\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5939 - mean_squared_error: 0.2639\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5885 - mean_squared_error: 0.2639\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5834 - mean_squared_error: 0.2642\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5781 - mean_squared_error: 0.2641\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5730 - mean_squared_error: 0.2641\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5679 - mean_squared_error: 0.2640\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5629 - mean_squared_error: 0.2639\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5581 - mean_squared_error: 0.2638\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5533 - mean_squared_error: 0.2637\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5487 - mean_squared_error: 0.2637\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5440 - mean_squared_error: 0.2635\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5395 - mean_squared_error: 0.2635\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5350 - mean_squared_error: 0.2634\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5306 - mean_squared_error: 0.2633\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5263 - mean_squared_error: 0.2634\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5221 - mean_squared_error: 0.2635\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5179 - mean_squared_error: 0.2634\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5138 - mean_squared_error: 0.2635\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5098 - mean_squared_error: 0.2635\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5059 - mean_squared_error: 0.2636\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5020 - mean_squared_error: 0.2635\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4982 - mean_squared_error: 0.2634\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4945 - mean_squared_error: 0.2633\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4908 - mean_squared_error: 0.2632\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4872 - mean_squared_error: 0.2631\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4837 - mean_squared_error: 0.2630\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4803 - mean_squared_error: 0.2630\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4769 - mean_squared_error: 0.2630\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4735 - mean_squared_error: 0.2629\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 385.78125 262.19625\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-10-20T21:47:52.820505</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 385.78125 262.19625 \nL 385.78125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 224.64 \nL 378.58125 224.64 \nL 378.58125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m8f9cf5f910\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#m8f9cf5f910\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(55.818182 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.23607\" xlink:href=\"#m8f9cf5f910\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(90.87357 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"135.472707\" xlink:href=\"#m8f9cf5f910\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(129.110207 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"173.709345\" xlink:href=\"#m8f9cf5f910\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(167.346845 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"211.945983\" xlink:href=\"#m8f9cf5f910\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(202.402233 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"250.18262\" xlink:href=\"#m8f9cf5f910\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(240.63887 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"288.419258\" xlink:href=\"#m8f9cf5f910\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(278.875508 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"326.655896\" xlink:href=\"#m8f9cf5f910\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(317.112146 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"364.892534\" xlink:href=\"#m8f9cf5f910\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(355.348784 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Epoch -->\n     <g transform=\"translate(195.870313 252.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m35e1b79f7d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m35e1b79f7d\" y=\"203.194037\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.5 -->\n      <g transform=\"translate(20.878125 206.993256)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m35e1b79f7d\" y=\"160.340954\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 164.140172)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m35e1b79f7d\" y=\"117.48787\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.5 -->\n      <g transform=\"translate(20.878125 121.287089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m35e1b79f7d\" y=\"74.634786\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 2.0 -->\n      <g transform=\"translate(20.878125 78.434005)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m35e1b79f7d\" y=\"31.781703\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2.5 -->\n      <g transform=\"translate(20.878125 35.580922)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Mean Squared Error -->\n     <g transform=\"translate(14.798438 165.681719)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n       <path d=\"M 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\nM 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nL 54.390625 -20.796875 \nL 45.40625 -20.796875 \nz\n\" id=\"DejaVuSans-113\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"86.279297\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"147.802734\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"209.082031\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"272.460938\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"304.248047\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"367.724609\" xlink:href=\"#DejaVuSans-113\"/>\n      <use x=\"431.201172\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"494.580078\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"555.859375\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"594.722656\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"656.246094\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"719.722656\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"751.509766\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"814.693359\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"854.056641\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"892.919922\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"954.101562\" xlink:href=\"#DejaVuSans-114\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p2149b654e7)\" d=\"M 58.999432 14.156712 \nL 62.058363 52.849036 \nL 63.587828 70.297437 \nL 65.117294 86.279743 \nL 66.646759 100.688237 \nL 68.176225 113.769986 \nL 69.70569 125.78165 \nL 71.235156 136.056541 \nL 72.764621 145.378322 \nL 74.294087 153.627974 \nL 75.823552 160.813672 \nL 77.353018 167.068661 \nL 78.882483 172.48366 \nL 80.411949 177.191876 \nL 81.941414 181.246011 \nL 83.47088 184.784889 \nL 85.000345 187.791161 \nL 86.529811 190.490137 \nL 88.059276 192.780839 \nL 89.588742 194.836212 \nL 92.647673 198.204865 \nL 95.706604 200.890835 \nL 98.765535 203.146058 \nL 101.824466 205.005079 \nL 104.883397 206.624503 \nL 109.471794 208.57726 \nL 114.06019 210.153496 \nL 118.648587 211.48996 \nL 126.295914 213.360135 \nL 133.943242 214.878061 \nL 140.061104 215.873015 \nL 150.767362 217.333855 \nL 159.944155 218.336794 \nL 172.17988 219.422179 \nL 187.474535 220.525819 \nL 207.357586 221.481555 \nL 221.122776 222.015208 \nL 257.829948 222.878583 \nL 322.067499 223.426409 \nL 329.714827 223.431502 \nL 363.363068 223.513309 \nL 363.363068 223.513309 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 224.64 \nL 43.78125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 378.58125 224.64 \nL 378.58125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 224.64 \nL 378.58125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 378.58125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 317.646875 29.878125 \nL 371.58125 29.878125 \nQ 373.58125 29.878125 373.58125 27.878125 \nL 373.58125 14.2 \nQ 373.58125 12.2 371.58125 12.2 \nL 317.646875 12.2 \nQ 315.646875 12.2 315.646875 14.2 \nL 315.646875 27.878125 \nQ 315.646875 29.878125 317.646875 29.878125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 319.646875 20.298437 \nL 339.646875 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_17\"/>\n    <g id=\"text_17\">\n     <!-- Loss -->\n     <g transform=\"translate(347.646875 23.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p2149b654e7\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f32c34d0b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4921 - mean_squared_error: 0.2843\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4921499192714691, 0.28434568643569946]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc7SfS8E7jHx",
        "outputId": "df184249-deae-4eba-b896-ab230f4ea57d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "# Node tuning\n",
        "learning_rate = 0.0015\n",
        "epochs = 100\n",
        "batch_size = 1000\n",
        "n_layers = 1\n",
        "n_nodes = [[25], [15], [10]]\n",
        "\n",
        "# Test data\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "\n",
        "average_mses = []\n",
        "for nodes in n_nodes:\n",
        "    mse_simulation = []\n",
        "    # 10 simulations for each node hyperparamter\n",
        "    for i in range(10):\n",
        "        # Specify the label\n",
        "        label_name = \"price\"\n",
        "\n",
        "        # Establish the model's topography.\n",
        "        my_model = create_model(learning_rate, my_feature_layer, n_layers, nodes)\n",
        "\n",
        "        # Train the model on the normalized training set. We're passing the entire\n",
        "        # normalized training set, but the model will only use the features\n",
        "        # defined by the feature_layer.\n",
        "        epoch, mse = train_model(my_model, train_df_norm, epochs, \n",
        "                                label_name, batch_size)\n",
        "        \n",
        "        # After building a model against the training set, test that model\n",
        "        # against the test set.\n",
        "        print(\"\\n Evaluate the new model against the test set:\")\n",
        "        mse = my_model.evaluate(x = test_features, \n",
        "                                y = test_label, \n",
        "                                batch_size=batch_size)[1]\n",
        "        mse_simulation.append(mse)                        \n",
        "        print('Training MSE:', mse)\n",
        "        print('+'*75)\n",
        "    average_mse = np.array(mse_simulation).mean()\n",
        "    average_mses.append(average_mse)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ms_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 4.7281 - mean_squared_error: 1.4234\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 4.5854 - mean_squared_error: 1.3352\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.4490 - mean_squared_error: 1.2532\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.3236 - mean_squared_error: 1.1815\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.2009 - mean_squared_error: 1.1126\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.0847 - mean_squared_error: 1.0510\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9760 - mean_squared_error: 0.9970\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8730 - mean_squared_error: 0.9487\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.7741 - mean_squared_error: 0.9047\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6794 - mean_squared_error: 0.8652\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.5900 - mean_squared_error: 0.8310\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.5044 - mean_squared_error: 0.8007\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.4211 - mean_squared_error: 0.7727\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3410 - mean_squared_error: 0.7479\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2639 - mean_squared_error: 0.7258\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.1888 - mean_squared_error: 0.7055\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.1163 - mean_squared_error: 0.6874\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.0455 - mean_squared_error: 0.6705\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 2.9761 - mean_squared_error: 0.6548\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.9084 - mean_squared_error: 0.6402\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.8426 - mean_squared_error: 0.6268\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.7786 - mean_squared_error: 0.6144\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.7158 - mean_squared_error: 0.6024\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.6546 - mean_squared_error: 0.5910\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.5948 - mean_squared_error: 0.5803\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.5365 - mean_squared_error: 0.5702\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4796 - mean_squared_error: 0.5605\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.4242 - mean_squared_error: 0.5514\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.3697 - mean_squared_error: 0.5424\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.3167 - mean_squared_error: 0.5339\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2650 - mean_squared_error: 0.5258\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.2146 - mean_squared_error: 0.5181\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.1652 - mean_squared_error: 0.5106\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.1171 - mean_squared_error: 0.5035\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.0698 - mean_squared_error: 0.4964\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 2.0241 - mean_squared_error: 0.4900\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9792 - mean_squared_error: 0.4836\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.9354 - mean_squared_error: 0.4776\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8927 - mean_squared_error: 0.4717\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8507 - mean_squared_error: 0.4659\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8100 - mean_squared_error: 0.4606\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.7702 - mean_squared_error: 0.4554\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7313 - mean_squared_error: 0.4502\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.6932 - mean_squared_error: 0.4452\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.6563 - mean_squared_error: 0.4404\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.6198 - mean_squared_error: 0.4351\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5845 - mean_squared_error: 0.4302\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5500 - mean_squared_error: 0.4255\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5164 - mean_squared_error: 0.4207\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.4832 - mean_squared_error: 0.4157\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.4510 - mean_squared_error: 0.4110\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4197 - mean_squared_error: 0.4067\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.3892 - mean_squared_error: 0.4027\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3593 - mean_squared_error: 0.3986\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3302 - mean_squared_error: 0.3946\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3018 - mean_squared_error: 0.3909\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2741 - mean_squared_error: 0.3872\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2471 - mean_squared_error: 0.3836\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.2206 - mean_squared_error: 0.3801\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1948 - mean_squared_error: 0.3765\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1698 - mean_squared_error: 0.3733\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1454 - mean_squared_error: 0.3700\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1214 - mean_squared_error: 0.3669\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0981 - mean_squared_error: 0.3639\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0754 - mean_squared_error: 0.3610\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0532 - mean_squared_error: 0.3580\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0317 - mean_squared_error: 0.3551\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0107 - mean_squared_error: 0.3522\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9902 - mean_squared_error: 0.3492\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9701 - mean_squared_error: 0.3462\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9507 - mean_squared_error: 0.3435\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9317 - mean_squared_error: 0.3407\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9132 - mean_squared_error: 0.3381\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8953 - mean_squared_error: 0.3356\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8779 - mean_squared_error: 0.3333\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8608 - mean_squared_error: 0.3308\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.8442 - mean_squared_error: 0.3287\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8281 - mean_squared_error: 0.3266\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8123 - mean_squared_error: 0.3245\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7969 - mean_squared_error: 0.3226\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7822 - mean_squared_error: 0.3208\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7678 - mean_squared_error: 0.3189\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7536 - mean_squared_error: 0.3169\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7398 - mean_squared_error: 0.3148\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7265 - mean_squared_error: 0.3128\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7136 - mean_squared_error: 0.3110\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7010 - mean_squared_error: 0.3092\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6888 - mean_squared_error: 0.3075\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6770 - mean_squared_error: 0.3060\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6654 - mean_squared_error: 0.3044\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6542 - mean_squared_error: 0.3029\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6432 - mean_squared_error: 0.3014\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6325 - mean_squared_error: 0.2999\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6223 - mean_squared_error: 0.2988\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6123 - mean_squared_error: 0.2976\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6027 - mean_squared_error: 0.2965\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5933 - mean_squared_error: 0.2953\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5843 - mean_squared_error: 0.2941\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5753 - mean_squared_error: 0.2927\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5668 - mean_squared_error: 0.2916\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f32c2fcf8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5741 - mean_squared_error: 0.3050\n",
            "Training MSE: 0.3049650192260742\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohqIZIP9IxsU",
        "outputId": "c3c102e3-5b81-47e0-fd0d-c5a39ca5fb90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print('Average mses for number of nodes:')\n",
        "for i in range(len(n_nodes)):\n",
        "    print(n_nodes[i], 'number of nodes: average mse =', average_mses[i])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average mses for number of nodes:\n[25] number of nodes: average mse = 0.29215354323387144\n[15] number of nodes: average mse = 0.2897717922925949\n[10] number of nodes: average mse = 0.31062056720256803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjwmdiQfRgTF"
      },
      "source": [
        "One layer performs best, with similar results using ReLu and Tanh activation.\n",
        "There doesn't seem to be a significant diffence in the performance of the linear and non linear nets. The simplest model will be chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_38\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_features_3 (DenseFeatu multiple                  0         \n_________________________________________________________________\nHidden0 (Dense)              multiple                  585       \n_________________________________________________________________\nOutput (Dense)               multiple                  16        \n=================================================================\nTotal params: 601\nTrainable params: 601\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "my_model.summary()"
      ]
    },
    {
      "source": [
        "I had issues saving and loading the previous model which seemed to be due to the tf.feature_colum representation of the data. I therefore created another model to allow proper saving and loading."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "## Save Linear Model as File"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    # Create a simple model.\n",
        "    inputs = keras.Input(shape=(18,))\n",
        "    outputs = keras.layers.Dense(1)(inputs)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for b in boolean_features:\n",
        "#     train_df_norm[b] = train_df_norm[b].apply(lambda x: 1 if x == 'True' else 0)\n",
        "#     test_df_norm[b] = test_df_norm[b].apply(lambda x: 1 if x == 'True' else 0)\n",
        "# test_df_norm[boolean_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['price', 'lat', 'long', 'restaurants', 'vibrant', 'cycling_friendly',\n",
              "       'car_friendly', 'historic', 'quiet', 'parks', 'groceries', 'cafes',\n",
              "       'transit_friendly', 'greenery', 'year_built', 'walk_score', 'bedrooms',\n",
              "       'bathrooms', 'powder_rooms', 'total_area', 'mr_distance'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "test_df_norm.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, dataset, epochs, label_name):\n",
        "    \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "    # Split the dataset into features and label.\n",
        "    features = dataset.copy()\n",
        "    label = np.array(features.pop(label_name))\n",
        "    feature = features.to_numpy()\n",
        "    history = model.fit(x=features, y=label,\n",
        "                        epochs=epochs)\n",
        "\n",
        "    # Get details that will be useful for plotting the loss curve.\n",
        "    epoch = history.epoch\n",
        "    rmse = history.history[\"loss\"]\n",
        "\n",
        "    return epoch, rmse   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288560611328.0000\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288560513024.0000\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288560349184.0000\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288560250880.0000\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288560185344.0000\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 0s 986us/step - loss: 288560054272.0000\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288559955968.0000\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288559857664.0000\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288559792128.0000\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 0s 970us/step - loss: 288559595520.0000\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288559529984.0000\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288559398912.0000\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288559333376.0000\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288559267840.0000\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288559202304.0000\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288559038464.0000\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288558972928.0000\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288558776320.0000\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288558743552.0000\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288558645248.0000\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288558546944.0000\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288558415872.0000\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288558317568.0000\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288558186496.0000\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288558186496.0000\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557989888.0000\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557826048.0000\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557760512.0000\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557694976.0000\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557498368.0000\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557498368.0000\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557367296.0000\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557268992.0000\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557137920.0000\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288557072384.0000\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288556974080.0000\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288556843008.0000\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288556711936.0000\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288556613632.0000\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288556482560.0000\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288556417024.0000\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288556351488.0000\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288556220416.0000\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288556056576.0000\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288555958272.0000\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288555892736.0000\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288555794432.0000\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288555696128.0000\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288555565056.0000\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288555466752.0000\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288555335680.0000\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288555270144.0000\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288555204608.0000\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288554975232.0000\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288554942464.0000\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288554876928.0000\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288554745856.0000\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288554680320.0000\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288554549248.0000\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288554483712.0000\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288554352640.0000\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288554188800.0000\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288554123264.0000\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288553992192.0000\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288553926656.0000\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288553861120.0000\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 288553664512.0000\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 288553598976.0000\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288553467904.0000\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288553369600.0000\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288553336832.0000\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288553205760.0000\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288553074688.0000\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 288552976384.0000\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288552910848.0000\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288552714240.0000\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288552648704.0000\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288552550400.0000\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288552452096.0000\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288552321024.0000\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288552189952.0000\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288552157184.0000\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 0s 954us/step - loss: 288552058880.0000\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288551927808.0000\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288551796736.0000\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288551731200.0000\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288551600128.0000\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288551567360.0000\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288551370752.0000\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288551305216.0000\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288551206912.0000\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288551043072.0000\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288550977536.0000\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288550912000.0000\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288550813696.0000\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288550748160.0000\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288550551552.0000\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288550453248.0000\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288550322176.0000\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 288550256640.0000\n",
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 327530446848.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327530446848.0"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "# Specify the label, batchsize and model\n",
        "label_name = \"price\"\n",
        "batch_size = 1000\n",
        "model = get_model()\n",
        "\n",
        "# Train the model.\n",
        "epochs, mse = train_model(model, train_df_norm.drop(['lat', 'long'], axis=1), 100, label_name)\n",
        "\n",
        "# Validation\n",
        "test_features = test_df_norm.iloc[:, 3 :].to_numpy()\n",
        "test_label = np.array(test_df_norm.price) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "model.evaluate(x = test_features, y = test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "572302.7580293494"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "np.sqrt(327530446848.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"functional_31\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_16 (InputLayer)        [(None, 18)]              0         \n_________________________________________________________________\ndense_16 (Dense)             (None, 1)                 19        \n=================================================================\nTotal params: 19\nTrainable params: 19\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Save model as 'tf'\n",
        "# model.save('web-app/tf_linear_model_2')\n",
        "\n",
        "# Load model\n",
        "reconstructed_model = keras.models.load_model('web-app/tf_linear_model_2', compile=True)\n",
        "reconstructed_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing\n",
        "test_input = test_df_norm.iloc[:, 3:]\n",
        "test_target = test_df_norm.price.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.11492658],\n",
              "       [-0.32514444],\n",
              "       [-0.30683163],\n",
              "       [-0.9980568 ],\n",
              "       [-0.5387163 ],\n",
              "       [ 0.4361036 ],\n",
              "       [ 0.23225535],\n",
              "       [ 0.6241727 ],\n",
              "       [ 0.4155161 ],\n",
              "       [ 0.63147104],\n",
              "       [-0.47266498],\n",
              "       [-0.8737802 ],\n",
              "       [ 0.05246219],\n",
              "       [-0.6265605 ],\n",
              "       [-0.1915634 ],\n",
              "       [-0.412644  ],\n",
              "       [-0.31058612],\n",
              "       [-0.8018513 ],\n",
              "       [-0.21564727],\n",
              "       [-0.18644427],\n",
              "       [-0.6432509 ],\n",
              "       [ 1.7280805 ],\n",
              "       [-0.21413948],\n",
              "       [-1.0032072 ],\n",
              "       [ 0.06475769],\n",
              "       [ 0.56328803],\n",
              "       [ 0.09766158],\n",
              "       [-0.38006327],\n",
              "       [ 0.20624168],\n",
              "       [-0.9213267 ],\n",
              "       [ 0.3620706 ],\n",
              "       [ 0.9839985 ],\n",
              "       [ 0.81079495],\n",
              "       [-0.5890024 ],\n",
              "       [-1.0365664 ],\n",
              "       [ 1.2487364 ],\n",
              "       [ 0.44970426],\n",
              "       [-0.38488922],\n",
              "       [ 0.31931454],\n",
              "       [ 0.14672104],\n",
              "       [-0.40817285],\n",
              "       [ 1.2096558 ],\n",
              "       [ 1.0524616 ],\n",
              "       [ 0.00970267],\n",
              "       [-0.02101753],\n",
              "       [-0.63122463],\n",
              "       [-0.91901195],\n",
              "       [-0.7085264 ],\n",
              "       [-0.3705791 ],\n",
              "       [-0.334077  ],\n",
              "       [ 0.01598542],\n",
              "       [ 1.1766975 ],\n",
              "       [ 0.8069431 ],\n",
              "       [-0.16790935],\n",
              "       [-0.11093768],\n",
              "       [-0.44977397],\n",
              "       [-1.3267025 ],\n",
              "       [ 0.59493667],\n",
              "       [ 0.75612724],\n",
              "       [ 0.69124943],\n",
              "       [ 1.3778667 ],\n",
              "       [-1.0700799 ],\n",
              "       [-0.8100562 ],\n",
              "       [-0.12954341],\n",
              "       [ 0.7026658 ],\n",
              "       [ 0.00970267],\n",
              "       [ 1.2798289 ],\n",
              "       [-0.41780508],\n",
              "       [-0.02652418],\n",
              "       [-0.55710196],\n",
              "       [-1.1004847 ],\n",
              "       [ 0.7635568 ],\n",
              "       [-0.3388604 ],\n",
              "       [ 1.2887281 ],\n",
              "       [-0.20945491],\n",
              "       [-0.69474113],\n",
              "       [ 0.76227444],\n",
              "       [ 1.4412161 ],\n",
              "       [-0.02732856],\n",
              "       [-0.5977908 ],\n",
              "       [-0.23008412],\n",
              "       [ 1.0221466 ],\n",
              "       [ 0.1335452 ],\n",
              "       [ 0.4347851 ],\n",
              "       [-0.581168  ],\n",
              "       [-0.03457851],\n",
              "       [ 0.01423523],\n",
              "       [-0.1374027 ],\n",
              "       [-0.31424412],\n",
              "       [ 0.13573708],\n",
              "       [-0.11378311],\n",
              "       [ 1.4505198 ],\n",
              "       [-0.07196737],\n",
              "       [ 0.3805522 ],\n",
              "       [-0.16170466],\n",
              "       [-0.21905527],\n",
              "       [ 0.06368849],\n",
              "       [-0.01486545],\n",
              "       [-0.71999234],\n",
              "       [ 1.145495  ],\n",
              "       [-0.17706874],\n",
              "       [ 0.03757685],\n",
              "       [ 0.5154658 ],\n",
              "       [-0.43775183],\n",
              "       [-0.07417952],\n",
              "       [-0.73249704],\n",
              "       [-0.60506994],\n",
              "       [-1.0764669 ],\n",
              "       [-0.7068631 ],\n",
              "       [-0.54052275],\n",
              "       [ 0.8261904 ],\n",
              "       [-0.09389538],\n",
              "       [-1.0342734 ],\n",
              "       [-0.34956786],\n",
              "       [ 1.0182719 ],\n",
              "       [ 0.5434195 ],\n",
              "       [ 0.03843047],\n",
              "       [ 0.15824342],\n",
              "       [-0.928543  ],\n",
              "       [ 0.43003383],\n",
              "       [-0.2806476 ],\n",
              "       [-0.36737004],\n",
              "       [-1.1413194 ],\n",
              "       [-0.4335065 ],\n",
              "       [-0.2868932 ],\n",
              "       [-1.0688405 ],\n",
              "       [-0.3043978 ],\n",
              "       [ 0.29322836],\n",
              "       [-0.9816515 ],\n",
              "       [-0.37667692],\n",
              "       [ 2.0815382 ],\n",
              "       [-0.7328628 ],\n",
              "       [-0.420039  ],\n",
              "       [-0.20872125],\n",
              "       [ 1.0437685 ],\n",
              "       [ 0.52652127],\n",
              "       [ 0.68993   ],\n",
              "       [ 1.0125875 ],\n",
              "       [ 0.04738835],\n",
              "       [ 0.01951147],\n",
              "       [-0.4090649 ],\n",
              "       [-0.619107  ],\n",
              "       [-0.4231554 ],\n",
              "       [ 0.09267295],\n",
              "       [ 0.06436335],\n",
              "       [-0.79609585],\n",
              "       [-0.5760459 ],\n",
              "       [-0.04118271],\n",
              "       [-0.32249376],\n",
              "       [-0.44339252],\n",
              "       [-0.49128786],\n",
              "       [ 1.1334212 ],\n",
              "       [ 0.00970267],\n",
              "       [ 1.5857338 ],\n",
              "       [-0.14847782],\n",
              "       [-0.43548176],\n",
              "       [-0.11089379],\n",
              "       [ 0.6248571 ],\n",
              "       [ 0.27682975],\n",
              "       [ 0.11316479],\n",
              "       [ 0.48746052],\n",
              "       [-0.25515807],\n",
              "       [-0.19025944],\n",
              "       [-0.8636397 ],\n",
              "       [ 0.15155767],\n",
              "       [-0.31148326],\n",
              "       [-0.41968277],\n",
              "       [-0.5712568 ],\n",
              "       [-0.39236647],\n",
              "       [-0.6622166 ],\n",
              "       [-0.30284807],\n",
              "       [-0.26299602],\n",
              "       [-0.47722474],\n",
              "       [ 0.03811168],\n",
              "       [-0.6142303 ],\n",
              "       [-0.44272855],\n",
              "       [-0.5441027 ],\n",
              "       [-0.31811082],\n",
              "       [-0.26335147],\n",
              "       [-0.30016616],\n",
              "       [-0.9548316 ],\n",
              "       [-0.62858224],\n",
              "       [ 1.0004187 ],\n",
              "       [ 0.1189638 ],\n",
              "       [ 1.23457   ],\n",
              "       [ 1.8305017 ],\n",
              "       [ 0.00970267],\n",
              "       [ 1.2904174 ],\n",
              "       [ 0.05497139],\n",
              "       [ 0.00970267],\n",
              "       [ 0.22302969],\n",
              "       [ 1.018377  ],\n",
              "       [-0.05013158],\n",
              "       [ 1.4313799 ],\n",
              "       [-0.02789667],\n",
              "       [ 0.6357341 ],\n",
              "       [-0.4822364 ],\n",
              "       [ 0.53139085],\n",
              "       [ 0.6606888 ],\n",
              "       [-1.0288874 ],\n",
              "       [-0.8202579 ],\n",
              "       [-0.64582014],\n",
              "       [ 0.6882398 ],\n",
              "       [-0.16404471],\n",
              "       [-0.04160384],\n",
              "       [ 0.8323329 ],\n",
              "       [-0.95869625],\n",
              "       [-0.23450682],\n",
              "       [-0.71323466],\n",
              "       [-0.43906382],\n",
              "       [-0.54074854],\n",
              "       [-0.23438592],\n",
              "       [ 0.4364462 ],\n",
              "       [ 0.03979924],\n",
              "       [ 1.5357838 ],\n",
              "       [ 0.8588838 ],\n",
              "       [-0.37102985],\n",
              "       [-0.6229916 ],\n",
              "       [-0.40643695],\n",
              "       [-0.0487525 ],\n",
              "       [ 0.12059519],\n",
              "       [ 0.22498783],\n",
              "       [ 0.16021107],\n",
              "       [-0.3079572 ],\n",
              "       [ 0.56496084],\n",
              "       [-1.1100482 ],\n",
              "       [-0.14827262],\n",
              "       [-0.33836642],\n",
              "       [-0.470173  ],\n",
              "       [ 0.03489285],\n",
              "       [-0.00444723],\n",
              "       [ 0.4141805 ],\n",
              "       [-0.75463784],\n",
              "       [-0.12059461],\n",
              "       [-0.82580936],\n",
              "       [-0.05321522],\n",
              "       [-0.47392157],\n",
              "       [-0.10655441],\n",
              "       [ 0.7207951 ],\n",
              "       [-0.59369665],\n",
              "       [ 0.03988259],\n",
              "       [-0.55513877],\n",
              "       [ 1.0473881 ],\n",
              "       [-0.55505157],\n",
              "       [-0.57722634],\n",
              "       [-0.6139696 ],\n",
              "       [-0.01991329],\n",
              "       [ 0.620359  ],\n",
              "       [-0.35377768],\n",
              "       [-0.5215946 ],\n",
              "       [-1.2261602 ],\n",
              "       [ 0.07559022],\n",
              "       [-0.71143174],\n",
              "       [ 0.13414791],\n",
              "       [-0.22493418],\n",
              "       [ 1.1126654 ],\n",
              "       [ 0.9145164 ],\n",
              "       [ 1.5614994 ],\n",
              "       [-0.44838881],\n",
              "       [-1.0489906 ],\n",
              "       [-0.5474074 ],\n",
              "       [-1.3249428 ],\n",
              "       [ 0.23106872],\n",
              "       [ 1.288889  ],\n",
              "       [-0.5874016 ],\n",
              "       [ 0.01243505],\n",
              "       [-0.51443785],\n",
              "       [ 0.64452994],\n",
              "       [-0.5281964 ],\n",
              "       [-0.70470726],\n",
              "       [-0.19007288],\n",
              "       [-0.6320826 ],\n",
              "       [-0.62065005],\n",
              "       [ 0.74543387],\n",
              "       [-0.34242666],\n",
              "       [-0.26364064],\n",
              "       [-0.65678984],\n",
              "       [-0.6953482 ],\n",
              "       [ 1.2551752 ],\n",
              "       [ 2.339244  ],\n",
              "       [-0.4406565 ],\n",
              "       [ 3.3531268 ],\n",
              "       [ 0.22944804],\n",
              "       [-0.5993526 ],\n",
              "       [ 0.1611462 ],\n",
              "       [-0.18137592],\n",
              "       [-0.17760634],\n",
              "       [-0.2035798 ],\n",
              "       [-0.71580094],\n",
              "       [-0.00589676],\n",
              "       [ 0.10433645],\n",
              "       [-0.6304346 ],\n",
              "       [-0.6316949 ],\n",
              "       [-0.63747096],\n",
              "       [-0.68687326],\n",
              "       [-0.42160597],\n",
              "       [-0.29538843],\n",
              "       [-0.5611736 ],\n",
              "       [ 1.2096558 ],\n",
              "       [-0.22996381],\n",
              "       [-0.17648345],\n",
              "       [-0.13857852],\n",
              "       [-0.22322471],\n",
              "       [ 0.11462971],\n",
              "       [-0.30703595],\n",
              "       [-0.3214471 ],\n",
              "       [ 0.3549328 ],\n",
              "       [-0.16745542],\n",
              "       [-0.8034492 ],\n",
              "       [-0.50471693],\n",
              "       [-0.48914003],\n",
              "       [ 0.00431729],\n",
              "       [-0.06569277],\n",
              "       [-1.0152066 ],\n",
              "       [ 0.21744847],\n",
              "       [-1.086487  ],\n",
              "       [-0.16590577],\n",
              "       [-0.8267996 ],\n",
              "       [-0.03791403],\n",
              "       [ 2.4529812 ],\n",
              "       [-0.10413381],\n",
              "       [-0.63292766],\n",
              "       [-0.8367882 ],\n",
              "       [-0.2505758 ],\n",
              "       [-0.79049367],\n",
              "       [ 0.03910271],\n",
              "       [-0.7486818 ],\n",
              "       [ 1.623222  ],\n",
              "       [ 0.04767467],\n",
              "       [-1.3940312 ],\n",
              "       [-0.2682853 ],\n",
              "       [-0.17809293],\n",
              "       [-0.82103765],\n",
              "       [ 0.06548559],\n",
              "       [-0.96972865],\n",
              "       [-0.4759536 ],\n",
              "       [-0.57768065],\n",
              "       [ 0.7425413 ],\n",
              "       [-0.614077  ],\n",
              "       [-0.6171537 ],\n",
              "       [ 0.6382472 ],\n",
              "       [-0.2873434 ],\n",
              "       [ 1.2296271 ],\n",
              "       [-0.52692485],\n",
              "       [ 0.22299938],\n",
              "       [-0.66158354],\n",
              "       [ 0.820218  ],\n",
              "       [-0.67507   ],\n",
              "       [ 0.00594399],\n",
              "       [ 0.14441848],\n",
              "       [ 3.559931  ],\n",
              "       [-0.9328572 ],\n",
              "       [-0.25383505],\n",
              "       [ 0.81513226],\n",
              "       [ 0.20659618],\n",
              "       [ 1.3265733 ],\n",
              "       [ 0.04870159],\n",
              "       [ 0.7680223 ],\n",
              "       [-0.17434828],\n",
              "       [-0.3648695 ],\n",
              "       [ 1.1658844 ],\n",
              "       [-0.45594713],\n",
              "       [-0.10479318],\n",
              "       [ 0.22902454],\n",
              "       [ 0.36267725],\n",
              "       [-0.24620748],\n",
              "       [-1.0242454 ],\n",
              "       [-0.4663933 ],\n",
              "       [ 0.05712583],\n",
              "       [-0.48720908],\n",
              "       [-0.6207934 ],\n",
              "       [ 1.6518756 ],\n",
              "       [ 0.6158362 ],\n",
              "       [ 1.5261681 ],\n",
              "       [ 0.38626873],\n",
              "       [-0.05964218],\n",
              "       [-0.90752894],\n",
              "       [-0.0733489 ],\n",
              "       [-0.13116924],\n",
              "       [ 0.02276584],\n",
              "       [ 0.8836782 ],\n",
              "       [-0.1666528 ],\n",
              "       [-0.12762493],\n",
              "       [-1.1888199 ],\n",
              "       [-0.39772755],\n",
              "       [-0.05474192],\n",
              "       [-0.8883701 ],\n",
              "       [ 0.6239357 ],\n",
              "       [ 0.7721403 ],\n",
              "       [-0.53431195],\n",
              "       [-0.10247666],\n",
              "       [-0.9258639 ],\n",
              "       [-0.50308216],\n",
              "       [-0.570138  ],\n",
              "       [ 0.4815114 ],\n",
              "       [ 0.4010702 ],\n",
              "       [ 0.58753425],\n",
              "       [-0.12936433],\n",
              "       [ 0.54843956],\n",
              "       [-0.42139387],\n",
              "       [-0.1807772 ],\n",
              "       [-0.81497306],\n",
              "       [ 0.35834515],\n",
              "       [ 0.95450395],\n",
              "       [ 0.28316173],\n",
              "       [ 1.0538107 ],\n",
              "       [ 0.9484965 ],\n",
              "       [-0.17404366],\n",
              "       [ 1.3823565 ],\n",
              "       [ 1.5673295 ],\n",
              "       [-0.838909  ],\n",
              "       [-0.56371796],\n",
              "       [-0.49756524],\n",
              "       [ 0.96572906],\n",
              "       [-0.9894505 ],\n",
              "       [ 0.79984057],\n",
              "       [-0.8221218 ],\n",
              "       [ 0.9120754 ],\n",
              "       [-0.9972941 ],\n",
              "       [-0.01404502],\n",
              "       [ 0.6710517 ],\n",
              "       [-0.91594106],\n",
              "       [ 1.0959749 ],\n",
              "       [ 0.09218252],\n",
              "       [ 0.27009407],\n",
              "       [ 0.39970008],\n",
              "       [ 0.5803482 ],\n",
              "       [ 1.8825294 ],\n",
              "       [ 0.5362254 ],\n",
              "       [-0.37567285],\n",
              "       [ 0.1433448 ],\n",
              "       [-0.5928126 ],\n",
              "       [ 0.04199617],\n",
              "       [-0.7736767 ],\n",
              "       [ 0.11661107],\n",
              "       [ 0.70843565],\n",
              "       [ 0.28157142],\n",
              "       [ 1.925626  ],\n",
              "       [-1.5203292 ],\n",
              "       [ 0.4768992 ],\n",
              "       [ 0.68109244],\n",
              "       [ 1.5808922 ],\n",
              "       [-0.25274202],\n",
              "       [-0.6300184 ],\n",
              "       [-0.8035311 ],\n",
              "       [ 0.06498016],\n",
              "       [-0.22000997],\n",
              "       [-0.58790886],\n",
              "       [ 1.0366269 ],\n",
              "       [ 0.51276886],\n",
              "       [-0.7086964 ],\n",
              "       [-0.09714266],\n",
              "       [ 0.7368281 ],\n",
              "       [-0.2607505 ],\n",
              "       [-1.0271654 ],\n",
              "       [-0.77786314],\n",
              "       [-0.40280122],\n",
              "       [-1.3271465 ],\n",
              "       [-0.6058024 ],\n",
              "       [-0.5093211 ],\n",
              "       [ 0.08458003],\n",
              "       [ 0.44246432],\n",
              "       [-0.25338313],\n",
              "       [ 1.4751862 ],\n",
              "       [ 0.04103619],\n",
              "       [-0.17823292],\n",
              "       [-1.5438387 ],\n",
              "       [-1.0010802 ],\n",
              "       [-0.16898286],\n",
              "       [-0.6057066 ],\n",
              "       [ 0.4333795 ],\n",
              "       [ 0.32452148],\n",
              "       [ 0.7049265 ],\n",
              "       [ 1.3679969 ],\n",
              "       [-0.39217883],\n",
              "       [ 0.06892621],\n",
              "       [-0.01195293],\n",
              "       [-0.4539134 ],\n",
              "       [ 0.5693557 ],\n",
              "       [-1.4308009 ],\n",
              "       [-0.55618626],\n",
              "       [-0.7923851 ],\n",
              "       [ 1.5445586 ],\n",
              "       [ 2.3788087 ],\n",
              "       [ 1.4136834 ],\n",
              "       [-1.4661456 ],\n",
              "       [ 0.04037665],\n",
              "       [-0.4407045 ],\n",
              "       [ 0.82080317],\n",
              "       [-0.16213135],\n",
              "       [ 0.02385111],\n",
              "       [ 0.28029743],\n",
              "       [ 0.08643518],\n",
              "       [-0.8273073 ],\n",
              "       [-1.0567666 ],\n",
              "       [ 0.36441213],\n",
              "       [ 0.02435659],\n",
              "       [ 0.26511332],\n",
              "       [-0.4456472 ],\n",
              "       [ 1.6146775 ],\n",
              "       [-0.8204778 ],\n",
              "       [-1.0658253 ],\n",
              "       [ 2.8134952 ],\n",
              "       [-0.75760275],\n",
              "       [ 0.83630097],\n",
              "       [-0.19986834],\n",
              "       [ 0.80531603],\n",
              "       [ 1.0006335 ],\n",
              "       [ 0.8129085 ],\n",
              "       [-0.34471166],\n",
              "       [ 0.5654946 ],\n",
              "       [-0.6883246 ],\n",
              "       [-0.25697634],\n",
              "       [-0.5478444 ],\n",
              "       [ 0.7148593 ],\n",
              "       [ 0.01825448],\n",
              "       [ 0.92772347],\n",
              "       [ 2.4477503 ],\n",
              "       [-0.43892175],\n",
              "       [-0.2716331 ],\n",
              "       [ 0.6414314 ],\n",
              "       [ 1.1512797 ],\n",
              "       [-1.0421469 ],\n",
              "       [ 0.33833763],\n",
              "       [ 0.02185706],\n",
              "       [-0.08579559],\n",
              "       [-0.53275424],\n",
              "       [-0.32023546],\n",
              "       [-0.87924683],\n",
              "       [-0.20183638],\n",
              "       [ 1.3346068 ],\n",
              "       [ 0.00870269],\n",
              "       [ 0.40835354],\n",
              "       [ 0.9529917 ],\n",
              "       [ 0.76599777],\n",
              "       [ 1.2422185 ],\n",
              "       [-0.22050086],\n",
              "       [-0.27688786],\n",
              "       [ 1.1054302 ],\n",
              "       [ 0.31251562],\n",
              "       [ 1.476891  ],\n",
              "       [-0.8885446 ],\n",
              "       [ 0.29950908],\n",
              "       [-0.5881901 ],\n",
              "       [-1.2175915 ],\n",
              "       [ 0.00970267],\n",
              "       [-0.93916774],\n",
              "       [ 0.48783496]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "preds = model.predict(test_input.to_numpy())\n",
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122314"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Compute prediction differences for test set\n",
        "diffs = (preds - test_target)\n",
        "# Standard deviation of residuals\n",
        "(diffs < test_target).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f4f5b8539d0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 370.942187 248.518125\" width=\"370.942187pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-11-22T17:01:33.194253</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 370.942187 248.518125 \nL 370.942187 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 28.942188 224.64 \nL 363.742188 224.64 \nL 363.742188 7.2 \nL 28.942188 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m6da4fc5958\" style=\"stroke:#1f77b4;\"/>\n    </defs>\n    <g clip-path=\"url(#pf931f3737b)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"122.795351\" xlink:href=\"#m6da4fc5958\" y=\"155.874742\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"123.026631\" xlink:href=\"#m6da4fc5958\" y=\"164.156974\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"105.680679\" xlink:href=\"#m6da4fc5958\" y=\"164.946165\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"53.642823\" xlink:href=\"#m6da4fc5958\" y=\"192.464845\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.165067\" xlink:href=\"#m6da4fc5958\" y=\"173.522631\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"175.989604\" xlink:href=\"#m6da4fc5958\" y=\"135.511392\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"150.548874\" xlink:href=\"#m6da4fc5958\" y=\"144.054263\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"122.332793\" xlink:href=\"#m6da4fc5958\" y=\"128.073814\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.231383\" xlink:href=\"#m6da4fc5958\" y=\"138.586825\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.505851\" xlink:href=\"#m6da4fc5958\" y=\"127.034002\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.601099\" xlink:href=\"#m6da4fc5958\" y=\"170.361915\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.955617\" xlink:href=\"#m6da4fc5958\" y=\"185.19845\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"123.720469\" xlink:href=\"#m6da4fc5958\" y=\"149.50834\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.266097\" xlink:href=\"#m6da4fc5958\" y=\"178.866793\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.729035\" xlink:href=\"#m6da4fc5958\" y=\"159.308963\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.231383\" xlink:href=\"#m6da4fc5958\" y=\"167.669317\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.80925\" xlink:href=\"#m6da4fc5958\" y=\"164.917242\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.913892\" xlink:href=\"#m6da4fc5958\" y=\"184.311138\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"86.484492\" xlink:href=\"#m6da4fc5958\" y=\"161.051926\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"148.236081\" xlink:href=\"#m6da4fc5958\" y=\"163.602923\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"89.491124\" xlink:href=\"#m6da4fc5958\" y=\"177.623293\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"277.752522\" xlink:href=\"#m6da4fc5958\" y=\"86.237459\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"160.034693\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.288305\" xlink:href=\"#m6da4fc5958\" y=\"194.425009\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"127.420939\" xlink:href=\"#m6da4fc5958\" y=\"149.591325\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"233.994467\" xlink:href=\"#m6da4fc5958\" y=\"132.457094\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"130.073019\" xlink:href=\"#m6da4fc5958\" y=\"148.143959\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"99.667415\" xlink:href=\"#m6da4fc5958\" y=\"167.228372\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"146.243584\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.852273\" xlink:href=\"#m6da4fc5958\" y=\"187.886067\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"155.174462\" xlink:href=\"#m6da4fc5958\" y=\"137.982449\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"176.220883\" xlink:href=\"#m6da4fc5958\" y=\"114.469851\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"169.051223\" xlink:href=\"#m6da4fc5958\" y=\"121.146886\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.852273\" xlink:href=\"#m6da4fc5958\" y=\"176.916601\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"51.09875\" xlink:href=\"#m6da4fc5958\" y=\"194.16197\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"268.732627\" xlink:href=\"#m6da4fc5958\" y=\"104.013712\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"164.425636\" xlink:href=\"#m6da4fc5958\" y=\"134.427019\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"99.667415\" xlink:href=\"#m6da4fc5958\" y=\"166.673192\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"153.092947\" xlink:href=\"#m6da4fc5958\" y=\"139.470754\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"99.898695\" xlink:href=\"#m6da4fc5958\" y=\"146.256789\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"167.465518\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"210.681508\" xlink:href=\"#m6da4fc5958\" y=\"105.950122\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"199.082385\" xlink:href=\"#m6da4fc5958\" y=\"111.825498\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"107.543634\" xlink:href=\"#m6da4fc5958\" y=\"151.521275\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"115.625691\" xlink:href=\"#m6da4fc5958\" y=\"152.265479\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.612049\" xlink:href=\"#m6da4fc5958\" y=\"177.657364\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.53948\" xlink:href=\"#m6da4fc5958\" y=\"188.587711\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"90.416241\" xlink:href=\"#m6da4fc5958\" y=\"178.811286\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"138.753627\" xlink:href=\"#m6da4fc5958\" y=\"165.798115\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.790654\" xlink:href=\"#m6da4fc5958\" y=\"164.73334\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"110.15871\" xlink:href=\"#m6da4fc5958\" y=\"151.280037\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"245.604691\" xlink:href=\"#m6da4fc5958\" y=\"107.753336\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"133.311624\" xlink:href=\"#m6da4fc5958\" y=\"121.25123\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"121.777722\" xlink:href=\"#m6da4fc5958\" y=\"158.3534\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"156.219586\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.733732\" xlink:href=\"#m6da4fc5958\" y=\"170.273366\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.601099\" xlink:href=\"#m6da4fc5958\" y=\"204.199773\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"135.746995\" xlink:href=\"#m6da4fc5958\" y=\"130.589454\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.2977\" xlink:href=\"#m6da4fc5958\" y=\"122.948376\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"134.359319\" xlink:href=\"#m6da4fc5958\" y=\"126.52277\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"171.364017\" xlink:href=\"#m6da4fc5958\" y=\"99.350984\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.913892\" xlink:href=\"#m6da4fc5958\" y=\"193.86663\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"184.101603\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"152.861668\" xlink:href=\"#m6da4fc5958\" y=\"158.279507\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"126.495821\" xlink:href=\"#m6da4fc5958\" y=\"125.125297\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.744101\" xlink:href=\"#m6da4fc5958\" y=\"151.521275\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"257.168659\" xlink:href=\"#m6da4fc5958\" y=\"104.004909\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"89.467996\" xlink:href=\"#m6da4fc5958\" y=\"168.056469\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"152.783268\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.762994\" xlink:href=\"#m6da4fc5958\" y=\"174.431265\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.724337\" xlink:href=\"#m6da4fc5958\" y=\"196.843461\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"173.884962\" xlink:href=\"#m6da4fc5958\" y=\"122.516262\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"102.674047\" xlink:href=\"#m6da4fc5958\" y=\"165.416282\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"222.245476\" xlink:href=\"#m6da4fc5958\" y=\"102.175301\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"112.61906\" xlink:href=\"#m6da4fc5958\" y=\"160.278154\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.288305\" xlink:href=\"#m6da4fc5958\" y=\"179.385869\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.231383\" xlink:href=\"#m6da4fc5958\" y=\"122.962068\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"194.491953\" xlink:href=\"#m6da4fc5958\" y=\"96.999468\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"125.108145\" xlink:href=\"#m6da4fc5958\" y=\"153.897162\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"62.825539\" xlink:href=\"#m6da4fc5958\" y=\"175.401284\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"103.367885\" xlink:href=\"#m6da4fc5958\" y=\"160.807563\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"175.989604\" xlink:href=\"#m6da4fc5958\" y=\"113.073557\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"158.874931\" xlink:href=\"#m6da4fc5958\" y=\"148.085931\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"123.951748\" xlink:href=\"#m6da4fc5958\" y=\"135.165704\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"115.856971\" xlink:href=\"#m6da4fc5958\" y=\"173.862016\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.128675\" xlink:href=\"#m6da4fc5958\" y=\"155.797234\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.733732\" xlink:href=\"#m6da4fc5958\" y=\"151.181437\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"100.823812\" xlink:href=\"#m6da4fc5958\" y=\"157.944395\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.852273\" xlink:href=\"#m6da4fc5958\" y=\"164.824504\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"138.984906\" xlink:href=\"#m6da4fc5958\" y=\"146.499177\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"103.136606\" xlink:href=\"#m6da4fc5958\" y=\"156.271181\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"291.860563\" xlink:href=\"#m6da4fc5958\" y=\"96.498313\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.2977\" xlink:href=\"#m6da4fc5958\" y=\"156.578303\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"222.245476\" xlink:href=\"#m6da4fc5958\" y=\"139.51155\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.957539\" xlink:href=\"#m6da4fc5958\" y=\"158.038759\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.049427\" xlink:href=\"#m6da4fc5958\" y=\"162.649532\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"134.359319\" xlink:href=\"#m6da4fc5958\" y=\"149.372972\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"136.672113\" xlink:href=\"#m6da4fc5958\" y=\"152.316823\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"65.183663\" xlink:href=\"#m6da4fc5958\" y=\"180.635762\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"155.174462\" xlink:href=\"#m6da4fc5958\" y=\"109.088833\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"110.306266\" xlink:href=\"#m6da4fc5958\" y=\"159.433876\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"128.808615\" xlink:href=\"#m6da4fc5958\" y=\"150.650701\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.733732\" xlink:href=\"#m6da4fc5958\" y=\"132.699255\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.031964\" xlink:href=\"#m6da4fc5958\" y=\"169.996566\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"154.686708\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.53948\" xlink:href=\"#m6da4fc5958\" y=\"181.478512\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.041828\" xlink:href=\"#m6da4fc5958\" y=\"176.682492\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.614362\" xlink:href=\"#m6da4fc5958\" y=\"194.647036\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"61.737601\" xlink:href=\"#m6da4fc5958\" y=\"180.654453\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"77.857772\" xlink:href=\"#m6da4fc5958\" y=\"174.808843\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"199.11754\" xlink:href=\"#m6da4fc5958\" y=\"120.209411\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.377916\" xlink:href=\"#m6da4fc5958\" y=\"155.669289\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.682613\" xlink:href=\"#m6da4fc5958\" y=\"192.510937\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.47786\" xlink:href=\"#m6da4fc5958\" y=\"164.951578\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"241.904221\" xlink:href=\"#m6da4fc5958\" y=\"112.6014\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.031964\" xlink:href=\"#m6da4fc5958\" y=\"131.592436\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"116.065122\" xlink:href=\"#m6da4fc5958\" y=\"150.539763\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"121.847106\" xlink:href=\"#m6da4fc5958\" y=\"146.273497\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.165067\" xlink:href=\"#m6da4fc5958\" y=\"188.376862\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"98.742298\" xlink:href=\"#m6da4fc5958\" y=\"136.239725\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"97.354622\" xlink:href=\"#m6da4fc5958\" y=\"163.703958\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.246581\" xlink:href=\"#m6da4fc5958\" y=\"165.72368\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"68.675981\" xlink:href=\"#m6da4fc5958\" y=\"197.076105\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.558076\" xlink:href=\"#m6da4fc5958\" y=\"169.254839\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.790654\" xlink:href=\"#m6da4fc5958\" y=\"162.778199\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.349924\" xlink:href=\"#m6da4fc5958\" y=\"192.809461\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"88.103448\" xlink:href=\"#m6da4fc5958\" y=\"163.421794\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.980209\" xlink:href=\"#m6da4fc5958\" y=\"140.334298\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.245282\" xlink:href=\"#m6da4fc5958\" y=\"191.189807\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.701375\" xlink:href=\"#m6da4fc5958\" y=\"167.459544\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"268.732627\" xlink:href=\"#m6da4fc5958\" y=\"72.014996\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.790654\" xlink:href=\"#m6da4fc5958\" y=\"181.292598\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"87.17833\" xlink:href=\"#m6da4fc5958\" y=\"167.747045\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"103.344757\" xlink:href=\"#m6da4fc5958\" y=\"159.829985\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"153.092947\" xlink:href=\"#m6da4fc5958\" y=\"113.650917\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.837076\" xlink:href=\"#m6da4fc5958\" y=\"131.876176\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"180.615191\" xlink:href=\"#m6da4fc5958\" y=\"126.018746\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"222.245476\" xlink:href=\"#m6da4fc5958\" y=\"113.362393\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"127.420939\" xlink:href=\"#m6da4fc5958\" y=\"150.140417\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"126.264542\" xlink:href=\"#m6da4fc5958\" y=\"151.142858\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.810549\" xlink:href=\"#m6da4fc5958\" y=\"168.375631\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"112.595932\" xlink:href=\"#m6da4fc5958\" y=\"176.1088\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.913892\" xlink:href=\"#m6da4fc5958\" y=\"167.905549\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.733732\" xlink:href=\"#m6da4fc5958\" y=\"150.21511\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"143.610494\" xlink:href=\"#m6da4fc5958\" y=\"149.272147\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.037131\" xlink:href=\"#m6da4fc5958\" y=\"183.320532\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"74.226686\" xlink:href=\"#m6da4fc5958\" y=\"175.375086\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.701375\" xlink:href=\"#m6da4fc5958\" y=\"155.352424\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"84.842409\" xlink:href=\"#m6da4fc5958\" y=\"164.164227\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.47786\" xlink:href=\"#m6da4fc5958\" y=\"170.33753\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.165067\" xlink:href=\"#m6da4fc5958\" y=\"170.660683\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"250.230278\" xlink:href=\"#m6da4fc5958\" y=\"108.796362\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"108.348255\" xlink:href=\"#m6da4fc5958\" y=\"151.521275\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"268.270068\" xlink:href=\"#m6da4fc5958\" y=\"92.116618\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.231383\" xlink:href=\"#m6da4fc5958\" y=\"157.510507\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"168.378116\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.752328\" xlink:href=\"#m6da4fc5958\" y=\"157.510097\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"179.690074\" xlink:href=\"#m6da4fc5958\" y=\"128.093907\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"142.649069\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"148.236081\" xlink:href=\"#m6da4fc5958\" y=\"147.891505\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.2977\" xlink:href=\"#m6da4fc5958\" y=\"133.527709\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"99.667415\" xlink:href=\"#m6da4fc5958\" y=\"161.674329\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"99.898695\" xlink:href=\"#m6da4fc5958\" y=\"159.067689\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.972444\" xlink:href=\"#m6da4fc5958\" y=\"186.120654\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"153.092716\" xlink:href=\"#m6da4fc5958\" y=\"148.240578\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.116711\" xlink:href=\"#m6da4fc5958\" y=\"163.716482\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.733732\" xlink:href=\"#m6da4fc5958\" y=\"168.301425\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"91.803917\" xlink:href=\"#m6da4fc5958\" y=\"175.70902\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"90.416241\" xlink:href=\"#m6da4fc5958\" y=\"166.923327\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.041828\" xlink:href=\"#m6da4fc5958\" y=\"177.613012\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"132.277805\" xlink:href=\"#m6da4fc5958\" y=\"164.746443\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"128.808615\" xlink:href=\"#m6da4fc5958\" y=\"163.210328\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"147.310963\" xlink:href=\"#m6da4fc5958\" y=\"170.492458\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"125.108145\" xlink:href=\"#m6da4fc5958\" y=\"150.50158\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.53948\" xlink:href=\"#m6da4fc5958\" y=\"175.272126\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"80.239949\" xlink:href=\"#m6da4fc5958\" y=\"168.693402\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.852273\" xlink:href=\"#m6da4fc5958\" y=\"172.725582\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.852273\" xlink:href=\"#m6da4fc5958\" y=\"163.960248\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"138.059789\" xlink:href=\"#m6da4fc5958\" y=\"161.925147\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"97.354622\" xlink:href=\"#m6da4fc5958\" y=\"163.421097\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"72.05266\" xlink:href=\"#m6da4fc5958\" y=\"190.417862\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"74.226686\" xlink:href=\"#m6da4fc5958\" y=\"177.398381\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"162.112842\" xlink:href=\"#m6da4fc5958\" y=\"114.237623\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.2977\" xlink:href=\"#m6da4fc5958\" y=\"148.000669\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"140.372583\" xlink:href=\"#m6da4fc5958\" y=\"106.055042\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"256.012262\" xlink:href=\"#m6da4fc5958\" y=\"81.606014\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"105.981342\" xlink:href=\"#m6da4fc5958\" y=\"151.521275\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"176.220883\" xlink:href=\"#m6da4fc5958\" y=\"102.700357\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.980209\" xlink:href=\"#m6da4fc5958\" y=\"150.587647\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.976509\" xlink:href=\"#m6da4fc5958\" y=\"151.521275\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.733732\" xlink:href=\"#m6da4fc5958\" y=\"143.308973\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"193.335556\" xlink:href=\"#m6da4fc5958\" y=\"113.218302\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"112.61906\" xlink:href=\"#m6da4fc5958\" y=\"154.771893\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"199.11754\" xlink:href=\"#m6da4fc5958\" y=\"96.992383\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"132.277805\" xlink:href=\"#m6da4fc5958\" y=\"153.330009\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"178.302398\" xlink:href=\"#m6da4fc5958\" y=\"127.834517\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.035197\" xlink:href=\"#m6da4fc5958\" y=\"171.560174\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"133.533543\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.2977\" xlink:href=\"#m6da4fc5958\" y=\"126.734005\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.497755\" xlink:href=\"#m6da4fc5958\" y=\"193.414709\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.363188\" xlink:href=\"#m6da4fc5958\" y=\"184.407408\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.913892\" xlink:href=\"#m6da4fc5958\" y=\"177.587086\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"169.282503\" xlink:href=\"#m6da4fc5958\" y=\"126.178864\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"110.768825\" xlink:href=\"#m6da4fc5958\" y=\"158.032415\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"97.585901\" xlink:href=\"#m6da4fc5958\" y=\"156.461054\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"210.450228\" xlink:href=\"#m6da4fc5958\" y=\"120.226045\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.53948\" xlink:href=\"#m6da4fc5958\" y=\"189.797907\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"160.910511\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"119.55744\" xlink:href=\"#m6da4fc5958\" y=\"181.115925\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.790654\" xlink:href=\"#m6da4fc5958\" y=\"168.766809\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.246581\" xlink:href=\"#m6da4fc5958\" y=\"173.030237\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"125.108145\" xlink:href=\"#m6da4fc5958\" y=\"161.843342\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"151.936551\" xlink:href=\"#m6da4fc5958\" y=\"136.380024\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"147.310963\" xlink:href=\"#m6da4fc5958\" y=\"152.401469\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"342.510742\" xlink:href=\"#m6da4fc5958\" y=\"93.417918\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.244647\" xlink:href=\"#m6da4fc5958\" y=\"119.137844\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"168.406124\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.328095\" xlink:href=\"#m6da4fc5958\" y=\"176.824262\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.47786\" xlink:href=\"#m6da4fc5958\" y=\"167.403889\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"120.482558\" xlink:href=\"#m6da4fc5958\" y=\"153.621121\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"162.112842\" xlink:href=\"#m6da4fc5958\" y=\"147.60229\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"135.746995\" xlink:href=\"#m6da4fc5958\" y=\"143.274298\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"128.808615\" xlink:href=\"#m6da4fc5958\" y=\"147.425744\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.293003\" xlink:href=\"#m6da4fc5958\" y=\"164.804074\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"145.923287\" xlink:href=\"#m6da4fc5958\" y=\"130.304571\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.363188\" xlink:href=\"#m6da4fc5958\" y=\"197.130246\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.544177\" xlink:href=\"#m6da4fc5958\" y=\"158.572485\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"99.667415\" xlink:href=\"#m6da4fc5958\" y=\"166.388123\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"77.927156\" xlink:href=\"#m6da4fc5958\" y=\"169.673136\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.244647\" xlink:href=\"#m6da4fc5958\" y=\"151.651284\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.293003\" xlink:href=\"#m6da4fc5958\" y=\"153.949203\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"150.317595\" xlink:href=\"#m6da4fc5958\" y=\"135.579817\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.363188\" xlink:href=\"#m6da4fc5958\" y=\"181.979651\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"110.306266\" xlink:href=\"#m6da4fc5958\" y=\"156.500602\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.975512\" xlink:href=\"#m6da4fc5958\" y=\"185.091792\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.813948\" xlink:href=\"#m6da4fc5958\" y=\"155.649174\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.601099\" xlink:href=\"#m6da4fc5958\" y=\"170.410161\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"102.193911\" xlink:href=\"#m6da4fc5958\" y=\"156.037038\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"161.187725\" xlink:href=\"#m6da4fc5958\" y=\"124.562293\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.373218\" xlink:href=\"#m6da4fc5958\" y=\"174.300344\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.041828\" xlink:href=\"#m6da4fc5958\" y=\"152.584804\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.027266\" xlink:href=\"#m6da4fc5958\" y=\"174.656218\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"187.553572\" xlink:href=\"#m6da4fc5958\" y=\"113.107676\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.165067\" xlink:href=\"#m6da4fc5958\" y=\"174.149844\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.932489\" xlink:href=\"#m6da4fc5958\" y=\"175.88173\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.614362\" xlink:href=\"#m6da4fc5958\" y=\"176.386512\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"149.623757\" xlink:href=\"#m6da4fc5958\" y=\"153.024932\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"145.692008\" xlink:href=\"#m6da4fc5958\" y=\"128.385978\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.980209\" xlink:href=\"#m6da4fc5958\" y=\"165.374168\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"72.122044\" xlink:href=\"#m6da4fc5958\" y=\"171.844833\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.558076\" xlink:href=\"#m6da4fc5958\" y=\"201.748293\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"108.91859\" xlink:href=\"#m6da4fc5958\" y=\"149.999405\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"88.103448\" xlink:href=\"#m6da4fc5958\" y=\"180.01237\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"134.359319\" xlink:href=\"#m6da4fc5958\" y=\"146.686165\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.544177\" xlink:href=\"#m6da4fc5958\" y=\"161.593003\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"164.194357\" xlink:href=\"#m6da4fc5958\" y=\"109.127516\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"201.199054\" xlink:href=\"#m6da4fc5958\" y=\"117.110152\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"230.571533\" xlink:href=\"#m6da4fc5958\" y=\"92.153244\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"98.742298\" xlink:href=\"#m6da4fc5958\" y=\"170.586376\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"80.216821\" xlink:href=\"#m6da4fc5958\" y=\"193.528098\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.601099\" xlink:href=\"#m6da4fc5958\" y=\"172.71749\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.614362\" xlink:href=\"#m6da4fc5958\" y=\"203.483836\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"175.758325\" xlink:href=\"#m6da4fc5958\" y=\"143.10997\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"216.694771\" xlink:href=\"#m6da4fc5958\" y=\"102.359715\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.752328\" xlink:href=\"#m6da4fc5958\" y=\"175.271619\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"123.026399\" xlink:href=\"#m6da4fc5958\" y=\"151.052913\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.686012\" xlink:href=\"#m6da4fc5958\" y=\"173.573638\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"203.511848\" xlink:href=\"#m6da4fc5958\" y=\"127.496788\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.041828\" xlink:href=\"#m6da4fc5958\" y=\"172.415736\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.245282\" xlink:href=\"#m6da4fc5958\" y=\"180.746742\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"108.91859\" xlink:href=\"#m6da4fc5958\" y=\"159.8773\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"89.491124\" xlink:href=\"#m6da4fc5958\" y=\"177.114826\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"89.444868\" xlink:href=\"#m6da4fc5958\" y=\"177.108899\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"182.002867\" xlink:href=\"#m6da4fc5958\" y=\"124.553054\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"74.226686\" xlink:href=\"#m6da4fc5958\" y=\"165.757568\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"105.657551\" xlink:href=\"#m6da4fc5958\" y=\"162.962107\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"82.321464\" xlink:href=\"#m6da4fc5958\" y=\"177.042345\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.980209\" xlink:href=\"#m6da4fc5958\" y=\"178.705882\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"150.317595\" xlink:href=\"#m6da4fc5958\" y=\"104.004882\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"256.93738\" xlink:href=\"#m6da4fc5958\" y=\"62.985789\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.055092\" xlink:href=\"#m6da4fc5958\" y=\"168.717566\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"291.860563\" xlink:href=\"#m6da4fc5958\" y=\"22.957395\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.544177\" xlink:href=\"#m6da4fc5958\" y=\"142.613028\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.975512\" xlink:href=\"#m6da4fc5958\" y=\"176.055787\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"225.945945\" xlink:href=\"#m6da4fc5958\" y=\"146.137557\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"97.354622\" xlink:href=\"#m6da4fc5958\" y=\"159.012635\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"158.867895\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"159.106211\" xlink:href=\"#m6da4fc5958\" y=\"161.165818\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"89.444868\" xlink:href=\"#m6da4fc5958\" y=\"179.930948\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.972444\" xlink:href=\"#m6da4fc5958\" y=\"153.224012\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"136.672113\" xlink:href=\"#m6da4fc5958\" y=\"147.828384\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.116711\" xlink:href=\"#m6da4fc5958\" y=\"177.066058\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.729035\" xlink:href=\"#m6da4fc5958\" y=\"176.28912\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.041828\" xlink:href=\"#m6da4fc5958\" y=\"177.832056\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.980209\" xlink:href=\"#m6da4fc5958\" y=\"180.071554\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.810549\" xlink:href=\"#m6da4fc5958\" y=\"167.848045\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"48.577805\" xlink:href=\"#m6da4fc5958\" y=\"163.250624\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.70914\" xlink:href=\"#m6da4fc5958\" y=\"173.386936\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"200.505216\" xlink:href=\"#m6da4fc5958\" y=\"105.950122\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"163.281606\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.938485\" xlink:href=\"#m6da4fc5958\" y=\"158.674698\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"108.91859\" xlink:href=\"#m6da4fc5958\" y=\"156.808547\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"121.870234\" xlink:href=\"#m6da4fc5958\" y=\"160.330606\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"88.103448\" xlink:href=\"#m6da4fc5958\" y=\"149.817781\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.998805\" xlink:href=\"#m6da4fc5958\" y=\"163.626944\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"107.993472\" xlink:href=\"#m6da4fc5958\" y=\"165.709806\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.081618\" xlink:href=\"#m6da4fc5958\" y=\"140.171958\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"157.926314\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.037131\" xlink:href=\"#m6da4fc5958\" y=\"184.547226\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.041828\" xlink:href=\"#m6da4fc5958\" y=\"173.108148\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.913892\" xlink:href=\"#m6da4fc5958\" y=\"171.660025\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"158.874931\" xlink:href=\"#m6da4fc5958\" y=\"151.907554\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.53948\" xlink:href=\"#m6da4fc5958\" y=\"156.046356\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"57.690212\" xlink:href=\"#m6da4fc5958\" y=\"192.480737\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"121.870234\" xlink:href=\"#m6da4fc5958\" y=\"143.563782\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.913892\" xlink:href=\"#m6da4fc5958\" y=\"193.809364\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"112.61906\" xlink:href=\"#m6da4fc5958\" y=\"158.188491\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.165067\" xlink:href=\"#m6da4fc5958\" y=\"184.682825\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"103.367885\" xlink:href=\"#m6da4fc5958\" y=\"153.111521\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"302.268134\" xlink:href=\"#m6da4fc5958\" y=\"58.21483\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"128.808615\" xlink:href=\"#m6da4fc5958\" y=\"157.852225\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.47786\" xlink:href=\"#m6da4fc5958\" y=\"177.741965\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.47786\" xlink:href=\"#m6da4fc5958\" y=\"185.43691\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"136.209554\" xlink:href=\"#m6da4fc5958\" y=\"163.848326\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.686012\" xlink:href=\"#m6da4fc5958\" y=\"183.548643\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"174.370648\" xlink:href=\"#m6da4fc5958\" y=\"150.021746\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.363188\" xlink:href=\"#m6da4fc5958\" y=\"181.914423\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"187.761723\" xlink:href=\"#m6da4fc5958\" y=\"92.022323\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"150.232138\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"50.173633\" xlink:href=\"#m6da4fc5958\" y=\"209.429916\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"91.803917\" xlink:href=\"#m6da4fc5958\" y=\"162.157556\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"115.833843\" xlink:href=\"#m6da4fc5958\" y=\"158.654427\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.707841\" xlink:href=\"#m6da4fc5958\" y=\"185.343744\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.244647\" xlink:href=\"#m6da4fc5958\" y=\"149.54404\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"62.662718\" xlink:href=\"#m6da4fc5958\" y=\"190.787308\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.035197\" xlink:href=\"#m6da4fc5958\" y=\"171.318936\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"82.784022\" xlink:href=\"#m6da4fc5958\" y=\"173.996037\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"201.430333\" xlink:href=\"#m6da4fc5958\" y=\"123.733492\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"72.122044\" xlink:href=\"#m6da4fc5958\" y=\"176.969189\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.790654\" xlink:href=\"#m6da4fc5958\" y=\"175.499379\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"199.11754\" xlink:href=\"#m6da4fc5958\" y=\"127.738023\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"114.931853\" xlink:href=\"#m6da4fc5958\" y=\"162.69478\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"152.861668\" xlink:href=\"#m6da4fc5958\" y=\"104.550526\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"99.667415\" xlink:href=\"#m6da4fc5958\" y=\"173.36836\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.066421\" xlink:href=\"#m6da4fc5958\" y=\"145.503629\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.852273\" xlink:href=\"#m6da4fc5958\" y=\"177.281865\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"185.472058\" xlink:href=\"#m6da4fc5958\" y=\"120.78797\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"110.306035\" xlink:href=\"#m6da4fc5958\" y=\"179.233144\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.244647\" xlink:href=\"#m6da4fc5958\" y=\"151.443736\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"146.132498\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"302.268134\" xlink:href=\"#m6da4fc5958\" y=\"17.083636\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.369819\" xlink:href=\"#m6da4fc5958\" y=\"187.632815\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"90.416241\" xlink:href=\"#m6da4fc5958\" y=\"162.765392\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"126.495821\" xlink:href=\"#m6da4fc5958\" y=\"122.072128\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"122.795351\" xlink:href=\"#m6da4fc5958\" y=\"144.76333\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"234.017595\" xlink:href=\"#m6da4fc5958\" y=\"101.192853\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"115.856971\" xlink:href=\"#m6da4fc5958\" y=\"150.067481\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"164.194357\" xlink:href=\"#m6da4fc5958\" y=\"122.667347\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.293003\" xlink:href=\"#m6da4fc5958\" y=\"158.543939\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.293003\" xlink:href=\"#m6da4fc5958\" y=\"167.230883\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"210.681508\" xlink:href=\"#m6da4fc5958\" y=\"107.20914\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"91.803917\" xlink:href=\"#m6da4fc5958\" y=\"169.285005\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.244647\" xlink:href=\"#m6da4fc5958\" y=\"155.892912\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"166.969709\" xlink:href=\"#m6da4fc5958\" y=\"145.627447\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.980209\" xlink:href=\"#m6da4fc5958\" y=\"140.088736\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"136.672113\" xlink:href=\"#m6da4fc5958\" y=\"162.522907\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"84.842409\" xlink:href=\"#m6da4fc5958\" y=\"192.495826\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.913892\" xlink:href=\"#m6da4fc5958\" y=\"170.281249\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"139.678745\" xlink:href=\"#m6da4fc5958\" y=\"151.92955\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"139.678745\" xlink:href=\"#m6da4fc5958\" y=\"170.450941\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"80.239949\" xlink:href=\"#m6da4fc5958\" y=\"177.457613\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"279.834036\" xlink:href=\"#m6da4fc5958\" y=\"88.724725\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"162.112842\" xlink:href=\"#m6da4fc5958\" y=\"129.662045\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"279.140198\" xlink:href=\"#m6da4fc5958\" y=\"93.439552\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"138.527921\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"99.667415\" xlink:href=\"#m6da4fc5958\" y=\"153.898731\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.363188\" xlink:href=\"#m6da4fc5958\" y=\"188.511494\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.733732\" xlink:href=\"#m6da4fc5958\" y=\"154.44493\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"116.065122\" xlink:href=\"#m6da4fc5958\" y=\"158.560194\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"150.981452\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"222.476755\" xlink:href=\"#m6da4fc5958\" y=\"118.430945\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.938485\" xlink:href=\"#m6da4fc5958\" y=\"158.305153\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"176.220883\" xlink:href=\"#m6da4fc5958\" y=\"156.613081\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.975512\" xlink:href=\"#m6da4fc5958\" y=\"197.327386\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.729035\" xlink:href=\"#m6da4fc5958\" y=\"167.298044\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.502453\" xlink:href=\"#m6da4fc5958\" y=\"155.408949\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.57927\" xlink:href=\"#m6da4fc5958\" y=\"186.720336\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"130.634064\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"147.310963\" xlink:href=\"#m6da4fc5958\" y=\"123.241379\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.116711\" xlink:href=\"#m6da4fc5958\" y=\"172.266899\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"171.364017\" xlink:href=\"#m6da4fc5958\" y=\"155.555676\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.70914\" xlink:href=\"#m6da4fc5958\" y=\"188.969002\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"172.665519\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.165067\" xlink:href=\"#m6da4fc5958\" y=\"174.132017\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.244647\" xlink:href=\"#m6da4fc5958\" y=\"135.728948\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.482724\" xlink:href=\"#m6da4fc5958\" y=\"137.704329\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"169.282503\" xlink:href=\"#m6da4fc5958\" y=\"129.324847\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.041828\" xlink:href=\"#m6da4fc5958\" y=\"158.13183\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.273108\" xlink:href=\"#m6da4fc5958\" y=\"130.873253\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"77.557109\" xlink:href=\"#m6da4fc5958\" y=\"169.220551\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.231383\" xlink:href=\"#m6da4fc5958\" y=\"158.84716\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.852273\" xlink:href=\"#m6da4fc5958\" y=\"184.586973\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"164.425636\" xlink:href=\"#m6da4fc5958\" y=\"138.745152\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"187.761723\" xlink:href=\"#m6da4fc5958\" y=\"116.894089\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.752328\" xlink:href=\"#m6da4fc5958\" y=\"142.926486\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"202.81801\" xlink:href=\"#m6da4fc5958\" y=\"111.768433\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"291.629283\" xlink:href=\"#m6da4fc5958\" y=\"115.72307\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.312898\" xlink:href=\"#m6da4fc5958\" y=\"158.539002\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"206.2872\" xlink:href=\"#m6da4fc5958\" y=\"99.10121\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"284.690903\" xlink:href=\"#m6da4fc5958\" y=\"92.478451\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"84.634257\" xlink:href=\"#m6da4fc5958\" y=\"184.680527\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"74.226686\" xlink:href=\"#m6da4fc5958\" y=\"175.587634\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.055092\" xlink:href=\"#m6da4fc5958\" y=\"172.725809\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"209.75639\" xlink:href=\"#m6da4fc5958\" y=\"115.568785\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.245282\" xlink:href=\"#m6da4fc5958\" y=\"191.157707\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"297.411267\" xlink:href=\"#m6da4fc5958\" y=\"123.188319\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.975512\" xlink:href=\"#m6da4fc5958\" y=\"185.712868\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"256.93738\" xlink:href=\"#m6da4fc5958\" y=\"119.102909\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"57.088885\" xlink:href=\"#m6da4fc5958\" y=\"191.336428\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.811172\" xlink:href=\"#m6da4fc5958\" y=\"153.550296\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"127.420939\" xlink:href=\"#m6da4fc5958\" y=\"126.463396\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.431604\" xlink:href=\"#m6da4fc5958\" y=\"190.244739\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"175.064486\" xlink:href=\"#m6da4fc5958\" y=\"110.736737\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.377916\" xlink:href=\"#m6da4fc5958\" y=\"148.122507\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"115.856971\" xlink:href=\"#m6da4fc5958\" y=\"143.322922\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"172.751693\" xlink:href=\"#m6da4fc5958\" y=\"136.81244\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"88.103448\" xlink:href=\"#m6da4fc5958\" y=\"131.978282\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"302.268134\" xlink:href=\"#m6da4fc5958\" y=\"79.939367\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"164.194357\" xlink:href=\"#m6da4fc5958\" y=\"132.915654\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.790654\" xlink:href=\"#m6da4fc5958\" y=\"166.17865\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.041828\" xlink:href=\"#m6da4fc5958\" y=\"146.388587\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.938485\" xlink:href=\"#m6da4fc5958\" y=\"174.724009\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"138.984906\" xlink:href=\"#m6da4fc5958\" y=\"150.135265\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.80925\" xlink:href=\"#m6da4fc5958\" y=\"183.333064\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"108.68731\" xlink:href=\"#m6da4fc5958\" y=\"148.84281\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.231383\" xlink:href=\"#m6da4fc5958\" y=\"127.039449\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.733732\" xlink:href=\"#m6da4fc5958\" y=\"142.765563\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"303.424531\" xlink:href=\"#m6da4fc5958\" y=\"77.882035\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"44.160369\" xlink:href=\"#m6da4fc5958\" y=\"213.595541\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"169.051223\" xlink:href=\"#m6da4fc5958\" y=\"133.654422\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"161.187725\" xlink:href=\"#m6da4fc5958\" y=\"126.826677\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"233.578164\" xlink:href=\"#m6da4fc5958\" y=\"92.305832\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"127.652218\" xlink:href=\"#m6da4fc5958\" y=\"161.968249\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.47786\" xlink:href=\"#m6da4fc5958\" y=\"176.38674\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.050394\" xlink:href=\"#m6da4fc5958\" y=\"184.772585\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.398731\" xlink:href=\"#m6da4fc5958\" y=\"149.464954\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.74893\" xlink:href=\"#m6da4fc5958\" y=\"160.317487\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"115.856971\" xlink:href=\"#m6da4fc5958\" y=\"175.859547\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"187.784851\" xlink:href=\"#m6da4fc5958\" y=\"112.224415\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"175.989604\" xlink:href=\"#m6da4fc5958\" y=\"133.228212\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"182.993722\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"107.993472\" xlink:href=\"#m6da4fc5958\" y=\"155.6703\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"187.553572\" xlink:href=\"#m6da4fc5958\" y=\"123.821731\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.544177\" xlink:href=\"#m6da4fc5958\" y=\"162.488862\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"90.416241\" xlink:href=\"#m6da4fc5958\" y=\"192.760715\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.273108\" xlink:href=\"#m6da4fc5958\" y=\"183.493299\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.093583\" xlink:href=\"#m6da4fc5958\" y=\"167.33207\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"45.779325\" xlink:href=\"#m6da4fc5958\" y=\"204.216355\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.246581\" xlink:href=\"#m6da4fc5958\" y=\"176.856079\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"82.784022\" xlink:href=\"#m6da4fc5958\" y=\"171.407804\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"139.193058\" xlink:href=\"#m6da4fc5958\" y=\"148.649495\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"222.476755\" xlink:href=\"#m6da4fc5958\" y=\"135.51214\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"122.564072\" xlink:href=\"#m6da4fc5958\" y=\"162.739285\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"209.75639\" xlink:href=\"#m6da4fc5958\" y=\"95.278091\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.2977\" xlink:href=\"#m6da4fc5958\" y=\"149.990863\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"53.411544\" xlink:href=\"#m6da4fc5958\" y=\"160.319293\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"70.988775\" xlink:href=\"#m6da4fc5958\" y=\"214.756364\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"62.662718\" xlink:href=\"#m6da4fc5958\" y=\"191.317206\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.960314\" xlink:href=\"#m6da4fc5958\" y=\"158.174594\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"86.021933\" xlink:href=\"#m6da4fc5958\" y=\"176.218697\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"115.856971\" xlink:href=\"#m6da4fc5958\" y=\"137.296837\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"87.29212\" xlink:href=\"#m6da4fc5958\" y=\"139.987718\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"164.194357\" xlink:href=\"#m6da4fc5958\" y=\"124.683164\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"196.573467\" xlink:href=\"#m6da4fc5958\" y=\"98.823887\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.47786\" xlink:href=\"#m6da4fc5958\" y=\"167.123154\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.524051\" xlink:href=\"#m6da4fc5958\" y=\"149.108998\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.965011\" xlink:href=\"#m6da4fc5958\" y=\"152.878819\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.293003\" xlink:href=\"#m6da4fc5958\" y=\"169.545133\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"168.126106\" xlink:href=\"#m6da4fc5958\" y=\"130.457503\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"88.103448\" xlink:href=\"#m6da4fc5958\" y=\"208.299083\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"51.329798\" xlink:href=\"#m6da4fc5958\" y=\"174.22569\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.686012\" xlink:href=\"#m6da4fc5958\" y=\"183.734263\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"303.193251\" xlink:href=\"#m6da4fc5958\" y=\"92.658972\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"206.055921\" xlink:href=\"#m6da4fc5958\" y=\"62.24566\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"118.169764\" xlink:href=\"#m6da4fc5958\" y=\"97.824326\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.724337\" xlink:href=\"#m6da4fc5958\" y=\"211.443517\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"134.359319\" xlink:href=\"#m6da4fc5958\" y=\"150.355624\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"125.108145\" xlink:href=\"#m6da4fc5958\" y=\"168.608842\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.066421\" xlink:href=\"#m6da4fc5958\" y=\"120.5335\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"105.680679\" xlink:href=\"#m6da4fc5958\" y=\"158.161962\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.733732\" xlink:href=\"#m6da4fc5958\" y=\"150.846479\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"108.91859\" xlink:href=\"#m6da4fc5958\" y=\"142.471849\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"199.11754\" xlink:href=\"#m6da4fc5958\" y=\"149.833224\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"101.980209\" xlink:href=\"#m6da4fc5958\" y=\"185.246599\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.975512\" xlink:href=\"#m6da4fc5958\" y=\"194.005463\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"124.183028\" xlink:href=\"#m6da4fc5958\" y=\"137.962508\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.116711\" xlink:href=\"#m6da4fc5958\" y=\"150.776721\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"152.861668\" xlink:href=\"#m6da4fc5958\" y=\"141.924927\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.686012\" xlink:href=\"#m6da4fc5958\" y=\"170.084035\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"279.140198\" xlink:href=\"#m6da4fc5958\" y=\"91.113654\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"59.424807\" xlink:href=\"#m6da4fc5958\" y=\"184.772017\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"48.785956\" xlink:href=\"#m6da4fc5958\" y=\"194.371033\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"348.524006\" xlink:href=\"#m6da4fc5958\" y=\"45.478067\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.288305\" xlink:href=\"#m6da4fc5958\" y=\"180.708975\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"140.372583\" xlink:href=\"#m6da4fc5958\" y=\"120.814433\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"131.121408\" xlink:href=\"#m6da4fc5958\" y=\"160.480017\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"173.67681\" xlink:href=\"#m6da4fc5958\" y=\"121.071312\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"210.681508\" xlink:href=\"#m6da4fc5958\" y=\"114.547636\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"185.240778\" xlink:href=\"#m6da4fc5958\" y=\"121.03164\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"97.328719\" xlink:href=\"#m6da4fc5958\" y=\"166.263779\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"149.392478\" xlink:href=\"#m6da4fc5958\" y=\"130.285049\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"72.122044\" xlink:href=\"#m6da4fc5958\" y=\"179.770673\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.041828\" xlink:href=\"#m6da4fc5958\" y=\"161.723329\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.614362\" xlink:href=\"#m6da4fc5958\" y=\"173.662466\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"134.359319\" xlink:href=\"#m6da4fc5958\" y=\"126.103861\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"117.938485\" xlink:href=\"#m6da4fc5958\" y=\"151.053016\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.918756\" xlink:href=\"#m6da4fc5958\" y=\"117.893702\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"252.311792\" xlink:href=\"#m6da4fc5958\" y=\"59.887113\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.790654\" xlink:href=\"#m6da4fc5958\" y=\"168.729333\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"136.672113\" xlink:href=\"#m6da4fc5958\" y=\"162.000532\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"153.023564\" xlink:href=\"#m6da4fc5958\" y=\"129.710517\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"182.002867\" xlink:href=\"#m6da4fc5958\" y=\"108.87237\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.293003\" xlink:href=\"#m6da4fc5958\" y=\"192.639739\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.544177\" xlink:href=\"#m6da4fc5958\" y=\"140.507513\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"171.595296\" xlink:href=\"#m6da4fc5958\" y=\"150.427037\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.837076\" xlink:href=\"#m6da4fc5958\" y=\"155.188073\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.273108\" xlink:href=\"#m6da4fc5958\" y=\"172.252845\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.729035\" xlink:href=\"#m6da4fc5958\" y=\"165.888278\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.70914\" xlink:href=\"#m6da4fc5958\" y=\"187.0934\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"123.026631\" xlink:href=\"#m6da4fc5958\" y=\"159.656079\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.2977\" xlink:href=\"#m6da4fc5958\" y=\"101.08665\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.686012\" xlink:href=\"#m6da4fc5958\" y=\"153.619698\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"127.420939\" xlink:href=\"#m6da4fc5958\" y=\"136.184305\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"216.694771\" xlink:href=\"#m6da4fc5958\" y=\"114.91719\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"127.420939\" xlink:href=\"#m6da4fc5958\" y=\"124.160427\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"178.302398\" xlink:href=\"#m6da4fc5958\" y=\"104.404247\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"90.416241\" xlink:href=\"#m6da4fc5958\" y=\"160.333644\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"124.1599\" xlink:href=\"#m6da4fc5958\" y=\"162.49064\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"141.2977\" xlink:href=\"#m6da4fc5958\" y=\"110.655466\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.605796\" xlink:href=\"#m6da4fc5958\" y=\"142.845075\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"279.140198\" xlink:href=\"#m6da4fc5958\" y=\"95.360828\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.050394\" xlink:href=\"#m6da4fc5958\" y=\"185.924443\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"187.553572\" xlink:href=\"#m6da4fc5958\" y=\"140.3615\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.852273\" xlink:href=\"#m6da4fc5958\" y=\"174.847756\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"44.391649\" xlink:href=\"#m6da4fc5958\" y=\"200.60085\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"109.354089\" xlink:href=\"#m6da4fc5958\" y=\"151.521275\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"72.122044\" xlink:href=\"#m6da4fc5958\" y=\"189.195903\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"150.548874\" xlink:href=\"#m6da4fc5958\" y=\"133.515856\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m21323d5651\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.269381\" xlink:href=\"#m21323d5651\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- âˆ’1 -->\n      <g transform=\"translate(61.898287 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.519429\" xlink:href=\"#m21323d5651\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0 -->\n      <g transform=\"translate(120.338179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"177.769477\" xlink:href=\"#m21323d5651\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1 -->\n      <g transform=\"translate(174.588227 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"232.019524\" xlink:href=\"#m21323d5651\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2 -->\n      <g transform=\"translate(228.838274 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"286.269572\" xlink:href=\"#m21323d5651\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3 -->\n      <g transform=\"translate(283.088322 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"340.51962\" xlink:href=\"#m21323d5651\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 4 -->\n      <g transform=\"translate(337.33837 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"md13e3e4d58\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#md13e3e4d58\" y=\"190.86645\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- âˆ’1 -->\n      <g transform=\"translate(7.2 194.665669)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#md13e3e4d58\" y=\"152.546601\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(15.579688 156.34582)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#md13e3e4d58\" y=\"114.226751\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1 -->\n      <g transform=\"translate(15.579688 118.02597)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#md13e3e4d58\" y=\"75.906902\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 2 -->\n      <g transform=\"translate(15.579688 79.706121)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#md13e3e4d58\" y=\"37.587052\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 3 -->\n      <g transform=\"translate(15.579688 41.386271)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 28.942188 224.64 \nL 28.942188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 363.742188 224.64 \nL 363.742188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 28.942188 224.64 \nL 363.742188 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 28.942188 7.2 \nL 363.742188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pf931f3737b\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"28.942188\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.scatter(test_target, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             feature   weight  std\n",
              "0         total_area 650565.8  0.0\n",
              "1          bathrooms 146965.0  0.0\n",
              "2        mr_distance  96264.2  0.0\n",
              "3              cafes  50728.9  0.0\n",
              "4          groceries  24673.7  0.0\n",
              "5            vibrant  21650.4  0.0\n",
              "6              parks  17471.3  0.0\n",
              "7           bedrooms  17278.0  0.0\n",
              "8         year_built  15169.6  0.0\n",
              "9           historic  12811.9  0.0\n",
              "10       restaurants  11341.1  0.0\n",
              "11        walk_score  10293.8  0.0\n",
              "12  transit_friendly   6738.6  0.0\n",
              "13  cycling_friendly   4696.0  0.0\n",
              "14          greenery   4681.4  0.0\n",
              "15      powder_rooms   3086.0  0.0\n",
              "16      car_friendly   1596.1  0.0\n",
              "17             quiet  -4517.4  0.0"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>weight</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>total_area</td>\n      <td>650565.8</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bathrooms</td>\n      <td>146965.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mr_distance</td>\n      <td>96264.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cafes</td>\n      <td>50728.9</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>groceries</td>\n      <td>24673.7</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>vibrant</td>\n      <td>21650.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>parks</td>\n      <td>17471.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>bedrooms</td>\n      <td>17278.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>year_built</td>\n      <td>15169.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>historic</td>\n      <td>12811.9</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>restaurants</td>\n      <td>11341.1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>walk_score</td>\n      <td>10293.8</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>transit_friendly</td>\n      <td>6738.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>cycling_friendly</td>\n      <td>4696.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>greenery</td>\n      <td>4681.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>powder_rooms</td>\n      <td>3086.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>car_friendly</td>\n      <td>1596.1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>quiet</td>\n      <td>-4517.4</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 409
        }
      ],
      "source": [
        "# Feature weights\n",
        "feature_names = test_df_norm.iloc[:, 3:].columns\n",
        "def feature_importance():\n",
        "    perm = PermutationImportance(reconstructed_model, \n",
        "                             scoring='neg_mean_squared_error',\n",
        "                             random_state=1).fit(test_input, test_target)\n",
        "    weights = eli5.explain_weights_df(perm,   \n",
        "                            feature_names=feature_names.tolist(),\n",
        "                            top = 31)\n",
        "    return weights\n",
        "pd.set_option('display.max_rows', 500)\n",
        "weights = feature_importance()\n",
        "weights.weight = weights.weight * 1000000\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              feature  weight  std\n",
              "10        Restaurants     1.1  0.0\n",
              "9            Bedrooms     1.2  0.0\n",
              "8    Transit Friendly     1.4  0.0\n",
              "7               Parks     1.6  0.0\n",
              "6          Year Built     1.6  0.0\n",
              "5            Historic     2.0  0.0\n",
              "4               Cafes     2.3  0.0\n",
              "3           Groceries     4.8  0.0\n",
              "2   Downtown Distance     9.0  0.0\n",
              "1           Bathrooms    13.8  0.0\n",
              "0          Total Area    61.1  0.0"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>weight</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Restaurants</td>\n      <td>1.1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Bedrooms</td>\n      <td>1.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Transit Friendly</td>\n      <td>1.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Parks</td>\n      <td>1.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Year Built</td>\n      <td>1.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Historic</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cafes</td>\n      <td>2.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Groceries</td>\n      <td>4.8</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Downtown Distance</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bathrooms</td>\n      <td>13.8</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Total Area</td>\n      <td>61.1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 411
        }
      ],
      "source": [
        "top_11 = weights[: 11]\n",
        "top_11.weight = 100 * top_11.weight / top_11.weight.sum()\n",
        "top_11.sort_values(by='weight', ascending=True, inplace=True)\n",
        "top_11.feature = ['Restaurants', 'Bedrooms', 'Transit Friendly', 'Parks',\n",
        "                'Year Built', 'Historic', 'Cafes', 'Groceries', 'Downtown Distance',\n",
        "                'Bathrooms', 'Total Area']\n",
        "top_11.to_csv('web-app/data/top_11_features.csv')\n",
        "top_11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}