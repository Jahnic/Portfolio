{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_gcolab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRWjoIT1-hlm"
      },
      "source": [
        "# Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "from __future__ imports must occur at the beginning of the file (<ipython-input-3-bff099f85c3d>, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-bff099f85c3d>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m from __future__ imports must occur at the beginning of the file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0D9c1N1cHFu"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "import matplotlib\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# Saves model as file\n",
        "import pickle\n",
        "# Verify computational environment\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "# Outlier detection\n",
        "from sklearn.ensemble import IsolationForest"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW8t0RFlfNZT",
        "outputId": "f60da5f7-de08-4e84-f4e2-b12320ab4b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import data to google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwh7_zVjcKWS",
        "outputId": "2976606d-7ad5-4d94-9ac3-7b6e015d5078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "# Verify GPU\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 13892430929200484823, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 16690323410498343107\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 15592745869904713114\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14640891840\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 10571825691592496943\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k6lk1Z-cXIU",
        "outputId": "9d7df90b-d40c-41ff-865d-1a2570b2e18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# Load data\n",
        "path = \"data/complete_data.csv\"\n",
        "data = pd.read_csv(path).iloc[:, 4: ]\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    price  lat  long  restaurants  shopping  vibrant  cycling_friendly  \\\n",
              "0  409000 45.5 -73.6          7.0       8.0      5.0               9.0   \n",
              "1  680000 45.4 -73.6          3.0       3.0      1.0               7.0   \n",
              "2  283000 45.5 -73.6          8.0      10.0      5.0               3.0   \n",
              "3  339000 45.5 -73.6         10.0      10.0      9.0               9.0   \n",
              "4  177800 45.6 -73.6          6.0       7.0      3.0               4.0   \n",
              "\n",
              "   car_friendly  historic  quiet  ...  powder_rooms  total_area  \\\n",
              "0           6.0       5.0    8.0  ...           0.0      1014.0   \n",
              "1          10.0       0.0   10.0  ...           0.0      1249.0   \n",
              "2           6.0       2.0    0.0  ...           0.0       848.0   \n",
              "3           5.0       6.0    7.0  ...           0.0       621.0   \n",
              "4           9.0       0.0    6.0  ...           0.0       586.0   \n",
              "\n",
              "   new_area_from_price  new_area_from_rooms  river_proximity  has_pool  \\\n",
              "0               1014.0               1014.0            False     False   \n",
              "1               1249.0               1249.0            False      True   \n",
              "2                848.0                848.0            False     False   \n",
              "3                621.0                621.0            False      True   \n",
              "4                586.0                586.0            False     False   \n",
              "\n",
              "   n_parking  has_garage  is_devided  mr_distance  \n",
              "0        1.0        True           1          5.7  \n",
              "1        2.0        True           1          7.1  \n",
              "2        1.0        True           1          5.2  \n",
              "3        0.0       False           1          3.3  \n",
              "4        1.0       False           1         11.3  \n",
              "\n",
              "[5 rows x 76 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>restaurants</th>\n      <th>shopping</th>\n      <th>vibrant</th>\n      <th>cycling_friendly</th>\n      <th>car_friendly</th>\n      <th>historic</th>\n      <th>quiet</th>\n      <th>...</th>\n      <th>powder_rooms</th>\n      <th>total_area</th>\n      <th>new_area_from_price</th>\n      <th>new_area_from_rooms</th>\n      <th>river_proximity</th>\n      <th>has_pool</th>\n      <th>n_parking</th>\n      <th>has_garage</th>\n      <th>is_devided</th>\n      <th>mr_distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>409000</td>\n      <td>45.5</td>\n      <td>-73.6</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1014.0</td>\n      <td>1014.0</td>\n      <td>1014.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>True</td>\n      <td>1</td>\n      <td>5.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>680000</td>\n      <td>45.4</td>\n      <td>-73.6</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1249.0</td>\n      <td>1249.0</td>\n      <td>1249.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>1</td>\n      <td>7.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>283000</td>\n      <td>45.5</td>\n      <td>-73.6</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>848.0</td>\n      <td>848.0</td>\n      <td>848.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>True</td>\n      <td>1</td>\n      <td>5.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>339000</td>\n      <td>45.5</td>\n      <td>-73.6</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>621.0</td>\n      <td>621.0</td>\n      <td>621.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>3.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>177800</td>\n      <td>45.6</td>\n      <td>-73.6</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>586.0</td>\n      <td>586.0</td>\n      <td>586.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>11.3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 76 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv3fPw1Pryxe"
      },
      "source": [
        "# Transform is_devided into boolean feature\n",
        "data.is_devided = data.is_devided.astype('bool')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nuNb6Uvemew"
      },
      "source": [
        "# # Drop redundant data\n",
        "# redundant = ['more_than_$150,000_(%)', '5-person_or_more_households_(%)', \n",
        "#             'single-parent_families_(%)', 'renters_(%)', 'before_1960_(%)',\n",
        "#             'mobile_homes_(%)', 'university_(%)', 'non-immigrant_population_(%)',\n",
        "#             'french_(%)', 'new_area_from_price', 'new_area_from_rooms',\n",
        "#             'basement_bedroom']\n",
        "# data.drop(redundant, axis=1, inplace=True)\n",
        "\n",
        "# Drop demographics data\n",
        "demographics = ['less_than_$50,000_(%)', 'between_$50,000_and_$80,000_(%)', \n",
        "                'between_$80,000_and_$100,000_(%)', 'between_$100,000_and_$150,000_(%)',\n",
        "                'more_than_$150,000_(%)', '1-person_households_(%)', \n",
        "                '2-person_households_(%)', '3-person_households_(%)', \n",
        "                '4-person_households_(%)', '5-person_or_more_households_(%)', \n",
        "                'couples_without_children_at_home_(%)', 'couples_with_children_at_home_(%)',\n",
        "                'single-parent_families_(%)', 'owners_(%)', 'renters_(%)',\n",
        "                'before_1960_(%)', 'between_1961_and_1980_(%)',\n",
        "                'between_1981_and_1990_(%)', 'between_1991_and_2000_(%)',\n",
        "                'between_2001_and_2010_(%)', 'between_2011_and_2016_(%)',\n",
        "                'single-family_homes_(%)', 'semi-detached_or_row_houses_(%)',\n",
        "                'buildings_with_less_than_5_floors_(%)',\n",
        "                'buildings_with_5_or_more_floors_(%)', 'mobile_homes_(%)',\n",
        "                'university_(%)', 'college_(%)', 'secondary_(high)_school_(%)',\n",
        "                'apprentice_or_trade_school_diploma_(%)', 'no_diploma_(%)',\n",
        "                'non-immigrant_population_(%)', 'immigrant_population_(%)',\n",
        "                'french_(%)', 'english_(%)', 'others_languages_(%)',\n",
        "                'new_area_from_price', 'new_area_from_rooms', 'basement_bedroom']\n",
        "data.drop(demographics, axis=1, inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdXUPRvj_O7w",
        "outputId": "3527eff9-6787-4a41-b505-eef53b0c604d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Remove symbols violating tf scope naming conventions\n",
        "valid_column_names = [col.replace('_(%)', '').replace('$', 'CAD').\n",
        "                      replace(',', '.').\n",
        "                      replace('(', '').replace(')', '') for col in data.columns]\n",
        "data.columns = valid_column_names\n",
        "data.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['price', 'lat', 'long', 'restaurants', 'shopping', 'vibrant',\n",
              "       'cycling_friendly', 'car_friendly', 'historic', 'quiet',\n",
              "       'elementary_schools', 'high_schools', 'parks', 'nightlife', 'groceries',\n",
              "       'daycares', 'pedestrian_friendly', 'cafes', 'transit_friendly',\n",
              "       'greenery', 'year_built', 'population_2016_',\n",
              "       'population_variation_between_2011_2016_', 'population_density_',\n",
              "       'unemployment_rate_2016_', 'walk_score', 'rooms', 'bedrooms',\n",
              "       'bathrooms', 'powder_rooms', 'total_area', 'river_proximity',\n",
              "       'has_pool', 'n_parking', 'has_garage', 'is_devided', 'mr_distance'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ztlVY8Ufx90",
        "outputId": "ae2244b3-07f8-44c6-9da9-ec2dc1d095f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# Random index shuffling for train/test split\n",
        "df = data.copy().sample(frac=1, random_state=0)\n",
        "# Prepare train and test data\n",
        "train_size = round(0.8*df.shape[0])\n",
        "train = df[: train_size]\n",
        "test = df[train_size : ]\n",
        "\n",
        "# Inspect training data\n",
        "print('Shape of the train data with all features:', train.shape)\n",
        "print(\"\")\n",
        "print(\"List of features:\")\n",
        "print(list(train.columns))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the train data with all features: (2142, 37)\n\nList of features:\n['price', 'lat', 'long', 'restaurants', 'shopping', 'vibrant', 'cycling_friendly', 'car_friendly', 'historic', 'quiet', 'elementary_schools', 'high_schools', 'parks', 'nightlife', 'groceries', 'daycares', 'pedestrian_friendly', 'cafes', 'transit_friendly', 'greenery', 'year_built', 'population_2016_', 'population_variation_between_2011_2016_', 'population_density_', 'unemployment_rate_2016_', 'walk_score', 'rooms', 'bedrooms', 'bathrooms', 'powder_rooms', 'total_area', 'river_proximity', 'has_pool', 'n_parking', 'has_garage', 'is_devided', 'mr_distance']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MekiDUOrf6Gy",
        "outputId": "0ca56181-aa41-493a-f2d9-234d7a1ef32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Outlier detection\n",
        "clf = IsolationForest(max_samples = 100, random_state = 0)\n",
        "clf.fit(train)\n",
        "y_noano = clf.predict(train)\n",
        "y_noano = pd.DataFrame(y_noano, columns = ['Top'])\n",
        "# Indices of non-outliers\n",
        "noano_indices = y_noano[y_noano['Top'] == 1].index.values\n",
        "\n",
        "# Remove anomalies\n",
        "train_ano_rm = train.iloc[noano_indices]\n",
        "train_ano_rm.reset_index(drop = True, inplace = True)\n",
        "print(\"Number of Outliers:\", y_noano[y_noano['Top'] == -1].shape[0])\n",
        "print(\"Number of rows without outliers:\", train_ano_rm.shape[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Outliers: 714\nNumber of rows without outliers: 1428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkoSsWFmg82y"
      },
      "source": [
        "## Z-score normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLKOyl6pqFCM"
      },
      "source": [
        "boolean_features = ['river_proximity', 'has_pool',\n",
        "                    'has_garage', 'is_devided']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5cqMqQEgiK-"
      },
      "source": [
        "# Calculate the Z-scores of each column in the training set:\n",
        "train_df_mean = train_ano_rm.mean()\n",
        "train_df_std = train_ano_rm.std()\n",
        "train_df_norm = (train_ano_rm - train_df_mean)/train_df_std\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "test_df_mean = test.mean()\n",
        "test_df_std = test.std()\n",
        "test_df_norm = (test - test_df_mean)/test_df_std\n",
        "\n",
        "# Add unnormalized boolean features back\n",
        "for bool_feature in boolean_features:\n",
        "    train_df_norm[bool_feature] = train_ano_rm[bool_feature]\n",
        "    test_df_norm[bool_feature] = test[bool_feature]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgLm7P2cmh1O"
      },
      "source": [
        "## Represent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG5NOvXRlop4"
      },
      "source": [
        "# Create an empty list that will eventually hold all created feature columns.\n",
        "feature_columns = []\n",
        "\n",
        "# We scaled all the columns, including latitude and longitude, into their\n",
        "# Z scores. So, instead of picking a resolution in degrees, we're going\n",
        "# to use resolution_in_Zs.  A resolution_in_Zs of 1 corresponds to \n",
        "# a full standard deviation. \n",
        "resolution_in_Zs = 0.15  # 1.5/10 of a standard deviation.\n",
        "\n",
        "# Create a bucket feature column for latitude.\n",
        "latitude_as_a_numeric_column = tf.feature_column.numeric_column(\"lat\")\n",
        "latitude_boundaries = list(np.arange(int(min(train_df_norm['lat'])), \n",
        "                                     int(max(train_df_norm['lat'])), \n",
        "                                     resolution_in_Zs))\n",
        "latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column, latitude_boundaries)\n",
        "\n",
        "# Create a bucket feature column for longitude.\n",
        "longitude_as_a_numeric_column = tf.feature_column.numeric_column(\"long\")\n",
        "longitude_boundaries = list(np.arange(int(min(train_df_norm['long'])), \n",
        "                                      int(max(train_df_norm['long'])), \n",
        "                                      resolution_in_Zs))\n",
        "longitude = tf.feature_column.bucketized_column(longitude_as_a_numeric_column, \n",
        "                                                longitude_boundaries)\n",
        "\n",
        "# Create a feature cross of latitude and longitude.\n",
        "latitude_x_longitude = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size=100)\n",
        "crossed_feature = tf.feature_column.indicator_column(latitude_x_longitude)\n",
        "feature_columns.append(crossed_feature)\n",
        "\n",
        "feature_names = data.drop(['price', 'lat', 'long'], axis=1).columns\n",
        "for feature in feature_names:\n",
        "    if data[feature].dtype == bool:\n",
        "        train_df_norm[feature] = data[feature].astype('str') # bool raises value error\n",
        "        test_df_norm[feature] = data[feature].astype('str') # bool raises value error\n",
        "        categorical_feature = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            feature, ['True', 'False']\n",
        "        )\n",
        "        new_feature = tf.feature_column.indicator_column(categorical_feature)\n",
        "    else:\n",
        "        new_feature = tf.feature_column.numeric_column(feature)\n",
        "    feature_columns.append(new_feature)\n",
        "\n",
        "# Convert list of feature columns into a layer that will be fed into the model. \n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6VAf7qw2EXE"
      },
      "source": [
        "## Plotting functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tynBAM6M2IbG",
        "outputId": "5750912d-93ea-44ef-c967-754818360216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def plot_loss_curve(epochs, mse):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, mse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_loss_curve function.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the plot_loss_curve function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hUsbjDT23Ua"
      },
      "source": [
        "## Linear Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJNsGvor2-KY",
        "outputId": "734f154a-eb72-4801-9d6a-427545181309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def create_model(my_learning_rate, feature_layer, l2=0):\n",
        "    \"\"\"Create and compile a linear regression model with l2 regularization.\"\"\"\n",
        "    # Most simple tf.keras models are sequential.\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Add the layer containing the feature columns to the model.\n",
        "    model.add(feature_layer)\n",
        "\n",
        "    # Add one linear layer to the model to yield a simple linear regressor.\n",
        "    model.add(tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
        "                                    kernel_regularizer=tf.keras.regularizers.l2(l2)))\n",
        "\n",
        "    # Construct the layers into a model that TensorFlow can execute.\n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "    return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size, label_name):\n",
        "    \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "    # Split the dataset into features and label.\n",
        "    features = {name:np.array(value) for name, value in dataset.items()}\n",
        "    label = np.array(features.pop(label_name))\n",
        "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                        epochs=epochs, shuffle=True)\n",
        "\n",
        "    # Get details that will be useful for plotting the loss curve.\n",
        "    epochs = history.epoch\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    rmse = hist[\"mean_squared_error\"]\n",
        "\n",
        "    return epochs, rmse   \n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZy2fjeP5fe7",
        "outputId": "76f2e68f-97ca-40d2-ae60-13bdd6e48d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "# Hyperparameters.\n",
        "learning_rate = 0.002\n",
        "epochs = 150\n",
        "batch_size = 1000\n",
        "l2 = 0.1\n",
        "label_name = \"price\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_linear_model = create_model(learning_rate, my_feature_layer, l2)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse = train_model(my_linear_model, train_df_norm, epochs, batch_size, label_name)\n",
        "plot_loss_curve(epochs, mse)\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_linear_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.6994 - mean_squared_error: 1.4881\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5345 - mean_squared_error: 1.3467\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.4402 - mean_squared_error: 1.2673\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3667 - mean_squared_error: 1.2053\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3037 - mean_squared_error: 1.1520\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2496 - mean_squared_error: 1.1065\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.2018 - mean_squared_error: 1.0665\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1580 - mean_squared_error: 1.0295\n",
            "Epoch 9/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1176 - mean_squared_error: 0.9959\n",
            "Epoch 10/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0799 - mean_squared_error: 0.9639\n",
            "Epoch 11/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0450 - mean_squared_error: 0.9346\n",
            "Epoch 12/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0130 - mean_squared_error: 0.9078\n",
            "Epoch 13/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9812 - mean_squared_error: 0.8813\n",
            "Epoch 14/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9510 - mean_squared_error: 0.8560\n",
            "Epoch 15/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9232 - mean_squared_error: 0.8326\n",
            "Epoch 16/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8967 - mean_squared_error: 0.8102\n",
            "Epoch 17/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8712 - mean_squared_error: 0.7889\n",
            "Epoch 18/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8477 - mean_squared_error: 0.7694\n",
            "Epoch 19/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8240 - mean_squared_error: 0.7493\n",
            "Epoch 20/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8027 - mean_squared_error: 0.7314\n",
            "Epoch 21/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7816 - mean_squared_error: 0.7136\n",
            "Epoch 22/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7614 - mean_squared_error: 0.6965\n",
            "Epoch 23/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7415 - mean_squared_error: 0.6795\n",
            "Epoch 24/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7239 - mean_squared_error: 0.6649\n",
            "Epoch 25/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7057 - mean_squared_error: 0.6489\n",
            "Epoch 26/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6888 - mean_squared_error: 0.6343\n",
            "Epoch 27/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6722 - mean_squared_error: 0.6201\n",
            "Epoch 28/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6568 - mean_squared_error: 0.6067\n",
            "Epoch 29/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6416 - mean_squared_error: 0.5937\n",
            "Epoch 30/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6276 - mean_squared_error: 0.5815\n",
            "Epoch 31/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6139 - mean_squared_error: 0.5696\n",
            "Epoch 32/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6007 - mean_squared_error: 0.5577\n",
            "Epoch 33/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5888 - mean_squared_error: 0.5473\n",
            "Epoch 34/150\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5776 - mean_squared_error: 0.5376\n",
            "Epoch 35/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5664 - mean_squared_error: 0.5277\n",
            "Epoch 36/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5559 - mean_squared_error: 0.5184\n",
            "Epoch 37/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5458 - mean_squared_error: 0.5097\n",
            "Epoch 38/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5356 - mean_squared_error: 0.5006\n",
            "Epoch 39/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5266 - mean_squared_error: 0.4923\n",
            "Epoch 40/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5177 - mean_squared_error: 0.4843\n",
            "Epoch 41/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5089 - mean_squared_error: 0.4760\n",
            "Epoch 42/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5006 - mean_squared_error: 0.4687\n",
            "Epoch 43/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4927 - mean_squared_error: 0.4615\n",
            "Epoch 44/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4855 - mean_squared_error: 0.4547\n",
            "Epoch 45/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4779 - mean_squared_error: 0.4478\n",
            "Epoch 46/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4712 - mean_squared_error: 0.4418\n",
            "Epoch 47/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4645 - mean_squared_error: 0.4354\n",
            "Epoch 48/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4580 - mean_squared_error: 0.4293\n",
            "Epoch 49/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4526 - mean_squared_error: 0.4243\n",
            "Epoch 50/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4468 - mean_squared_error: 0.4187\n",
            "Epoch 51/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4408 - mean_squared_error: 0.4130\n",
            "Epoch 52/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4355 - mean_squared_error: 0.4081\n",
            "Epoch 53/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4302 - mean_squared_error: 0.4027\n",
            "Epoch 54/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4258 - mean_squared_error: 0.3987\n",
            "Epoch 55/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4209 - mean_squared_error: 0.3938\n",
            "Epoch 56/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4166 - mean_squared_error: 0.3899\n",
            "Epoch 57/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4121 - mean_squared_error: 0.3853\n",
            "Epoch 58/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4079 - mean_squared_error: 0.3808\n",
            "Epoch 59/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4038 - mean_squared_error: 0.3771\n",
            "Epoch 60/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3999 - mean_squared_error: 0.3730\n",
            "Epoch 61/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3965 - mean_squared_error: 0.3696\n",
            "Epoch 62/150\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3924 - mean_squared_error: 0.3654\n",
            "Epoch 63/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3891 - mean_squared_error: 0.3621\n",
            "Epoch 64/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3862 - mean_squared_error: 0.3593\n",
            "Epoch 65/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3829 - mean_squared_error: 0.3559\n",
            "Epoch 66/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3801 - mean_squared_error: 0.3530\n",
            "Epoch 67/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3769 - mean_squared_error: 0.3498\n",
            "Epoch 68/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3739 - mean_squared_error: 0.3467\n",
            "Epoch 69/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3715 - mean_squared_error: 0.3445\n",
            "Epoch 70/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3691 - mean_squared_error: 0.3418\n",
            "Epoch 71/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3663 - mean_squared_error: 0.3391\n",
            "Epoch 72/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3639 - mean_squared_error: 0.3365\n",
            "Epoch 73/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3621 - mean_squared_error: 0.3349\n",
            "Epoch 74/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3598 - mean_squared_error: 0.3324\n",
            "Epoch 75/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3572 - mean_squared_error: 0.3299\n",
            "Epoch 76/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3554 - mean_squared_error: 0.3281\n",
            "Epoch 77/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3532 - mean_squared_error: 0.3258\n",
            "Epoch 78/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3515 - mean_squared_error: 0.3238\n",
            "Epoch 79/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3497 - mean_squared_error: 0.3220\n",
            "Epoch 80/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3477 - mean_squared_error: 0.3198\n",
            "Epoch 81/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3461 - mean_squared_error: 0.3180\n",
            "Epoch 82/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3450 - mean_squared_error: 0.3171\n",
            "Epoch 83/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3428 - mean_squared_error: 0.3148\n",
            "Epoch 84/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3413 - mean_squared_error: 0.3131\n",
            "Epoch 85/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3405 - mean_squared_error: 0.3121\n",
            "Epoch 86/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3387 - mean_squared_error: 0.3105\n",
            "Epoch 87/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3378 - mean_squared_error: 0.3092\n",
            "Epoch 88/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3363 - mean_squared_error: 0.3078\n",
            "Epoch 89/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3350 - mean_squared_error: 0.3065\n",
            "Epoch 90/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3340 - mean_squared_error: 0.3055\n",
            "Epoch 91/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3325 - mean_squared_error: 0.3036\n",
            "Epoch 92/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3319 - mean_squared_error: 0.3029\n",
            "Epoch 93/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3305 - mean_squared_error: 0.3011\n",
            "Epoch 94/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3295 - mean_squared_error: 0.3000\n",
            "Epoch 95/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3286 - mean_squared_error: 0.2989\n",
            "Epoch 96/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3276 - mean_squared_error: 0.2975\n",
            "Epoch 97/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3266 - mean_squared_error: 0.2964\n",
            "Epoch 98/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3257 - mean_squared_error: 0.2953\n",
            "Epoch 99/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3249 - mean_squared_error: 0.2946\n",
            "Epoch 100/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3242 - mean_squared_error: 0.2939\n",
            "Epoch 101/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3231 - mean_squared_error: 0.2925\n",
            "Epoch 102/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3226 - mean_squared_error: 0.2919\n",
            "Epoch 103/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3220 - mean_squared_error: 0.2910\n",
            "Epoch 104/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3213 - mean_squared_error: 0.2900\n",
            "Epoch 105/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3204 - mean_squared_error: 0.2894\n",
            "Epoch 106/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3205 - mean_squared_error: 0.2894\n",
            "Epoch 107/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3196 - mean_squared_error: 0.2884\n",
            "Epoch 108/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3188 - mean_squared_error: 0.2875\n",
            "Epoch 109/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3180 - mean_squared_error: 0.2864\n",
            "Epoch 110/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3173 - mean_squared_error: 0.2852\n",
            "Epoch 111/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3171 - mean_squared_error: 0.2851\n",
            "Epoch 112/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3161 - mean_squared_error: 0.2841\n",
            "Epoch 113/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3155 - mean_squared_error: 0.2833\n",
            "Epoch 114/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3151 - mean_squared_error: 0.2827\n",
            "Epoch 115/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3150 - mean_squared_error: 0.2822\n",
            "Epoch 116/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3140 - mean_squared_error: 0.2815\n",
            "Epoch 117/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3137 - mean_squared_error: 0.2808\n",
            "Epoch 118/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3129 - mean_squared_error: 0.2799\n",
            "Epoch 119/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3127 - mean_squared_error: 0.2800\n",
            "Epoch 120/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3123 - mean_squared_error: 0.2790\n",
            "Epoch 121/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3117 - mean_squared_error: 0.2783\n",
            "Epoch 122/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3113 - mean_squared_error: 0.2782\n",
            "Epoch 123/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3112 - mean_squared_error: 0.2778\n",
            "Epoch 124/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3106 - mean_squared_error: 0.2772\n",
            "Epoch 125/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3103 - mean_squared_error: 0.2765\n",
            "Epoch 126/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3101 - mean_squared_error: 0.2762\n",
            "Epoch 127/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3102 - mean_squared_error: 0.2762\n",
            "Epoch 128/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3100 - mean_squared_error: 0.2760\n",
            "Epoch 129/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3091 - mean_squared_error: 0.2751\n",
            "Epoch 130/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3084 - mean_squared_error: 0.2739\n",
            "Epoch 131/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3084 - mean_squared_error: 0.2740\n",
            "Epoch 132/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3079 - mean_squared_error: 0.2732\n",
            "Epoch 133/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3077 - mean_squared_error: 0.2730\n",
            "Epoch 134/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3075 - mean_squared_error: 0.2721\n",
            "Epoch 135/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3068 - mean_squared_error: 0.2716\n",
            "Epoch 136/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3068 - mean_squared_error: 0.2715\n",
            "Epoch 137/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3066 - mean_squared_error: 0.2712\n",
            "Epoch 138/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3066 - mean_squared_error: 0.2708\n",
            "Epoch 139/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3067 - mean_squared_error: 0.2710\n",
            "Epoch 140/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3061 - mean_squared_error: 0.2702\n",
            "Epoch 141/150\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3061 - mean_squared_error: 0.2698\n",
            "Epoch 142/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3062 - mean_squared_error: 0.2696\n",
            "Epoch 143/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3057 - mean_squared_error: 0.2691\n",
            "Epoch 144/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3060 - mean_squared_error: 0.2695\n",
            "Epoch 145/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3065 - mean_squared_error: 0.2694\n",
            "Epoch 146/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3053 - mean_squared_error: 0.2684\n",
            "Epoch 147/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3051 - mean_squared_error: 0.2683\n",
            "Epoch 148/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3054 - mean_squared_error: 0.2686\n",
            "Epoch 149/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3052 - mean_squared_error: 0.2684\n",
            "Epoch 150/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3052 - mean_squared_error: 0.2679\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 385.78125 262.19625\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-10-17T22:38:56.994679</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 385.78125 262.19625 \nL 385.78125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 224.64 \nL 378.58125 224.64 \nL 378.58125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mc2ad6603ec\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#mc2ad6603ec\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(55.818182 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"99.853611\" xlink:href=\"#mc2ad6603ec\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g transform=\"translate(93.491111 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"140.707791\" xlink:href=\"#mc2ad6603ec\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g transform=\"translate(134.345291 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"181.56197\" xlink:href=\"#mc2ad6603ec\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g transform=\"translate(175.19947 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"222.416149\" xlink:href=\"#mc2ad6603ec\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g transform=\"translate(216.053649 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"263.270329\" xlink:href=\"#mc2ad6603ec\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <g transform=\"translate(253.726579 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"304.124508\" xlink:href=\"#mc2ad6603ec\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g transform=\"translate(294.580758 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"344.978687\" xlink:href=\"#mc2ad6603ec\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 140 -->\n      <g transform=\"translate(335.434937 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- Epoch -->\n     <g transform=\"translate(195.870313 252.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m145b6b8abd\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m145b6b8abd\" y=\"199.8847\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 203.683919)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m145b6b8abd\" y=\"165.864997\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 169.664216)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m145b6b8abd\" y=\"131.845294\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 135.644513)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m145b6b8abd\" y=\"97.825591\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 101.624809)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m145b6b8abd\" y=\"63.805887\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.2 -->\n      <g transform=\"translate(20.878125 67.605106)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m145b6b8abd\" y=\"29.786184\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.4 -->\n      <g transform=\"translate(20.878125 33.585403)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Mean Squared Error -->\n     <g transform=\"translate(14.798438 165.681719)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n       <path d=\"M 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\nM 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nL 54.390625 -20.796875 \nL 45.40625 -20.796875 \nz\n\" id=\"DejaVuSans-113\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"86.279297\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"147.802734\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"209.082031\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"272.460938\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"304.248047\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"367.724609\" xlink:href=\"#DejaVuSans-113\"/>\n      <use x=\"431.201172\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"494.580078\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"555.859375\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"594.722656\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"656.246094\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"719.722656\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"751.509766\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"814.693359\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"854.056641\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"892.919922\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"954.101562\" xlink:href=\"#DejaVuSans-114\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p9ae632ac03)\" d=\"M 58.999432 14.793906 \nL 61.042141 38.856073 \nL 63.08485 52.364562 \nL 65.127559 62.911122 \nL 67.170268 71.974437 \nL 69.212977 79.704761 \nL 71.255686 86.521226 \nL 73.298395 92.802634 \nL 77.383813 103.967278 \nL 79.426522 108.952407 \nL 83.511939 118.018266 \nL 85.554648 122.325514 \nL 89.640066 130.102699 \nL 91.682775 133.727676 \nL 97.810902 143.515327 \nL 101.89632 149.448898 \nL 103.939029 152.350157 \nL 105.981738 154.827853 \nL 108.024447 157.542338 \nL 112.109865 162.44794 \nL 116.195283 166.930688 \nL 122.32341 173.061283 \nL 126.408828 176.482818 \nL 130.494246 179.739214 \nL 136.622373 184.187952 \nL 142.7505 188.199907 \nL 148.878626 191.760311 \nL 159.092171 196.700004 \nL 161.13488 197.678126 \nL 169.305716 200.939759 \nL 173.391134 202.379145 \nL 175.433843 203.142875 \nL 181.56197 205.06116 \nL 183.604679 205.774233 \nL 189.732806 207.3914 \nL 201.98906 210.243116 \nL 204.031769 210.693537 \nL 206.074478 210.963463 \nL 214.245313 212.513786 \nL 222.416149 213.828791 \nL 224.458858 213.98664 \nL 228.544276 214.671973 \nL 230.586985 214.836016 \nL 236.715112 215.575966 \nL 257.142202 217.691986 \nL 261.22762 217.934209 \nL 263.270329 218.176254 \nL 267.355747 218.421453 \nL 271.441165 218.698051 \nL 273.483874 218.700038 \nL 287.782836 219.729533 \nL 314.338053 220.943698 \nL 318.423471 220.969927 \nL 322.508889 221.33757 \nL 324.551598 221.313896 \nL 330.679725 221.636245 \nL 336.807852 221.801764 \nL 349.064105 222.15648 \nL 353.149523 222.096347 \nL 355.192232 222.270332 \nL 363.363068 222.361889 \nL 363.363068 222.361889 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 224.64 \nL 43.78125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 378.58125 224.64 \nL 378.58125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 224.64 \nL 378.58125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 378.58125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 317.646875 29.878125 \nL 371.58125 29.878125 \nQ 373.58125 29.878125 373.58125 27.878125 \nL 373.58125 14.2 \nQ 373.58125 12.2 371.58125 12.2 \nL 317.646875 12.2 \nQ 315.646875 12.2 315.646875 14.2 \nL 315.646875 27.878125 \nQ 315.646875 29.878125 317.646875 29.878125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 319.646875 20.298437 \nL 339.646875 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_17\"/>\n    <g id=\"text_17\">\n     <!-- Loss -->\n     <g transform=\"translate(347.646875 23.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9ae632ac03\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3409 - mean_squared_error: 0.3041\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34086689352989197, 0.3041191101074219]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRphzOlVVcMY"
      },
      "source": [
        "Data including demographics:   \n",
        "**Training:** loss: 0.2409 - mean_squared_error: 0.2409   \n",
        "**Validation:** loss: 0.4419 - mean_squared_error: 0.4419\n",
        "  \n",
        "---\n",
        "\n",
        "Data excluding demographics:   \n",
        "**Training:** loss: 0.2290 - mean_squared_error: 0.2290    \n",
        "**Validation:** loss: 0.3215 - mean_squared_error: 0.3215  \n",
        "\n",
        "---\n",
        "\n",
        "The linear model appears to perform better without the demographic data. The\n",
        "difference between training and validation metrics remains rather large. More stringent regularization may be advisable.\n",
        "\n",
        "---\n",
        "\n",
        "After Regularization of model with data excluding demographics:  \n",
        "**Training:** loss: 0.3113 - mean_squared_error: 0.2792  \n",
        "**Validation:** loss: 0.3497 - mean_squared_error: 0.3178"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOOl09u7eG6Q",
        "outputId": "23cbcfec-9ddc-4f03-8967-626a8e3ee34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Z-score conversion to $\n",
        "test_mse = my_linear_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)[1]\n",
        "test_mse * train_df_std.price"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3409 - mean_squared_error: 0.3041\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56778.79468936736"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ToPIBHYMBPq"
      },
      "source": [
        "## Deep neural net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQI6KtcJMFWT"
      },
      "source": [
        "def create_model(my_learning_rate, my_feature_layer, n_layers, n_nodes):\n",
        "    \"\"\"Create and compile a simple linear regression model.\n",
        "  \n",
        "    Args:\n",
        "    my_learning_rate - integer representing learning rate\n",
        "    my_feature_layer - tf feature columns\n",
        "    n_layers - integer indicating the number of layers\n",
        "    n_nodes - list of integers, indicating the number of nodes for each leayer.\n",
        "        len(n_nodes) must be n_layers\n",
        "    \"\"\"\n",
        "\n",
        "    # Stop if n_nodes as less or more elements than there are layers\n",
        "    if len(n_nodes) != n_layers:\n",
        "        print(\"n_nodes must be of length n_layers!\")\n",
        "        return None\n",
        "\n",
        "    # Most simple tf.keras models are sequential.\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Add the layer containing the feature columns to the model.\n",
        "    model.add(my_feature_layer)\n",
        "\n",
        "  # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
        "  # method once for each layer. We've specified the following arguments:\n",
        "  #   * units specifies the number of nodes in this layer.\n",
        "  #   * activation specifies the activation function (Rectified Linear Unit).\n",
        "  #   * name is just a string that can be useful when debugging.\n",
        "\n",
        "\n",
        "    # Define layers and nodes\n",
        "    for layer in range(n_layers):\n",
        "        nodes = n_nodes[layer]\n",
        "        name = 'Hidden' + str(layer)\n",
        "        # Define hidden layer with n nodes.   \n",
        "        model.add(tf.keras.layers.Dense(units=nodes, \n",
        "                                        activation='tanh',\n",
        "                                        kernel_regularizer=tf.keras.regularizers.l2(0.2), \n",
        "                                        name=name)) \n",
        "        # # Dropout layer\n",
        "        # model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "    # Define the output layer.\n",
        "    model.add(tf.keras.layers.Dense(units=1,  \n",
        "                                    name='Output'))                              \n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhqty7sS6_tJ"
      },
      "source": [
        "def train_model(model, dataset, epochs, label_name,\n",
        "                batch_size=None):\n",
        "    \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "    # Split the dataset into features and label.\n",
        "    features = {name:np.array(value) for name, value in dataset.items()}\n",
        "    label = np.array(features.pop(label_name))\n",
        "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                        epochs=epochs, shuffle=True) \n",
        "\n",
        "    # The list of epochs is stored separately from the rest of history.\n",
        "    epochs = history.epoch\n",
        "\n",
        "    # To track the progression of training, gather a snapshot\n",
        "    # of the model's mean squared error at each epoch. \n",
        "    hist = pd.DataFrame(history.history)\n",
        "    mse = hist[\"mean_squared_error\"]\n",
        "\n",
        "    return epochs, mse"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyZw1CCw7Q6W",
        "outputId": "99ea81a4-ed5b-4e2d-a55c-f8cbc569e212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "batch_size = 1000\n",
        "n_layers = 1\n",
        "n_nodes = [13]\n",
        "\n",
        "# Specify the label\n",
        "label_name = \"price\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer, n_layers, n_nodes)\n",
        "\n",
        "# Train the model on the normalized training set. We're passing the entire\n",
        "# normalized training set, but the model will only use the features\n",
        "# defined by the feature_layer.\n",
        "epochs, mse = train_model(my_model, train_df_norm, epochs, \n",
        "                          label_name, batch_size)\n",
        "plot_loss_curve(epochs, mse)\n",
        "\n",
        "# After building a model against the training set, test that model\n",
        "# against the test set.\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8297 - mean_squared_error: 1.0439\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6231 - mean_squared_error: 0.9587\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4287 - mean_squared_error: 0.8834\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2473 - mean_squared_error: 0.8190\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.0791 - mean_squared_error: 0.7661\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.9207 - mean_squared_error: 0.7213\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.7710 - mean_squared_error: 0.6835\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.6291 - mean_squared_error: 0.6521\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4927 - mean_squared_error: 0.6243\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.3622 - mean_squared_error: 0.6007\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.2346 - mean_squared_error: 0.5779\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1114 - mean_squared_error: 0.5577\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9915 - mean_squared_error: 0.5387\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8753 - mean_squared_error: 0.5213\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.7629 - mean_squared_error: 0.5056\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6540 - mean_squared_error: 0.4913\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5486 - mean_squared_error: 0.4783\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4470 - mean_squared_error: 0.4669\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3478 - mean_squared_error: 0.4558\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2523 - mean_squared_error: 0.4462\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.1596 - mean_squared_error: 0.4371\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0694 - mean_squared_error: 0.4286\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.9817 - mean_squared_error: 0.4204\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8969 - mean_squared_error: 0.4131\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8144 - mean_squared_error: 0.4058\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7342 - mean_squared_error: 0.3989\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.6560 - mean_squared_error: 0.3921\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5806 - mean_squared_error: 0.3862\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.5075 - mean_squared_error: 0.3805\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.4362 - mean_squared_error: 0.3750\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3673 - mean_squared_error: 0.3699\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.3002 - mean_squared_error: 0.3650\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2354 - mean_squared_error: 0.3605\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1724 - mean_squared_error: 0.3561\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1112 - mean_squared_error: 0.3519\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0520 - mean_squared_error: 0.3478\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9946 - mean_squared_error: 0.3440\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9389 - mean_squared_error: 0.3403\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8850 - mean_squared_error: 0.3368\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.8326 - mean_squared_error: 0.3333\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7819 - mean_squared_error: 0.3301\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7327 - mean_squared_error: 0.3271\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6852 - mean_squared_error: 0.3242\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.6390 - mean_squared_error: 0.3213\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5943 - mean_squared_error: 0.3187\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5510 - mean_squared_error: 0.3160\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5090 - mean_squared_error: 0.3134\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4684 - mean_squared_error: 0.3111\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4289 - mean_squared_error: 0.3087\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.3908 - mean_squared_error: 0.3066\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.3538 - mean_squared_error: 0.3045\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3180 - mean_squared_error: 0.3026\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2833 - mean_squared_error: 0.3007\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2498 - mean_squared_error: 0.2990\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.2173 - mean_squared_error: 0.2973\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1859 - mean_squared_error: 0.2956\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1555 - mean_squared_error: 0.2940\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1259 - mean_squared_error: 0.2924\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0973 - mean_squared_error: 0.2909\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0698 - mean_squared_error: 0.2896\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0430 - mean_squared_error: 0.2882\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0172 - mean_squared_error: 0.2869\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9922 - mean_squared_error: 0.2856\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9680 - mean_squared_error: 0.2844\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9445 - mean_squared_error: 0.2832\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9220 - mean_squared_error: 0.2822\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9001 - mean_squared_error: 0.2810\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8788 - mean_squared_error: 0.2799\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8583 - mean_squared_error: 0.2788\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8386 - mean_squared_error: 0.2779\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8195 - mean_squared_error: 0.2770\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8009 - mean_squared_error: 0.2762\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7830 - mean_squared_error: 0.2754\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7657 - mean_squared_error: 0.2746\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7489 - mean_squared_error: 0.2738\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7327 - mean_squared_error: 0.2730\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7171 - mean_squared_error: 0.2722\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7019 - mean_squared_error: 0.2715\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6873 - mean_squared_error: 0.2708\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6732 - mean_squared_error: 0.2701\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6596 - mean_squared_error: 0.2696\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6465 - mean_squared_error: 0.2690\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6338 - mean_squared_error: 0.2685\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6214 - mean_squared_error: 0.2679\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6096 - mean_squared_error: 0.2675\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5982 - mean_squared_error: 0.2671\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5871 - mean_squared_error: 0.2667\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5764 - mean_squared_error: 0.2663\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5661 - mean_squared_error: 0.2659\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5562 - mean_squared_error: 0.2655\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5466 - mean_squared_error: 0.2650\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5372 - mean_squared_error: 0.2643\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5284 - mean_squared_error: 0.2639\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5197 - mean_squared_error: 0.2635\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5113 - mean_squared_error: 0.2630\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5033 - mean_squared_error: 0.2628\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4956 - mean_squared_error: 0.2625\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4881 - mean_squared_error: 0.2621\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4808 - mean_squared_error: 0.2617\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4738 - mean_squared_error: 0.2612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fab26840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5022 - mean_squared_error: 0.2951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5022090077400208, 0.295091837644577]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc7SfS8E7jHx",
        "outputId": "df184249-deae-4eba-b896-ab230f4ea57d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Node tuning\n",
        "learning_rate = 0.0015\n",
        "epochs = 100\n",
        "batch_size = 1000\n",
        "n_layers = 1\n",
        "n_nodes = [[25], [15], [10]]\n",
        "\n",
        "# Test data\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "\n",
        "average_mses = []\n",
        "for nodes in n_nodes:\n",
        "    mse_simulation = []\n",
        "    # 10 simulations for each node hyperparamter\n",
        "    for i in range(10):\n",
        "        # Specify the label\n",
        "        label_name = \"price\"\n",
        "\n",
        "        # Establish the model's topography.\n",
        "        my_model = create_model(learning_rate, my_feature_layer, n_layers, nodes)\n",
        "\n",
        "        # Train the model on the normalized training set. We're passing the entire\n",
        "        # normalized training set, but the model will only use the features\n",
        "        # defined by the feature_layer.\n",
        "        epoch, mse = train_model(my_model, train_df_norm, epochs, \n",
        "                                label_name, batch_size)\n",
        "        \n",
        "        # After building a model against the training set, test that model\n",
        "        # against the test set.\n",
        "        print(\"\\n Evaluate the new model against the test set:\")\n",
        "        mse = my_model.evaluate(x = test_features, \n",
        "                                y = test_label, \n",
        "                                batch_size=batch_size)[1]\n",
        "        mse_simulation.append(mse)                        \n",
        "        print('Training MSE:', mse)\n",
        "        print('+'*75)\n",
        "    average_mse = np.array(mse_simulation).mean()\n",
        "    average_mses.append(average_mse)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7202 - mean_squared_error: 0.2691\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6325 - mean_squared_error: 0.2685\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5496 - mean_squared_error: 0.2679\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4714 - mean_squared_error: 0.2673\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3975 - mean_squared_error: 0.2664\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3283 - mean_squared_error: 0.2661\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.2630 - mean_squared_error: 0.2654\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2014 - mean_squared_error: 0.2646\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1433 - mean_squared_error: 0.2638\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0887 - mean_squared_error: 0.2632\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0375 - mean_squared_error: 0.2628\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9892 - mean_squared_error: 0.2623\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9439 - mean_squared_error: 0.2619\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9011 - mean_squared_error: 0.2610\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8615 - mean_squared_error: 0.2607\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8239 - mean_squared_error: 0.2603\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7886 - mean_squared_error: 0.2601\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7557 - mean_squared_error: 0.2602\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7248 - mean_squared_error: 0.2602\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6958 - mean_squared_error: 0.2601\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6686 - mean_squared_error: 0.2598\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6429 - mean_squared_error: 0.2596\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6190 - mean_squared_error: 0.2596\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5970 - mean_squared_error: 0.2597\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5761 - mean_squared_error: 0.2593\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5566 - mean_squared_error: 0.2592\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5384 - mean_squared_error: 0.2590\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5212 - mean_squared_error: 0.2586\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5053 - mean_squared_error: 0.2581\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4904 - mean_squared_error: 0.2579\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4766 - mean_squared_error: 0.2579\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4636 - mean_squared_error: 0.2578\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4515 - mean_squared_error: 0.2576\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4402 - mean_squared_error: 0.2573\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4296 - mean_squared_error: 0.2573\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4198 - mean_squared_error: 0.2571\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4105 - mean_squared_error: 0.2566\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4020 - mean_squared_error: 0.2566\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3942 - mean_squared_error: 0.2565\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3870 - mean_squared_error: 0.2566\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3800 - mean_squared_error: 0.2565\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3737 - mean_squared_error: 0.2565\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3677 - mean_squared_error: 0.2564\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3620 - mean_squared_error: 0.2561\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3569 - mean_squared_error: 0.2561\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3522 - mean_squared_error: 0.2559\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3478 - mean_squared_error: 0.2557\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3439 - mean_squared_error: 0.2556\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3398 - mean_squared_error: 0.2552\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3365 - mean_squared_error: 0.2554\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3333 - mean_squared_error: 0.2554\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3302 - mean_squared_error: 0.2552\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3275 - mean_squared_error: 0.2553\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3243 - mean_squared_error: 0.2550\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3222 - mean_squared_error: 0.2557\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3197 - mean_squared_error: 0.2554\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3175 - mean_squared_error: 0.2550\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3158 - mean_squared_error: 0.2551\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff65c6b6048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3631 - mean_squared_error: 0.3040\n",
            "Training MSE: 0.30396437644958496\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.1475 - mean_squared_error: 1.2847\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.3663 - mean_squared_error: 1.1327\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.6297 - mean_squared_error: 1.0111\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.9297 - mean_squared_error: 0.9119\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.2576 - mean_squared_error: 0.8245\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6194 - mean_squared_error: 0.7530\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0054 - mean_squared_error: 0.6870\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4188 - mean_squared_error: 0.6294\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8599 - mean_squared_error: 0.5804\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3274 - mean_squared_error: 0.5386\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8191 - mean_squared_error: 0.5020\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3349 - mean_squared_error: 0.4707\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.8748 - mean_squared_error: 0.4451\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4363 - mean_squared_error: 0.4232\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0180 - mean_squared_error: 0.4040\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6198 - mean_squared_error: 0.3880\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.2400 - mean_squared_error: 0.3742\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8783 - mean_squared_error: 0.3625\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5333 - mean_squared_error: 0.3524\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2041 - mean_squared_error: 0.3434\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.8908 - mean_squared_error: 0.3361\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.5925 - mean_squared_error: 0.3297\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3085 - mean_squared_error: 0.3240\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.0385 - mean_squared_error: 0.3194\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7814 - mean_squared_error: 0.3148\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5370 - mean_squared_error: 0.3108\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.3050 - mean_squared_error: 0.3074\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.0848 - mean_squared_error: 0.3043\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8757 - mean_squared_error: 0.3015\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6769 - mean_squared_error: 0.2989\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4886 - mean_squared_error: 0.2969\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.3101 - mean_squared_error: 0.2952\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1408 - mean_squared_error: 0.2935\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9802 - mean_squared_error: 0.2916\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.8277 - mean_squared_error: 0.2896\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.6833 - mean_squared_error: 0.2878\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.5469 - mean_squared_error: 0.2863\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.4174 - mean_squared_error: 0.2846\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.2949 - mean_squared_error: 0.2830\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.1787 - mean_squared_error: 0.2816\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0690 - mean_squared_error: 0.2804\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.9654 - mean_squared_error: 0.2795\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8674 - mean_squared_error: 0.2787\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7742 - mean_squared_error: 0.2772\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6866 - mean_squared_error: 0.2759\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6045 - mean_squared_error: 0.2753\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5259 - mean_squared_error: 0.2741\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4518 - mean_squared_error: 0.2733\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3825 - mean_squared_error: 0.2732\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3167 - mean_squared_error: 0.2726\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2545 - mean_squared_error: 0.2716\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1962 - mean_squared_error: 0.2710\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1409 - mean_squared_error: 0.2702\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0888 - mean_squared_error: 0.2696\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0399 - mean_squared_error: 0.2692\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9939 - mean_squared_error: 0.2687\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9510 - mean_squared_error: 0.2684\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9099 - mean_squared_error: 0.2674\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8713 - mean_squared_error: 0.2669\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8354 - mean_squared_error: 0.2669\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8015 - mean_squared_error: 0.2665\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7692 - mean_squared_error: 0.2656\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7393 - mean_squared_error: 0.2652\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7111 - mean_squared_error: 0.2648\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6846 - mean_squared_error: 0.2643\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6598 - mean_squared_error: 0.2639\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6365 - mean_squared_error: 0.2638\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6147 - mean_squared_error: 0.2637\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5942 - mean_squared_error: 0.2637\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5749 - mean_squared_error: 0.2634\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5569 - mean_squared_error: 0.2629\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5404 - mean_squared_error: 0.2626\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5246 - mean_squared_error: 0.2622\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5095 - mean_squared_error: 0.2617\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4956 - mean_squared_error: 0.2615\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4825 - mean_squared_error: 0.2612\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4702 - mean_squared_error: 0.2607\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4590 - mean_squared_error: 0.2604\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4484 - mean_squared_error: 0.2601\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4384 - mean_squared_error: 0.2601\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4290 - mean_squared_error: 0.2601\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4203 - mean_squared_error: 0.2599\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4119 - mean_squared_error: 0.2593\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4045 - mean_squared_error: 0.2592\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3972 - mean_squared_error: 0.2591\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3905 - mean_squared_error: 0.2590\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3843 - mean_squared_error: 0.2591\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3786 - mean_squared_error: 0.2594\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3732 - mean_squared_error: 0.2593\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3683 - mean_squared_error: 0.2591\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3632 - mean_squared_error: 0.2585\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3591 - mean_squared_error: 0.2587\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3550 - mean_squared_error: 0.2586\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3512 - mean_squared_error: 0.2583\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3475 - mean_squared_error: 0.2579\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3439 - mean_squared_error: 0.2576\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3407 - mean_squared_error: 0.2574\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3380 - mean_squared_error: 0.2576\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3352 - mean_squared_error: 0.2573\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3328 - mean_squared_error: 0.2572\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fa116158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3732 - mean_squared_error: 0.2996\n",
            "Training MSE: 0.2996468245983124\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.7414 - mean_squared_error: 1.0656\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.9811 - mean_squared_error: 0.9440\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.2676 - mean_squared_error: 0.8510\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.5911 - mean_squared_error: 0.7781\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.9449 - mean_squared_error: 0.7187\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.3269 - mean_squared_error: 0.6694\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7347 - mean_squared_error: 0.6267\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1667 - mean_squared_error: 0.5890\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6221 - mean_squared_error: 0.5556\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0997 - mean_squared_error: 0.5253\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6017 - mean_squared_error: 0.5005\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1258 - mean_squared_error: 0.4791\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.6713 - mean_squared_error: 0.4609\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2370 - mean_squared_error: 0.4448\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8215 - mean_squared_error: 0.4296\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4251 - mean_squared_error: 0.4162\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0469 - mean_squared_error: 0.4039\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6866 - mean_squared_error: 0.3929\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.3432 - mean_squared_error: 0.3829\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0165 - mean_squared_error: 0.3743\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7054 - mean_squared_error: 0.3663\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4095 - mean_squared_error: 0.3592\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.1282 - mean_squared_error: 0.3528\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8608 - mean_squared_error: 0.3467\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6069 - mean_squared_error: 0.3413\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.3657 - mean_squared_error: 0.3362\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.1371 - mean_squared_error: 0.3317\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.9203 - mean_squared_error: 0.3273\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7145 - mean_squared_error: 0.3230\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5195 - mean_squared_error: 0.3190\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.3346 - mean_squared_error: 0.3154\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1595 - mean_squared_error: 0.3122\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9938 - mean_squared_error: 0.3094\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8367 - mean_squared_error: 0.3066\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6882 - mean_squared_error: 0.3042\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5480 - mean_squared_error: 0.3023\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.4151 - mean_squared_error: 0.2998\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2893 - mean_squared_error: 0.2974\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.1706 - mean_squared_error: 0.2953\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0584 - mean_squared_error: 0.2932\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.9524 - mean_squared_error: 0.2914\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.8525 - mean_squared_error: 0.2901\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7579 - mean_squared_error: 0.2886\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.6689 - mean_squared_error: 0.2871\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5849 - mean_squared_error: 0.2856\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5056 - mean_squared_error: 0.2841\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4312 - mean_squared_error: 0.2830\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3608 - mean_squared_error: 0.2818\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2944 - mean_squared_error: 0.2806\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.2320 - mean_squared_error: 0.2795\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1733 - mean_squared_error: 0.2786\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1181 - mean_squared_error: 0.2776\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0661 - mean_squared_error: 0.2764\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0173 - mean_squared_error: 0.2753\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9714 - mean_squared_error: 0.2744\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9282 - mean_squared_error: 0.2736\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8876 - mean_squared_error: 0.2732\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8496 - mean_squared_error: 0.2730\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8138 - mean_squared_error: 0.2727\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7803 - mean_squared_error: 0.2723\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7490 - mean_squared_error: 0.2719\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7195 - mean_squared_error: 0.2712\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6918 - mean_squared_error: 0.2707\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6659 - mean_squared_error: 0.2702\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6416 - mean_squared_error: 0.2696\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6188 - mean_squared_error: 0.2690\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5977 - mean_squared_error: 0.2685\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5777 - mean_squared_error: 0.2678\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5591 - mean_squared_error: 0.2671\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5418 - mean_squared_error: 0.2666\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5254 - mean_squared_error: 0.2661\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5104 - mean_squared_error: 0.2661\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4961 - mean_squared_error: 0.2657\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4827 - mean_squared_error: 0.2654\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4702 - mean_squared_error: 0.2651\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4588 - mean_squared_error: 0.2650\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4479 - mean_squared_error: 0.2645\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4378 - mean_squared_error: 0.2643\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4284 - mean_squared_error: 0.2641\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4197 - mean_squared_error: 0.2639\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4114 - mean_squared_error: 0.2636\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4040 - mean_squared_error: 0.2637\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3968 - mean_squared_error: 0.2635\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3903 - mean_squared_error: 0.2634\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3840 - mean_squared_error: 0.2633\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3782 - mean_squared_error: 0.2633\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3732 - mean_squared_error: 0.2634\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3679 - mean_squared_error: 0.2629\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3633 - mean_squared_error: 0.2627\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3589 - mean_squared_error: 0.2621\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3549 - mean_squared_error: 0.2618\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3510 - mean_squared_error: 0.2613\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3473 - mean_squared_error: 0.2608\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3443 - mean_squared_error: 0.2608\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3413 - mean_squared_error: 0.2608\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3383 - mean_squared_error: 0.2605\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3356 - mean_squared_error: 0.2603\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3331 - mean_squared_error: 0.2601\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3309 - mean_squared_error: 0.2604\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3289 - mean_squared_error: 0.2606\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5f42c66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3735 - mean_squared_error: 0.3070\n",
            "Training MSE: 0.30701544880867004\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.9028 - mean_squared_error: 1.2446\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.1187 - mean_squared_error: 1.0935\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.3781 - mean_squared_error: 0.9710\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.6746 - mean_squared_error: 0.8688\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.0050 - mean_squared_error: 0.7834\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.3672 - mean_squared_error: 0.7118\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7608 - mean_squared_error: 0.6530\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1809 - mean_squared_error: 0.6017\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6276 - mean_squared_error: 0.5580\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1004 - mean_squared_error: 0.5215\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5968 - mean_squared_error: 0.4900\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1170 - mean_squared_error: 0.4637\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6600 - mean_squared_error: 0.4420\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2245 - mean_squared_error: 0.4236\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8101 - mean_squared_error: 0.4086\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4149 - mean_squared_error: 0.3956\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0373 - mean_squared_error: 0.3834\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6777 - mean_squared_error: 0.3730\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3351 - mean_squared_error: 0.3641\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0086 - mean_squared_error: 0.3560\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6984 - mean_squared_error: 0.3492\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4032 - mean_squared_error: 0.3429\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1224 - mean_squared_error: 0.3371\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8558 - mean_squared_error: 0.3323\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6024 - mean_squared_error: 0.3277\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.3619 - mean_squared_error: 0.3234\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.1339 - mean_squared_error: 0.3196\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9174 - mean_squared_error: 0.3159\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7121 - mean_squared_error: 0.3126\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.5175 - mean_squared_error: 0.3096\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3332 - mean_squared_error: 0.3069\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1585 - mean_squared_error: 0.3041\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9930 - mean_squared_error: 0.3013\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8367 - mean_squared_error: 0.2988\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6885 - mean_squared_error: 0.2964\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5484 - mean_squared_error: 0.2942\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4158 - mean_squared_error: 0.2920\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2904 - mean_squared_error: 0.2899\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.1720 - mean_squared_error: 0.2881\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0602 - mean_squared_error: 0.2864\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.9547 - mean_squared_error: 0.2850\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.8550 - mean_squared_error: 0.2838\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7609 - mean_squared_error: 0.2826\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6720 - mean_squared_error: 0.2812\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5882 - mean_squared_error: 0.2798\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5094 - mean_squared_error: 0.2787\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4350 - mean_squared_error: 0.2776\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3646 - mean_squared_error: 0.2766\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2987 - mean_squared_error: 0.2761\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2365 - mean_squared_error: 0.2753\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1778 - mean_squared_error: 0.2740\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1225 - mean_squared_error: 0.2730\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0708 - mean_squared_error: 0.2726\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0221 - mean_squared_error: 0.2721\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9761 - mean_squared_error: 0.2715\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9331 - mean_squared_error: 0.2710\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8924 - mean_squared_error: 0.2704\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8544 - mean_squared_error: 0.2698\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8187 - mean_squared_error: 0.2693\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7852 - mean_squared_error: 0.2691\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7538 - mean_squared_error: 0.2688\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7243 - mean_squared_error: 0.2685\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6967 - mean_squared_error: 0.2684\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6710 - mean_squared_error: 0.2684\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6467 - mean_squared_error: 0.2679\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6237 - mean_squared_error: 0.2672\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6023 - mean_squared_error: 0.2666\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5824 - mean_squared_error: 0.2662\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5638 - mean_squared_error: 0.2656\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5461 - mean_squared_error: 0.2649\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5298 - mean_squared_error: 0.2647\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5145 - mean_squared_error: 0.2645\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5001 - mean_squared_error: 0.2643\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4867 - mean_squared_error: 0.2641\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4745 - mean_squared_error: 0.2642\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4628 - mean_squared_error: 0.2638\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4517 - mean_squared_error: 0.2635\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4416 - mean_squared_error: 0.2633\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4321 - mean_squared_error: 0.2630\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4234 - mean_squared_error: 0.2628\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4149 - mean_squared_error: 0.2624\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4072 - mean_squared_error: 0.2623\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3999 - mean_squared_error: 0.2619\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3930 - mean_squared_error: 0.2614\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3868 - mean_squared_error: 0.2611\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3810 - mean_squared_error: 0.2608\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3755 - mean_squared_error: 0.2605\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3703 - mean_squared_error: 0.2602\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3658 - mean_squared_error: 0.2603\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3613 - mean_squared_error: 0.2599\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3569 - mean_squared_error: 0.2597\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3532 - mean_squared_error: 0.2600\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3500 - mean_squared_error: 0.2602\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3461 - mean_squared_error: 0.2592\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3431 - mean_squared_error: 0.2589\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3402 - mean_squared_error: 0.2588\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3373 - mean_squared_error: 0.2586\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3348 - mean_squared_error: 0.2590\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3323 - mean_squared_error: 0.2590\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3301 - mean_squared_error: 0.2590\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5f56eec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3714 - mean_squared_error: 0.3020\n",
            "Training MSE: 0.30198168754577637\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.8278 - mean_squared_error: 1.4789\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2909 - mean_squared_error: 1.3207\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7873 - mean_squared_error: 1.1872\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3221 - mean_squared_error: 1.0833\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8820 - mean_squared_error: 0.9950\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4674 - mean_squared_error: 0.9223\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0715 - mean_squared_error: 0.8583\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6925 - mean_squared_error: 0.8007\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3286 - mean_squared_error: 0.7472\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9803 - mean_squared_error: 0.6984\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6465 - mean_squared_error: 0.6529\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3272 - mean_squared_error: 0.6112\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0228 - mean_squared_error: 0.5736\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7338 - mean_squared_error: 0.5411\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4590 - mean_squared_error: 0.5125\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1975 - mean_squared_error: 0.4874\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9476 - mean_squared_error: 0.4644\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7110 - mean_squared_error: 0.4453\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4844 - mean_squared_error: 0.4272\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.2693 - mean_squared_error: 0.4117\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0639 - mean_squared_error: 0.3975\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.8690 - mean_squared_error: 0.3854\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6835 - mean_squared_error: 0.3747\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5073 - mean_squared_error: 0.3656\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3395 - mean_squared_error: 0.3573\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.1800 - mean_squared_error: 0.3500\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.0278 - mean_squared_error: 0.3430\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8834 - mean_squared_error: 0.3370\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.7458 - mean_squared_error: 0.3311\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6157 - mean_squared_error: 0.3265\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4915 - mean_squared_error: 0.3216\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3736 - mean_squared_error: 0.3173\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2616 - mean_squared_error: 0.3133\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1554 - mean_squared_error: 0.3098\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0543 - mean_squared_error: 0.3063\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9585 - mean_squared_error: 0.3033\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8676 - mean_squared_error: 0.3005\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7814 - mean_squared_error: 0.2979\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6997 - mean_squared_error: 0.2955\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6222 - mean_squared_error: 0.2931\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5489 - mean_squared_error: 0.2911\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4793 - mean_squared_error: 0.2890\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4134 - mean_squared_error: 0.2870\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3512 - mean_squared_error: 0.2853\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2922 - mean_squared_error: 0.2836\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2364 - mean_squared_error: 0.2820\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1835 - mean_squared_error: 0.2804\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1336 - mean_squared_error: 0.2790\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0865 - mean_squared_error: 0.2777\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0419 - mean_squared_error: 0.2766\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9997 - mean_squared_error: 0.2754\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9599 - mean_squared_error: 0.2743\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9223 - mean_squared_error: 0.2733\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8868 - mean_squared_error: 0.2724\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8533 - mean_squared_error: 0.2716\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8217 - mean_squared_error: 0.2708\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7918 - mean_squared_error: 0.2701\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7637 - mean_squared_error: 0.2695\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7371 - mean_squared_error: 0.2689\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7120 - mean_squared_error: 0.2682\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6885 - mean_squared_error: 0.2677\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6662 - mean_squared_error: 0.2671\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6452 - mean_squared_error: 0.2666\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6254 - mean_squared_error: 0.2661\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6068 - mean_squared_error: 0.2657\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5893 - mean_squared_error: 0.2655\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5728 - mean_squared_error: 0.2653\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5572 - mean_squared_error: 0.2650\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5427 - mean_squared_error: 0.2648\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5288 - mean_squared_error: 0.2644\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5158 - mean_squared_error: 0.2640\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5037 - mean_squared_error: 0.2638\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4923 - mean_squared_error: 0.2636\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4814 - mean_squared_error: 0.2633\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4712 - mean_squared_error: 0.2634\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4616 - mean_squared_error: 0.2632\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4526 - mean_squared_error: 0.2629\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4442 - mean_squared_error: 0.2626\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4363 - mean_squared_error: 0.2621\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4289 - mean_squared_error: 0.2619\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4216 - mean_squared_error: 0.2615\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4150 - mean_squared_error: 0.2614\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4087 - mean_squared_error: 0.2613\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4029 - mean_squared_error: 0.2612\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3976 - mean_squared_error: 0.2614\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3923 - mean_squared_error: 0.2613\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3873 - mean_squared_error: 0.2610\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3826 - mean_squared_error: 0.2608\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3782 - mean_squared_error: 0.2606\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3743 - mean_squared_error: 0.2608\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3706 - mean_squared_error: 0.2610\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3671 - mean_squared_error: 0.2611\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3636 - mean_squared_error: 0.2608\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3604 - mean_squared_error: 0.2608\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3574 - mean_squared_error: 0.2608\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3546 - mean_squared_error: 0.2607\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3521 - mean_squared_error: 0.2608\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3493 - mean_squared_error: 0.2604\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3469 - mean_squared_error: 0.2600\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3446 - mean_squared_error: 0.2596\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff60603f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3892 - mean_squared_error: 0.3058\n",
            "Training MSE: 0.30582916736602783\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.1707 - mean_squared_error: 1.5268\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6487 - mean_squared_error: 1.3613\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.1634 - mean_squared_error: 1.2239\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7062 - mean_squared_error: 1.1062\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2719 - mean_squared_error: 1.0030\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8589 - mean_squared_error: 0.9118\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4661 - mean_squared_error: 0.8309\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0929 - mean_squared_error: 0.7592\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7381 - mean_squared_error: 0.6954\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4041 - mean_squared_error: 0.6417\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0857 - mean_squared_error: 0.5930\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7825 - mean_squared_error: 0.5490\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.4981 - mean_squared_error: 0.5134\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2269 - mean_squared_error: 0.4807\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9696 - mean_squared_error: 0.4523\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7267 - mean_squared_error: 0.4285\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.4962 - mean_squared_error: 0.4078\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.2785 - mean_squared_error: 0.3909\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0716 - mean_squared_error: 0.3761\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8756 - mean_squared_error: 0.3639\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6892 - mean_squared_error: 0.3531\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5125 - mean_squared_error: 0.3441\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3445 - mean_squared_error: 0.3362\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1849 - mean_squared_error: 0.3292\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0335 - mean_squared_error: 0.3233\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8894 - mean_squared_error: 0.3176\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7521 - mean_squared_error: 0.3122\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6221 - mean_squared_error: 0.3078\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4987 - mean_squared_error: 0.3038\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3811 - mean_squared_error: 0.2999\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2696 - mean_squared_error: 0.2967\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1639 - mean_squared_error: 0.2938\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0637 - mean_squared_error: 0.2913\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9687 - mean_squared_error: 0.2889\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8784 - mean_squared_error: 0.2866\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7928 - mean_squared_error: 0.2845\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7116 - mean_squared_error: 0.2824\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6348 - mean_squared_error: 0.2804\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5621 - mean_squared_error: 0.2787\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4932 - mean_squared_error: 0.2772\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4280 - mean_squared_error: 0.2758\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3662 - mean_squared_error: 0.2744\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3077 - mean_squared_error: 0.2730\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2523 - mean_squared_error: 0.2716\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1999 - mean_squared_error: 0.2704\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1503 - mean_squared_error: 0.2693\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1034 - mean_squared_error: 0.2683\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0591 - mean_squared_error: 0.2672\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0172 - mean_squared_error: 0.2663\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9776 - mean_squared_error: 0.2653\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9402 - mean_squared_error: 0.2645\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9047 - mean_squared_error: 0.2639\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8712 - mean_squared_error: 0.2634\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8398 - mean_squared_error: 0.2633\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8100 - mean_squared_error: 0.2629\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7818 - mean_squared_error: 0.2625\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7551 - mean_squared_error: 0.2618\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7300 - mean_squared_error: 0.2613\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7062 - mean_squared_error: 0.2609\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6837 - mean_squared_error: 0.2606\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6626 - mean_squared_error: 0.2604\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6428 - mean_squared_error: 0.2603\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6239 - mean_squared_error: 0.2600\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6061 - mean_squared_error: 0.2595\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5894 - mean_squared_error: 0.2592\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5737 - mean_squared_error: 0.2591\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5586 - mean_squared_error: 0.2588\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5446 - mean_squared_error: 0.2587\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5315 - mean_squared_error: 0.2586\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5189 - mean_squared_error: 0.2583\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5072 - mean_squared_error: 0.2581\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4960 - mean_squared_error: 0.2578\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4855 - mean_squared_error: 0.2575\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4757 - mean_squared_error: 0.2575\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4663 - mean_squared_error: 0.2572\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4573 - mean_squared_error: 0.2569\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4493 - mean_squared_error: 0.2569\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4416 - mean_squared_error: 0.2569\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4342 - mean_squared_error: 0.2568\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4271 - mean_squared_error: 0.2565\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4205 - mean_squared_error: 0.2563\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4146 - mean_squared_error: 0.2563\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4086 - mean_squared_error: 0.2560\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4032 - mean_squared_error: 0.2562\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3982 - mean_squared_error: 0.2563\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3932 - mean_squared_error: 0.2562\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3885 - mean_squared_error: 0.2560\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3838 - mean_squared_error: 0.2556\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3802 - mean_squared_error: 0.2560\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3760 - mean_squared_error: 0.2557\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3723 - mean_squared_error: 0.2558\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3688 - mean_squared_error: 0.2558\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3654 - mean_squared_error: 0.2556\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3623 - mean_squared_error: 0.2554\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3595 - mean_squared_error: 0.2554\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3566 - mean_squared_error: 0.2553\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3540 - mean_squared_error: 0.2552\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3514 - mean_squared_error: 0.2549\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3489 - mean_squared_error: 0.2549\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3466 - mean_squared_error: 0.2549\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff65c18dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3921 - mean_squared_error: 0.3023\n",
            "Training MSE: 0.3022514879703522\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.9446 - mean_squared_error: 1.4265\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.3587 - mean_squared_error: 1.2032\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.8254 - mean_squared_error: 1.0239\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3431 - mean_squared_error: 0.8874\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9035 - mean_squared_error: 0.7855\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4995 - mean_squared_error: 0.7111\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1229 - mean_squared_error: 0.6561\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7660 - mean_squared_error: 0.6126\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4252 - mean_squared_error: 0.5767\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0983 - mean_squared_error: 0.5459\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7834 - mean_squared_error: 0.5182\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.4820 - mean_squared_error: 0.4946\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1915 - mean_squared_error: 0.4727\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9132 - mean_squared_error: 0.4537\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6465 - mean_squared_error: 0.4369\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.3913 - mean_squared_error: 0.4222\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.1469 - mean_squared_error: 0.4092\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9137 - mean_squared_error: 0.3982\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6900 - mean_squared_error: 0.3879\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4766 - mean_squared_error: 0.3791\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.2731 - mean_squared_error: 0.3717\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0778 - mean_squared_error: 0.3642\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8915 - mean_squared_error: 0.3576\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7130 - mean_squared_error: 0.3513\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5422 - mean_squared_error: 0.3450\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.3793 - mean_squared_error: 0.3394\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.2238 - mean_squared_error: 0.3341\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.0755 - mean_squared_error: 0.3292\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.9344 - mean_squared_error: 0.3249\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7998 - mean_squared_error: 0.3210\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6717 - mean_squared_error: 0.3175\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.5496 - mean_squared_error: 0.3143\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4335 - mean_squared_error: 0.3113\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.3226 - mean_squared_error: 0.3083\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2173 - mean_squared_error: 0.3057\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.1168 - mean_squared_error: 0.3028\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0215 - mean_squared_error: 0.3003\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9308 - mean_squared_error: 0.2978\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8444 - mean_squared_error: 0.2954\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7623 - mean_squared_error: 0.2931\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6844 - mean_squared_error: 0.2909\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6102 - mean_squared_error: 0.2888\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.5399 - mean_squared_error: 0.2869\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4730 - mean_squared_error: 0.2851\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4096 - mean_squared_error: 0.2835\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3494 - mean_squared_error: 0.2819\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2923 - mean_squared_error: 0.2804\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.2381 - mean_squared_error: 0.2791\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1867 - mean_squared_error: 0.2779\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1379 - mean_squared_error: 0.2768\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0919 - mean_squared_error: 0.2760\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0480 - mean_squared_error: 0.2752\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0065 - mean_squared_error: 0.2744\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9673 - mean_squared_error: 0.2738\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9301 - mean_squared_error: 0.2732\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8949 - mean_squared_error: 0.2726\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8615 - mean_squared_error: 0.2717\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8299 - mean_squared_error: 0.2708\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8000 - mean_squared_error: 0.2701\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7718 - mean_squared_error: 0.2695\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7450 - mean_squared_error: 0.2687\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7197 - mean_squared_error: 0.2681\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6958 - mean_squared_error: 0.2674\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6733 - mean_squared_error: 0.2670\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6518 - mean_squared_error: 0.2666\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6317 - mean_squared_error: 0.2662\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6126 - mean_squared_error: 0.2659\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5947 - mean_squared_error: 0.2656\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5777 - mean_squared_error: 0.2652\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5615 - mean_squared_error: 0.2647\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5464 - mean_squared_error: 0.2644\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5321 - mean_squared_error: 0.2642\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5186 - mean_squared_error: 0.2640\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5058 - mean_squared_error: 0.2636\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4938 - mean_squared_error: 0.2633\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4825 - mean_squared_error: 0.2629\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4718 - mean_squared_error: 0.2626\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4617 - mean_squared_error: 0.2623\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4522 - mean_squared_error: 0.2621\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4433 - mean_squared_error: 0.2620\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4348 - mean_squared_error: 0.2617\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4270 - mean_squared_error: 0.2615\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4195 - mean_squared_error: 0.2611\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4124 - mean_squared_error: 0.2607\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4058 - mean_squared_error: 0.2603\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3995 - mean_squared_error: 0.2599\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3936 - mean_squared_error: 0.2597\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3882 - mean_squared_error: 0.2598\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3831 - mean_squared_error: 0.2599\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3782 - mean_squared_error: 0.2598\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3734 - mean_squared_error: 0.2595\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3690 - mean_squared_error: 0.2594\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3648 - mean_squared_error: 0.2591\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3609 - mean_squared_error: 0.2589\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3572 - mean_squared_error: 0.2587\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3537 - mean_squared_error: 0.2585\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3504 - mean_squared_error: 0.2583\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3472 - mean_squared_error: 0.2581\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3444 - mean_squared_error: 0.2581\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3415 - mean_squared_error: 0.2579\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5f55b2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3848 - mean_squared_error: 0.3032\n",
            "Training MSE: 0.3032364547252655\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.7433 - mean_squared_error: 1.3711\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2243 - mean_squared_error: 1.2320\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7362 - mean_squared_error: 1.1154\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2770 - mean_squared_error: 1.0188\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.8351 - mean_squared_error: 0.9302\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4183 - mean_squared_error: 0.8569\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0186 - mean_squared_error: 0.7900\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6369 - mean_squared_error: 0.7305\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2737 - mean_squared_error: 0.6784\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9256 - mean_squared_error: 0.6306\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.5934 - mean_squared_error: 0.5878\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2775 - mean_squared_error: 0.5505\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9768 - mean_squared_error: 0.5175\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.6887 - mean_squared_error: 0.4867\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.4157 - mean_squared_error: 0.4609\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.1558 - mean_squared_error: 0.4380\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9089 - mean_squared_error: 0.4183\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.6747 - mean_squared_error: 0.4016\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.4511 - mean_squared_error: 0.3863\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.2390 - mean_squared_error: 0.3736\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.0373 - mean_squared_error: 0.3628\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.8458 - mean_squared_error: 0.3538\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.6627 - mean_squared_error: 0.3453\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.4892 - mean_squared_error: 0.3385\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.3239 - mean_squared_error: 0.3325\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1669 - mean_squared_error: 0.3278\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0175 - mean_squared_error: 0.3236\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8756 - mean_squared_error: 0.3201\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7403 - mean_squared_error: 0.3166\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6119 - mean_squared_error: 0.3135\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4895 - mean_squared_error: 0.3105\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3734 - mean_squared_error: 0.3080\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2630 - mean_squared_error: 0.3057\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1582 - mean_squared_error: 0.3037\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0582 - mean_squared_error: 0.3016\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9635 - mean_squared_error: 0.2997\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.8738 - mean_squared_error: 0.2981\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7883 - mean_squared_error: 0.2962\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7072 - mean_squared_error: 0.2943\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6305 - mean_squared_error: 0.2927\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5578 - mean_squared_error: 0.2912\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4887 - mean_squared_error: 0.2898\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4232 - mean_squared_error: 0.2887\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3609 - mean_squared_error: 0.2875\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3021 - mean_squared_error: 0.2864\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2465 - mean_squared_error: 0.2853\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1937 - mean_squared_error: 0.2841\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1438 - mean_squared_error: 0.2832\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0963 - mean_squared_error: 0.2820\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0516 - mean_squared_error: 0.2812\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0093 - mean_squared_error: 0.2804\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9692 - mean_squared_error: 0.2795\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9314 - mean_squared_error: 0.2787\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8955 - mean_squared_error: 0.2778\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8615 - mean_squared_error: 0.2770\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8294 - mean_squared_error: 0.2763\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7994 - mean_squared_error: 0.2759\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7705 - mean_squared_error: 0.2750\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7435 - mean_squared_error: 0.2741\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7184 - mean_squared_error: 0.2735\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6945 - mean_squared_error: 0.2729\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6715 - mean_squared_error: 0.2722\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6502 - mean_squared_error: 0.2720\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6301 - mean_squared_error: 0.2716\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6107 - mean_squared_error: 0.2704\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5925 - mean_squared_error: 0.2693\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5760 - mean_squared_error: 0.2691\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5601 - mean_squared_error: 0.2687\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5447 - mean_squared_error: 0.2681\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5303 - mean_squared_error: 0.2675\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5171 - mean_squared_error: 0.2674\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5045 - mean_squared_error: 0.2670\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4923 - mean_squared_error: 0.2663\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4810 - mean_squared_error: 0.2657\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4706 - mean_squared_error: 0.2656\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4606 - mean_squared_error: 0.2652\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4512 - mean_squared_error: 0.2649\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4424 - mean_squared_error: 0.2648\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4343 - mean_squared_error: 0.2648\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4266 - mean_squared_error: 0.2647\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4190 - mean_squared_error: 0.2641\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4122 - mean_squared_error: 0.2640\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4058 - mean_squared_error: 0.2639\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3995 - mean_squared_error: 0.2633\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3937 - mean_squared_error: 0.2628\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3884 - mean_squared_error: 0.2626\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3831 - mean_squared_error: 0.2623\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3783 - mean_squared_error: 0.2625\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3739 - mean_squared_error: 0.2625\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3695 - mean_squared_error: 0.2619\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3654 - mean_squared_error: 0.2615\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3617 - mean_squared_error: 0.2612\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3583 - mean_squared_error: 0.2611\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3548 - mean_squared_error: 0.2607\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3517 - mean_squared_error: 0.2606\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3485 - mean_squared_error: 0.2601\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3460 - mean_squared_error: 0.2601\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3431 - mean_squared_error: 0.2596\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3404 - mean_squared_error: 0.2594\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3385 - mean_squared_error: 0.2600\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff65c2cfe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3876 - mean_squared_error: 0.3110\n",
            "Training MSE: 0.31099048256874084\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.6940 - mean_squared_error: 2.1945\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0435 - mean_squared_error: 1.9077\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4348 - mean_squared_error: 1.6527\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8804 - mean_squared_error: 1.4423\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3660 - mean_squared_error: 1.2621\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8933 - mean_squared_error: 1.1142\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4539 - mean_squared_error: 0.9904\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0499 - mean_squared_error: 0.8928\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6719 - mean_squared_error: 0.8121\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3127 - mean_squared_error: 0.7413\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9753 - mean_squared_error: 0.6833\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6556 - mean_squared_error: 0.6339\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3534 - mean_squared_error: 0.5928\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.0634 - mean_squared_error: 0.5549\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.7883 - mean_squared_error: 0.5229\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5248 - mean_squared_error: 0.4936\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2743 - mean_squared_error: 0.4687\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0360 - mean_squared_error: 0.4473\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8081 - mean_squared_error: 0.4279\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.5914 - mean_squared_error: 0.4112\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.3845 - mean_squared_error: 0.3963\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1873 - mean_squared_error: 0.3831\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9998 - mean_squared_error: 0.3721\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.8210 - mean_squared_error: 0.3622\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6510 - mean_squared_error: 0.3539\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4889 - mean_squared_error: 0.3464\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.3347 - mean_squared_error: 0.3402\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.1879 - mean_squared_error: 0.3347\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.0473 - mean_squared_error: 0.3293\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.9134 - mean_squared_error: 0.3246\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.7856 - mean_squared_error: 0.3204\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.6638 - mean_squared_error: 0.3166\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5477 - mean_squared_error: 0.3131\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4372 - mean_squared_error: 0.3102\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3319 - mean_squared_error: 0.3074\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2315 - mean_squared_error: 0.3047\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1361 - mean_squared_error: 0.3024\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0451 - mean_squared_error: 0.3002\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.9585 - mean_squared_error: 0.2981\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8760 - mean_squared_error: 0.2962\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7976 - mean_squared_error: 0.2946\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7231 - mean_squared_error: 0.2931\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.6521 - mean_squared_error: 0.2917\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.5845 - mean_squared_error: 0.2902\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.5205 - mean_squared_error: 0.2890\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4593 - mean_squared_error: 0.2876\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4014 - mean_squared_error: 0.2863\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3462 - mean_squared_error: 0.2850\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2938 - mean_squared_error: 0.2838\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2441 - mean_squared_error: 0.2826\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1969 - mean_squared_error: 0.2816\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1520 - mean_squared_error: 0.2806\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1094 - mean_squared_error: 0.2799\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0689 - mean_squared_error: 0.2791\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0305 - mean_squared_error: 0.2784\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9940 - mean_squared_error: 0.2776\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9594 - mean_squared_error: 0.2770\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9266 - mean_squared_error: 0.2763\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8955 - mean_squared_error: 0.2757\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8659 - mean_squared_error: 0.2750\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8378 - mean_squared_error: 0.2742\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8112 - mean_squared_error: 0.2737\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7860 - mean_squared_error: 0.2731\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7622 - mean_squared_error: 0.2725\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7395 - mean_squared_error: 0.2721\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7179 - mean_squared_error: 0.2715\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6976 - mean_squared_error: 0.2711\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6782 - mean_squared_error: 0.2707\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6600 - mean_squared_error: 0.2705\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6426 - mean_squared_error: 0.2702\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6261 - mean_squared_error: 0.2700\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6106 - mean_squared_error: 0.2698\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5957 - mean_squared_error: 0.2695\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5816 - mean_squared_error: 0.2691\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5684 - mean_squared_error: 0.2689\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5558 - mean_squared_error: 0.2685\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5440 - mean_squared_error: 0.2683\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5326 - mean_squared_error: 0.2680\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5218 - mean_squared_error: 0.2677\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5116 - mean_squared_error: 0.2676\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5020 - mean_squared_error: 0.2676\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4930 - mean_squared_error: 0.2676\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4843 - mean_squared_error: 0.2674\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4760 - mean_squared_error: 0.2670\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4681 - mean_squared_error: 0.2666\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4608 - mean_squared_error: 0.2663\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4537 - mean_squared_error: 0.2660\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4471 - mean_squared_error: 0.2659\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4408 - mean_squared_error: 0.2657\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4349 - mean_squared_error: 0.2657\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4291 - mean_squared_error: 0.2656\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4235 - mean_squared_error: 0.2657\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4184 - mean_squared_error: 0.2657\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4136 - mean_squared_error: 0.2659\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4090 - mean_squared_error: 0.2660\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4046 - mean_squared_error: 0.2659\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4003 - mean_squared_error: 0.2657\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3963 - mean_squared_error: 0.2655\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3925 - mean_squared_error: 0.2654\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3888 - mean_squared_error: 0.2653\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5faa4fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4248 - mean_squared_error: 0.3041\n",
            "Training MSE: 0.3040793836116791\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9615 - mean_squared_error: 1.5958\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3772 - mean_squared_error: 1.3755\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.8392 - mean_squared_error: 1.1923\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3543 - mean_squared_error: 1.0539\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9094 - mean_squared_error: 0.9472\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4977 - mean_squared_error: 0.8661\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1148 - mean_squared_error: 0.8059\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7475 - mean_squared_error: 0.7534\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3942 - mean_squared_error: 0.7061\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0530 - mean_squared_error: 0.6614\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7253 - mean_squared_error: 0.6206\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4082 - mean_squared_error: 0.5803\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1040 - mean_squared_error: 0.5430\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8154 - mean_squared_error: 0.5114\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.5404 - mean_squared_error: 0.4837\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.2803 - mean_squared_error: 0.4612\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0320 - mean_squared_error: 0.4411\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.7958 - mean_squared_error: 0.4241\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5702 - mean_squared_error: 0.4086\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.3552 - mean_squared_error: 0.3949\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1492 - mean_squared_error: 0.3815\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.9528 - mean_squared_error: 0.3695\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7660 - mean_squared_error: 0.3592\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5877 - mean_squared_error: 0.3497\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4185 - mean_squared_error: 0.3420\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2568 - mean_squared_error: 0.3347\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1032 - mean_squared_error: 0.3285\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.9568 - mean_squared_error: 0.3229\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8176 - mean_squared_error: 0.3180\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.6848 - mean_squared_error: 0.3133\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5586 - mean_squared_error: 0.3091\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4388 - mean_squared_error: 0.3056\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3248 - mean_squared_error: 0.3021\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2163 - mean_squared_error: 0.2988\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1137 - mean_squared_error: 0.2962\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0159 - mean_squared_error: 0.2934\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9232 - mean_squared_error: 0.2910\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8354 - mean_squared_error: 0.2889\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7516 - mean_squared_error: 0.2867\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.6723 - mean_squared_error: 0.2849\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5972 - mean_squared_error: 0.2832\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5258 - mean_squared_error: 0.2814\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4584 - mean_squared_error: 0.2800\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3943 - mean_squared_error: 0.2784\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3336 - mean_squared_error: 0.2770\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2762 - mean_squared_error: 0.2757\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2218 - mean_squared_error: 0.2745\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1703 - mean_squared_error: 0.2733\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1215 - mean_squared_error: 0.2722\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0754 - mean_squared_error: 0.2713\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0316 - mean_squared_error: 0.2702\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9903 - mean_squared_error: 0.2693\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9513 - mean_squared_error: 0.2684\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9144 - mean_squared_error: 0.2676\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8796 - mean_squared_error: 0.2671\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8466 - mean_squared_error: 0.2665\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8154 - mean_squared_error: 0.2661\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7859 - mean_squared_error: 0.2655\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7581 - mean_squared_error: 0.2652\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7319 - mean_squared_error: 0.2648\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7073 - mean_squared_error: 0.2648\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6840 - mean_squared_error: 0.2647\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6618 - mean_squared_error: 0.2644\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6410 - mean_squared_error: 0.2641\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6213 - mean_squared_error: 0.2635\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6026 - mean_squared_error: 0.2629\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5852 - mean_squared_error: 0.2625\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5688 - mean_squared_error: 0.2623\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5533 - mean_squared_error: 0.2621\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5386 - mean_squared_error: 0.2619\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5248 - mean_squared_error: 0.2616\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5118 - mean_squared_error: 0.2614\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4996 - mean_squared_error: 0.2613\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4881 - mean_squared_error: 0.2611\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4771 - mean_squared_error: 0.2607\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4670 - mean_squared_error: 0.2605\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4575 - mean_squared_error: 0.2603\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4485 - mean_squared_error: 0.2602\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4400 - mean_squared_error: 0.2600\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4319 - mean_squared_error: 0.2598\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4242 - mean_squared_error: 0.2596\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4172 - mean_squared_error: 0.2594\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4105 - mean_squared_error: 0.2594\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4042 - mean_squared_error: 0.2593\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3982 - mean_squared_error: 0.2592\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3926 - mean_squared_error: 0.2593\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3874 - mean_squared_error: 0.2593\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3825 - mean_squared_error: 0.2594\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3778 - mean_squared_error: 0.2592\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3734 - mean_squared_error: 0.2591\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3695 - mean_squared_error: 0.2592\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3654 - mean_squared_error: 0.2589\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3618 - mean_squared_error: 0.2586\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3583 - mean_squared_error: 0.2584\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3552 - mean_squared_error: 0.2584\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3521 - mean_squared_error: 0.2583\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3492 - mean_squared_error: 0.2583\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3465 - mean_squared_error: 0.2581\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3438 - mean_squared_error: 0.2578\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3413 - mean_squared_error: 0.2578\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fa17a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3821 - mean_squared_error: 0.3004\n",
            "Training MSE: 0.30044642090797424\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.8730 - mean_squared_error: 0.8997\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4119 - mean_squared_error: 0.8217\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9716 - mean_squared_error: 0.7523\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5522 - mean_squared_error: 0.6924\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1505 - mean_squared_error: 0.6386\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7688 - mean_squared_error: 0.5932\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4038 - mean_squared_error: 0.5529\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0534 - mean_squared_error: 0.5157\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7203 - mean_squared_error: 0.4847\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4014 - mean_squared_error: 0.4567\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0986 - mean_squared_error: 0.4337\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.8093 - mean_squared_error: 0.4134\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.5340 - mean_squared_error: 0.3967\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2718 - mean_squared_error: 0.3825\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0212 - mean_squared_error: 0.3701\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7822 - mean_squared_error: 0.3597\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.5543 - mean_squared_error: 0.3509\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.3367 - mean_squared_error: 0.3434\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.1296 - mean_squared_error: 0.3373\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9315 - mean_squared_error: 0.3317\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7429 - mean_squared_error: 0.3273\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5630 - mean_squared_error: 0.3233\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.3916 - mean_squared_error: 0.3198\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2283 - mean_squared_error: 0.3166\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0732 - mean_squared_error: 0.3140\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.9253 - mean_squared_error: 0.3114\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.7847 - mean_squared_error: 0.3090\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.6509 - mean_squared_error: 0.3066\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5237 - mean_squared_error: 0.3044\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.4030 - mean_squared_error: 0.3026\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2882 - mean_squared_error: 0.3007\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1794 - mean_squared_error: 0.2992\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0759 - mean_squared_error: 0.2976\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9777 - mean_squared_error: 0.2958\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.8845 - mean_squared_error: 0.2941\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7961 - mean_squared_error: 0.2924\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7124 - mean_squared_error: 0.2910\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6330 - mean_squared_error: 0.2895\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.5577 - mean_squared_error: 0.2883\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4864 - mean_squared_error: 0.2871\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4188 - mean_squared_error: 0.2859\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3548 - mean_squared_error: 0.2845\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2942 - mean_squared_error: 0.2831\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2369 - mean_squared_error: 0.2817\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1829 - mean_squared_error: 0.2806\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1317 - mean_squared_error: 0.2795\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0830 - mean_squared_error: 0.2785\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0370 - mean_squared_error: 0.2777\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9938 - mean_squared_error: 0.2771\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9528 - mean_squared_error: 0.2762\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9142 - mean_squared_error: 0.2753\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8777 - mean_squared_error: 0.2744\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8431 - mean_squared_error: 0.2735\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8106 - mean_squared_error: 0.2730\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7800 - mean_squared_error: 0.2726\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7512 - mean_squared_error: 0.2724\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7238 - mean_squared_error: 0.2718\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6981 - mean_squared_error: 0.2714\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6739 - mean_squared_error: 0.2709\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6513 - mean_squared_error: 0.2706\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6299 - mean_squared_error: 0.2702\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6095 - mean_squared_error: 0.2696\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5904 - mean_squared_error: 0.2691\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5726 - mean_squared_error: 0.2687\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5556 - mean_squared_error: 0.2680\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5397 - mean_squared_error: 0.2675\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5249 - mean_squared_error: 0.2672\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5111 - mean_squared_error: 0.2668\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4980 - mean_squared_error: 0.2665\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4853 - mean_squared_error: 0.2660\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4739 - mean_squared_error: 0.2661\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4630 - mean_squared_error: 0.2660\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4527 - mean_squared_error: 0.2656\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4432 - mean_squared_error: 0.2652\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4344 - mean_squared_error: 0.2653\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4257 - mean_squared_error: 0.2648\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4175 - mean_squared_error: 0.2643\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4103 - mean_squared_error: 0.2644\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4035 - mean_squared_error: 0.2644\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3969 - mean_squared_error: 0.2643\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3907 - mean_squared_error: 0.2640\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3850 - mean_squared_error: 0.2640\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3796 - mean_squared_error: 0.2638\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3742 - mean_squared_error: 0.2632\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3695 - mean_squared_error: 0.2628\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3650 - mean_squared_error: 0.2623\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3610 - mean_squared_error: 0.2620\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3572 - mean_squared_error: 0.2616\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3533 - mean_squared_error: 0.2610\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3501 - mean_squared_error: 0.2611\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3473 - mean_squared_error: 0.2613\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3441 - mean_squared_error: 0.2609\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3412 - mean_squared_error: 0.2606\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3387 - mean_squared_error: 0.2606\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3358 - mean_squared_error: 0.2604\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3340 - mean_squared_error: 0.2612\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3314 - mean_squared_error: 0.2610\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3294 - mean_squared_error: 0.2610\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3277 - mean_squared_error: 0.2610\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3258 - mean_squared_error: 0.2606\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff65c100048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3669 - mean_squared_error: 0.3030\n",
            "Training MSE: 0.3029610514640808\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.8514 - mean_squared_error: 1.1806\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3348 - mean_squared_error: 1.0431\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8530 - mean_squared_error: 0.9364\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3968 - mean_squared_error: 0.8490\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9635 - mean_squared_error: 0.7763\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5510 - mean_squared_error: 0.7148\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1564 - mean_squared_error: 0.6609\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7787 - mean_squared_error: 0.6132\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4159 - mean_squared_error: 0.5698\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0710 - mean_squared_error: 0.5334\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7403 - mean_squared_error: 0.5002\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.4257 - mean_squared_error: 0.4724\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1258 - mean_squared_error: 0.4486\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.8400 - mean_squared_error: 0.4283\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5679 - mean_squared_error: 0.4114\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3080 - mean_squared_error: 0.3967\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.0603 - mean_squared_error: 0.3844\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.8231 - mean_squared_error: 0.3730\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.5967 - mean_squared_error: 0.3632\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.3806 - mean_squared_error: 0.3547\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1747 - mean_squared_error: 0.3475\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.9782 - mean_squared_error: 0.3412\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7909 - mean_squared_error: 0.3358\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6119 - mean_squared_error: 0.3308\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.4414 - mean_squared_error: 0.3264\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2788 - mean_squared_error: 0.3224\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1238 - mean_squared_error: 0.3187\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9763 - mean_squared_error: 0.3154\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8359 - mean_squared_error: 0.3125\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7024 - mean_squared_error: 0.3099\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5754 - mean_squared_error: 0.3075\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4545 - mean_squared_error: 0.3052\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3396 - mean_squared_error: 0.3029\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2305 - mean_squared_error: 0.3007\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1269 - mean_squared_error: 0.2985\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0283 - mean_squared_error: 0.2964\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9349 - mean_squared_error: 0.2946\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8462 - mean_squared_error: 0.2927\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7620 - mean_squared_error: 0.2909\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6823 - mean_squared_error: 0.2893\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6064 - mean_squared_error: 0.2876\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5346 - mean_squared_error: 0.2863\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.4665 - mean_squared_error: 0.2850\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4019 - mean_squared_error: 0.2835\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3405 - mean_squared_error: 0.2820\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2825 - mean_squared_error: 0.2806\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2276 - mean_squared_error: 0.2794\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1755 - mean_squared_error: 0.2782\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1263 - mean_squared_error: 0.2773\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0795 - mean_squared_error: 0.2763\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0354 - mean_squared_error: 0.2755\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9936 - mean_squared_error: 0.2746\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9541 - mean_squared_error: 0.2736\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9167 - mean_squared_error: 0.2728\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8814 - mean_squared_error: 0.2720\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8478 - mean_squared_error: 0.2710\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8163 - mean_squared_error: 0.2702\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7866 - mean_squared_error: 0.2696\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7585 - mean_squared_error: 0.2689\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7318 - mean_squared_error: 0.2682\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7067 - mean_squared_error: 0.2677\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6829 - mean_squared_error: 0.2673\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6604 - mean_squared_error: 0.2670\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6392 - mean_squared_error: 0.2669\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6194 - mean_squared_error: 0.2669\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6008 - mean_squared_error: 0.2668\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5827 - mean_squared_error: 0.2659\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5662 - mean_squared_error: 0.2655\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5505 - mean_squared_error: 0.2650\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5355 - mean_squared_error: 0.2645\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5216 - mean_squared_error: 0.2643\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5083 - mean_squared_error: 0.2639\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4958 - mean_squared_error: 0.2635\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4844 - mean_squared_error: 0.2634\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4737 - mean_squared_error: 0.2634\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4632 - mean_squared_error: 0.2632\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4531 - mean_squared_error: 0.2627\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4440 - mean_squared_error: 0.2625\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4353 - mean_squared_error: 0.2620\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4271 - mean_squared_error: 0.2618\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4196 - mean_squared_error: 0.2616\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4125 - mean_squared_error: 0.2614\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4057 - mean_squared_error: 0.2615\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3991 - mean_squared_error: 0.2613\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3931 - mean_squared_error: 0.2611\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3878 - mean_squared_error: 0.2611\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3825 - mean_squared_error: 0.2607\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3774 - mean_squared_error: 0.2603\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3726 - mean_squared_error: 0.2600\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3683 - mean_squared_error: 0.2599\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3642 - mean_squared_error: 0.2597\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3603 - mean_squared_error: 0.2595\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3566 - mean_squared_error: 0.2592\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3531 - mean_squared_error: 0.2589\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3499 - mean_squared_error: 0.2587\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3467 - mean_squared_error: 0.2584\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3441 - mean_squared_error: 0.2586\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3418 - mean_squared_error: 0.2592\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3392 - mean_squared_error: 0.2592\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3365 - mean_squared_error: 0.2587\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fa0818c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3813 - mean_squared_error: 0.3052\n",
            "Training MSE: 0.30520033836364746\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.4676 - mean_squared_error: 0.9793\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0045 - mean_squared_error: 0.9242\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5582 - mean_squared_error: 0.8731\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.1290 - mean_squared_error: 0.8261\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7142 - mean_squared_error: 0.7812\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3172 - mean_squared_error: 0.7414\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9347 - mean_squared_error: 0.7034\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5696 - mean_squared_error: 0.6706\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2176 - mean_squared_error: 0.6388\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8815 - mean_squared_error: 0.6111\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5593 - mean_squared_error: 0.5859\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2510 - mean_squared_error: 0.5630\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9562 - mean_squared_error: 0.5424\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6739 - mean_squared_error: 0.5235\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4047 - mean_squared_error: 0.5067\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1469 - mean_squared_error: 0.4910\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9017 - mean_squared_error: 0.4774\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6671 - mean_squared_error: 0.4645\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4432 - mean_squared_error: 0.4527\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.2297 - mean_squared_error: 0.4422\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0262 - mean_squared_error: 0.4325\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.8326 - mean_squared_error: 0.4240\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6476 - mean_squared_error: 0.4154\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4717 - mean_squared_error: 0.4075\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3042 - mean_squared_error: 0.4000\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1447 - mean_squared_error: 0.3927\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9931 - mean_squared_error: 0.3863\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8491 - mean_squared_error: 0.3802\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.7118 - mean_squared_error: 0.3741\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.5814 - mean_squared_error: 0.3684\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.4576 - mean_squared_error: 0.3632\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.3402 - mean_squared_error: 0.3583\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2284 - mean_squared_error: 0.3535\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1226 - mean_squared_error: 0.3492\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0220 - mean_squared_error: 0.3449\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.9267 - mean_squared_error: 0.3408\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.8360 - mean_squared_error: 0.3368\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7502 - mean_squared_error: 0.3335\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6688 - mean_squared_error: 0.3301\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5917 - mean_squared_error: 0.3265\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5188 - mean_squared_error: 0.3231\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4495 - mean_squared_error: 0.3197\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3841 - mean_squared_error: 0.3168\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3219 - mean_squared_error: 0.3141\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2632 - mean_squared_error: 0.3115\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2079 - mean_squared_error: 0.3090\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1551 - mean_squared_error: 0.3062\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1054 - mean_squared_error: 0.3038\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0585 - mean_squared_error: 0.3016\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0143 - mean_squared_error: 0.2995\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9723 - mean_squared_error: 0.2975\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9327 - mean_squared_error: 0.2957\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8953 - mean_squared_error: 0.2938\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8603 - mean_squared_error: 0.2922\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8270 - mean_squared_error: 0.2905\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7954 - mean_squared_error: 0.2891\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7659 - mean_squared_error: 0.2879\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7381 - mean_squared_error: 0.2868\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7120 - mean_squared_error: 0.2858\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6873 - mean_squared_error: 0.2846\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6641 - mean_squared_error: 0.2835\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6422 - mean_squared_error: 0.2824\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6213 - mean_squared_error: 0.2812\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6020 - mean_squared_error: 0.2805\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5837 - mean_squared_error: 0.2795\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5666 - mean_squared_error: 0.2785\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5504 - mean_squared_error: 0.2774\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5353 - mean_squared_error: 0.2765\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5210 - mean_squared_error: 0.2757\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5076 - mean_squared_error: 0.2750\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4952 - mean_squared_error: 0.2746\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4836 - mean_squared_error: 0.2742\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4723 - mean_squared_error: 0.2732\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4619 - mean_squared_error: 0.2726\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4521 - mean_squared_error: 0.2720\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4431 - mean_squared_error: 0.2716\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4346 - mean_squared_error: 0.2712\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4265 - mean_squared_error: 0.2708\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4188 - mean_squared_error: 0.2701\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4118 - mean_squared_error: 0.2695\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4051 - mean_squared_error: 0.2689\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3990 - mean_squared_error: 0.2687\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3932 - mean_squared_error: 0.2684\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3877 - mean_squared_error: 0.2680\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3825 - mean_squared_error: 0.2674\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3777 - mean_squared_error: 0.2672\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3733 - mean_squared_error: 0.2669\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3691 - mean_squared_error: 0.2665\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3654 - mean_squared_error: 0.2661\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3616 - mean_squared_error: 0.2655\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3579 - mean_squared_error: 0.2652\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3548 - mean_squared_error: 0.2653\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3520 - mean_squared_error: 0.2656\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3491 - mean_squared_error: 0.2653\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3465 - mean_squared_error: 0.2650\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3440 - mean_squared_error: 0.2646\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3413 - mean_squared_error: 0.2642\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3393 - mean_squared_error: 0.2645\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3374 - mean_squared_error: 0.2645\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3353 - mean_squared_error: 0.2641\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fa049950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3784 - mean_squared_error: 0.3086\n",
            "Training MSE: 0.30857735872268677\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5870 - mean_squared_error: 1.1286\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1049 - mean_squared_error: 1.0436\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6462 - mean_squared_error: 0.9715\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2039 - mean_squared_error: 0.9054\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7804 - mean_squared_error: 0.8472\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3738 - mean_squared_error: 0.7946\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9827 - mean_squared_error: 0.7459\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6066 - mean_squared_error: 0.7003\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2477 - mean_squared_error: 0.6602\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9039 - mean_squared_error: 0.6232\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.5751 - mean_squared_error: 0.5896\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2625 - mean_squared_error: 0.5604\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9629 - mean_squared_error: 0.5329\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6785 - mean_squared_error: 0.5091\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4072 - mean_squared_error: 0.4876\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1481 - mean_squared_error: 0.4676\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.9025 - mean_squared_error: 0.4507\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6686 - mean_squared_error: 0.4357\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4452 - mean_squared_error: 0.4217\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.2332 - mean_squared_error: 0.4100\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0315 - mean_squared_error: 0.3997\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.8394 - mean_squared_error: 0.3904\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6566 - mean_squared_error: 0.3822\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4829 - mean_squared_error: 0.3752\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.3173 - mean_squared_error: 0.3687\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1599 - mean_squared_error: 0.3630\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.0103 - mean_squared_error: 0.3581\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8680 - mean_squared_error: 0.3536\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7322 - mean_squared_error: 0.3491\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.6035 - mean_squared_error: 0.3454\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4813 - mean_squared_error: 0.3421\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3648 - mean_squared_error: 0.3387\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2543 - mean_squared_error: 0.3358\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1493 - mean_squared_error: 0.3329\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0497 - mean_squared_error: 0.3303\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9549 - mean_squared_error: 0.3276\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8653 - mean_squared_error: 0.3253\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7800 - mean_squared_error: 0.3231\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6992 - mean_squared_error: 0.3209\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6225 - mean_squared_error: 0.3189\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5499 - mean_squared_error: 0.3170\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4810 - mean_squared_error: 0.3150\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4158 - mean_squared_error: 0.3130\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3538 - mean_squared_error: 0.3110\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2953 - mean_squared_error: 0.3091\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2398 - mean_squared_error: 0.3071\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1873 - mean_squared_error: 0.3052\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1376 - mean_squared_error: 0.3035\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0904 - mean_squared_error: 0.3017\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0461 - mean_squared_error: 0.3004\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0040 - mean_squared_error: 0.2992\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9642 - mean_squared_error: 0.2977\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9266 - mean_squared_error: 0.2961\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8912 - mean_squared_error: 0.2947\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8577 - mean_squared_error: 0.2933\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8261 - mean_squared_error: 0.2920\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7960 - mean_squared_error: 0.2907\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7679 - mean_squared_error: 0.2899\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7413 - mean_squared_error: 0.2890\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7161 - mean_squared_error: 0.2880\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6925 - mean_squared_error: 0.2870\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6700 - mean_squared_error: 0.2859\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6491 - mean_squared_error: 0.2850\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6292 - mean_squared_error: 0.2840\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6105 - mean_squared_error: 0.2834\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5928 - mean_squared_error: 0.2828\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5763 - mean_squared_error: 0.2821\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5607 - mean_squared_error: 0.2813\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5460 - mean_squared_error: 0.2805\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5323 - mean_squared_error: 0.2799\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5192 - mean_squared_error: 0.2794\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5070 - mean_squared_error: 0.2790\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4954 - mean_squared_error: 0.2781\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4847 - mean_squared_error: 0.2774\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4744 - mean_squared_error: 0.2767\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4647 - mean_squared_error: 0.2763\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4557 - mean_squared_error: 0.2762\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4474 - mean_squared_error: 0.2761\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4394 - mean_squared_error: 0.2756\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4319 - mean_squared_error: 0.2749\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4249 - mean_squared_error: 0.2742\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4184 - mean_squared_error: 0.2738\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4119 - mean_squared_error: 0.2731\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4061 - mean_squared_error: 0.2727\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4006 - mean_squared_error: 0.2723\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3955 - mean_squared_error: 0.2719\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3907 - mean_squared_error: 0.2715\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3860 - mean_squared_error: 0.2710\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3820 - mean_squared_error: 0.2711\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3780 - mean_squared_error: 0.2709\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3741 - mean_squared_error: 0.2707\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3706 - mean_squared_error: 0.2704\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3672 - mean_squared_error: 0.2702\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3640 - mean_squared_error: 0.2699\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3610 - mean_squared_error: 0.2696\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3582 - mean_squared_error: 0.2695\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3557 - mean_squared_error: 0.2693\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3532 - mean_squared_error: 0.2690\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3509 - mean_squared_error: 0.2685\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3486 - mean_squared_error: 0.2680\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff65c100048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3870 - mean_squared_error: 0.3078\n",
            "Training MSE: 0.30781787633895874\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5528 - mean_squared_error: 1.2449\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1780 - mean_squared_error: 1.1144\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8257 - mean_squared_error: 1.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5033 - mean_squared_error: 0.9115\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1986 - mean_squared_error: 0.8340\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9148 - mean_squared_error: 0.7722\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6496 - mean_squared_error: 0.7232\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3982 - mean_squared_error: 0.6821\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1605 - mean_squared_error: 0.6489\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9315 - mean_squared_error: 0.6182\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7142 - mean_squared_error: 0.5929\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5059 - mean_squared_error: 0.5701\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.3055 - mean_squared_error: 0.5487\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1146 - mean_squared_error: 0.5302\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9314 - mean_squared_error: 0.5128\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7567 - mean_squared_error: 0.4974\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5891 - mean_squared_error: 0.4828\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4297 - mean_squared_error: 0.4702\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2776 - mean_squared_error: 0.4587\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1330 - mean_squared_error: 0.4487\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9945 - mean_squared_error: 0.4390\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8625 - mean_squared_error: 0.4304\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7367 - mean_squared_error: 0.4226\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.6167 - mean_squared_error: 0.4153\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5020 - mean_squared_error: 0.4083\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.3924 - mean_squared_error: 0.4016\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2879 - mean_squared_error: 0.3954\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.1882 - mean_squared_error: 0.3894\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0931 - mean_squared_error: 0.3838\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0024 - mean_squared_error: 0.3783\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9161 - mean_squared_error: 0.3733\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8340 - mean_squared_error: 0.3686\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7556 - mean_squared_error: 0.3640\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6810 - mean_squared_error: 0.3599\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6101 - mean_squared_error: 0.3561\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5426 - mean_squared_error: 0.3524\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4785 - mean_squared_error: 0.3489\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4173 - mean_squared_error: 0.3455\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3592 - mean_squared_error: 0.3423\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3039 - mean_squared_error: 0.3391\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2515 - mean_squared_error: 0.3362\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2016 - mean_squared_error: 0.3332\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1542 - mean_squared_error: 0.3301\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1093 - mean_squared_error: 0.3273\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0665 - mean_squared_error: 0.3244\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0259 - mean_squared_error: 0.3218\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9875 - mean_squared_error: 0.3193\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9510 - mean_squared_error: 0.3169\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9162 - mean_squared_error: 0.3145\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8834 - mean_squared_error: 0.3125\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8522 - mean_squared_error: 0.3104\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8227 - mean_squared_error: 0.3085\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7949 - mean_squared_error: 0.3068\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7683 - mean_squared_error: 0.3048\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7432 - mean_squared_error: 0.3030\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7194 - mean_squared_error: 0.3012\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6969 - mean_squared_error: 0.2993\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6756 - mean_squared_error: 0.2976\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6555 - mean_squared_error: 0.2959\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6364 - mean_squared_error: 0.2943\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6185 - mean_squared_error: 0.2930\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6015 - mean_squared_error: 0.2917\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5853 - mean_squared_error: 0.2905\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5701 - mean_squared_error: 0.2895\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5557 - mean_squared_error: 0.2885\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5421 - mean_squared_error: 0.2875\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5293 - mean_squared_error: 0.2865\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5172 - mean_squared_error: 0.2855\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5058 - mean_squared_error: 0.2845\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4950 - mean_squared_error: 0.2836\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4847 - mean_squared_error: 0.2827\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4750 - mean_squared_error: 0.2819\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4659 - mean_squared_error: 0.2812\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4574 - mean_squared_error: 0.2804\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4492 - mean_squared_error: 0.2797\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4416 - mean_squared_error: 0.2791\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4345 - mean_squared_error: 0.2784\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4277 - mean_squared_error: 0.2778\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4213 - mean_squared_error: 0.2771\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4152 - mean_squared_error: 0.2764\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4094 - mean_squared_error: 0.2758\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4040 - mean_squared_error: 0.2752\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3989 - mean_squared_error: 0.2747\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3941 - mean_squared_error: 0.2741\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3896 - mean_squared_error: 0.2737\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3853 - mean_squared_error: 0.2731\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3814 - mean_squared_error: 0.2727\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3776 - mean_squared_error: 0.2720\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3739 - mean_squared_error: 0.2716\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3704 - mean_squared_error: 0.2710\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3672 - mean_squared_error: 0.2706\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3641 - mean_squared_error: 0.2702\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3611 - mean_squared_error: 0.2697\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3585 - mean_squared_error: 0.2694\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3559 - mean_squared_error: 0.2692\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3535 - mean_squared_error: 0.2689\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3513 - mean_squared_error: 0.2685\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3490 - mean_squared_error: 0.2680\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3468 - mean_squared_error: 0.2676\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3450 - mean_squared_error: 0.2673\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5facdf950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3797 - mean_squared_error: 0.3033\n",
            "Training MSE: 0.30325064063072205\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5476 - mean_squared_error: 1.2350\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1910 - mean_squared_error: 1.1344\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8567 - mean_squared_error: 1.0478\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.5366 - mean_squared_error: 0.9676\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2367 - mean_squared_error: 0.9003\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9513 - mean_squared_error: 0.8407\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6813 - mean_squared_error: 0.7897\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4252 - mean_squared_error: 0.7460\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1813 - mean_squared_error: 0.7079\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9491 - mean_squared_error: 0.6748\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.7265 - mean_squared_error: 0.6447\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5134 - mean_squared_error: 0.6176\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.3098 - mean_squared_error: 0.5932\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1143 - mean_squared_error: 0.5702\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9271 - mean_squared_error: 0.5488\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7482 - mean_squared_error: 0.5290\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.5773 - mean_squared_error: 0.5109\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4139 - mean_squared_error: 0.4939\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2582 - mean_squared_error: 0.4785\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1096 - mean_squared_error: 0.4641\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.9681 - mean_squared_error: 0.4512\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8339 - mean_squared_error: 0.4399\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7056 - mean_squared_error: 0.4291\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5835 - mean_squared_error: 0.4192\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4675 - mean_squared_error: 0.4104\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.3571 - mean_squared_error: 0.4021\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2518 - mean_squared_error: 0.3942\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1513 - mean_squared_error: 0.3865\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0560 - mean_squared_error: 0.3798\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9649 - mean_squared_error: 0.3732\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8786 - mean_squared_error: 0.3672\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7965 - mean_squared_error: 0.3616\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7184 - mean_squared_error: 0.3563\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6442 - mean_squared_error: 0.3514\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5737 - mean_squared_error: 0.3469\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.5068 - mean_squared_error: 0.3426\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4431 - mean_squared_error: 0.3386\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3829 - mean_squared_error: 0.3350\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3258 - mean_squared_error: 0.3315\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2713 - mean_squared_error: 0.3281\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2197 - mean_squared_error: 0.3249\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1709 - mean_squared_error: 0.3222\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1245 - mean_squared_error: 0.3195\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0806 - mean_squared_error: 0.3170\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0389 - mean_squared_error: 0.3146\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9995 - mean_squared_error: 0.3123\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9620 - mean_squared_error: 0.3099\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9267 - mean_squared_error: 0.3078\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8932 - mean_squared_error: 0.3057\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8614 - mean_squared_error: 0.3036\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8315 - mean_squared_error: 0.3018\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8030 - mean_squared_error: 0.2998\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7762 - mean_squared_error: 0.2982\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7508 - mean_squared_error: 0.2966\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7269 - mean_squared_error: 0.2951\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7042 - mean_squared_error: 0.2936\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6828 - mean_squared_error: 0.2922\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6626 - mean_squared_error: 0.2910\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6435 - mean_squared_error: 0.2899\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6254 - mean_squared_error: 0.2888\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6084 - mean_squared_error: 0.2880\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5923 - mean_squared_error: 0.2872\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5772 - mean_squared_error: 0.2865\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5629 - mean_squared_error: 0.2858\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5494 - mean_squared_error: 0.2849\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5366 - mean_squared_error: 0.2842\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5246 - mean_squared_error: 0.2833\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5132 - mean_squared_error: 0.2823\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5025 - mean_squared_error: 0.2813\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4924 - mean_squared_error: 0.2804\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4830 - mean_squared_error: 0.2796\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4738 - mean_squared_error: 0.2787\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4654 - mean_squared_error: 0.2782\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4573 - mean_squared_error: 0.2776\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4499 - mean_squared_error: 0.2773\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4427 - mean_squared_error: 0.2768\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4360 - mean_squared_error: 0.2761\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4297 - mean_squared_error: 0.2756\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4238 - mean_squared_error: 0.2753\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4182 - mean_squared_error: 0.2749\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4128 - mean_squared_error: 0.2744\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4078 - mean_squared_error: 0.2740\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4030 - mean_squared_error: 0.2736\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3986 - mean_squared_error: 0.2735\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3944 - mean_squared_error: 0.2733\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3904 - mean_squared_error: 0.2732\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3866 - mean_squared_error: 0.2731\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3830 - mean_squared_error: 0.2730\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3796 - mean_squared_error: 0.2727\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3765 - mean_squared_error: 0.2725\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3735 - mean_squared_error: 0.2722\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3707 - mean_squared_error: 0.2719\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3681 - mean_squared_error: 0.2717\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3655 - mean_squared_error: 0.2714\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3632 - mean_squared_error: 0.2712\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3608 - mean_squared_error: 0.2709\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3587 - mean_squared_error: 0.2708\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3567 - mean_squared_error: 0.2707\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3547 - mean_squared_error: 0.2705\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3529 - mean_squared_error: 0.2703\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fabbd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3862 - mean_squared_error: 0.3050\n",
            "Training MSE: 0.30502820014953613\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5981 - mean_squared_error: 1.9704\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1812 - mean_squared_error: 1.8053\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.7954 - mean_squared_error: 1.6648\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4320 - mean_squared_error: 1.5412\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0922 - mean_squared_error: 1.4352\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7732 - mean_squared_error: 1.3441\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.4694 - mean_squared_error: 1.2622\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1792 - mean_squared_error: 1.1878\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9036 - mean_squared_error: 1.1217\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6390 - mean_squared_error: 1.0600\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3841 - mean_squared_error: 1.0013\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1395 - mean_squared_error: 0.9463\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9059 - mean_squared_error: 0.8956\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6810 - mean_squared_error: 0.8469\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.4654 - mean_squared_error: 0.8011\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.2605 - mean_squared_error: 0.7595\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0638 - mean_squared_error: 0.7195\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.8780 - mean_squared_error: 0.6843\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6997 - mean_squared_error: 0.6504\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5299 - mean_squared_error: 0.6190\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3686 - mean_squared_error: 0.5902\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2150 - mean_squared_error: 0.5635\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.0691 - mean_squared_error: 0.5390\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.9294 - mean_squared_error: 0.5155\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.7968 - mean_squared_error: 0.4939\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.6702 - mean_squared_error: 0.4735\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5505 - mean_squared_error: 0.4552\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4369 - mean_squared_error: 0.4385\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3287 - mean_squared_error: 0.4231\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2264 - mean_squared_error: 0.4092\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1290 - mean_squared_error: 0.3964\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0368 - mean_squared_error: 0.3850\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9491 - mean_squared_error: 0.3745\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.8660 - mean_squared_error: 0.3652\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7872 - mean_squared_error: 0.3570\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7123 - mean_squared_error: 0.3493\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6414 - mean_squared_error: 0.3427\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5740 - mean_squared_error: 0.3365\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5101 - mean_squared_error: 0.3310\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4493 - mean_squared_error: 0.3259\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3922 - mean_squared_error: 0.3217\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3373 - mean_squared_error: 0.3173\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2854 - mean_squared_error: 0.3136\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2360 - mean_squared_error: 0.3103\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1895 - mean_squared_error: 0.3076\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1451 - mean_squared_error: 0.3050\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1030 - mean_squared_error: 0.3026\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0629 - mean_squared_error: 0.3003\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0249 - mean_squared_error: 0.2982\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9890 - mean_squared_error: 0.2964\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9547 - mean_squared_error: 0.2946\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9222 - mean_squared_error: 0.2930\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8914 - mean_squared_error: 0.2916\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8620 - mean_squared_error: 0.2903\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8343 - mean_squared_error: 0.2893\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8079 - mean_squared_error: 0.2883\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7828 - mean_squared_error: 0.2874\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7590 - mean_squared_error: 0.2866\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7365 - mean_squared_error: 0.2858\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7150 - mean_squared_error: 0.2848\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6947 - mean_squared_error: 0.2839\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6755 - mean_squared_error: 0.2830\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6573 - mean_squared_error: 0.2822\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6399 - mean_squared_error: 0.2815\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6236 - mean_squared_error: 0.2808\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6080 - mean_squared_error: 0.2801\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5932 - mean_squared_error: 0.2794\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5792 - mean_squared_error: 0.2789\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5658 - mean_squared_error: 0.2783\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5534 - mean_squared_error: 0.2778\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5414 - mean_squared_error: 0.2773\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5302 - mean_squared_error: 0.2769\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5195 - mean_squared_error: 0.2765\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5094 - mean_squared_error: 0.2762\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4997 - mean_squared_error: 0.2757\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4907 - mean_squared_error: 0.2752\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4821 - mean_squared_error: 0.2748\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4740 - mean_squared_error: 0.2743\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4662 - mean_squared_error: 0.2738\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4588 - mean_squared_error: 0.2736\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4519 - mean_squared_error: 0.2734\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4456 - mean_squared_error: 0.2733\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4391 - mean_squared_error: 0.2728\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4332 - mean_squared_error: 0.2724\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4277 - mean_squared_error: 0.2720\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4226 - mean_squared_error: 0.2718\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4174 - mean_squared_error: 0.2713\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4125 - mean_squared_error: 0.2708\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4079 - mean_squared_error: 0.2706\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4038 - mean_squared_error: 0.2705\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3999 - mean_squared_error: 0.2704\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3960 - mean_squared_error: 0.2699\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3922 - mean_squared_error: 0.2694\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3886 - mean_squared_error: 0.2687\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3854 - mean_squared_error: 0.2683\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3823 - mean_squared_error: 0.2678\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3793 - mean_squared_error: 0.2674\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3764 - mean_squared_error: 0.2671\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3736 - mean_squared_error: 0.2670\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3713 - mean_squared_error: 0.2671\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff65c2a4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4093 - mean_squared_error: 0.3071\n",
            "Training MSE: 0.30712616443634033\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4247 - mean_squared_error: 1.9954\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0065 - mean_squared_error: 1.8280\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6073 - mean_squared_error: 1.6708\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2316 - mean_squared_error: 1.5295\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8729 - mean_squared_error: 1.3983\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.5349 - mean_squared_error: 1.2811\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2179 - mean_squared_error: 1.1782\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9175 - mean_squared_error: 1.0850\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.6368 - mean_squared_error: 1.0047\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3727 - mean_squared_error: 0.9343\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.1220 - mean_squared_error: 0.8708\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.8879 - mean_squared_error: 0.8176\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6652 - mean_squared_error: 0.7694\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.4553 - mean_squared_error: 0.7276\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.2553 - mean_squared_error: 0.6898\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0646 - mean_squared_error: 0.6554\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.8842 - mean_squared_error: 0.6254\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7122 - mean_squared_error: 0.5981\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5485 - mean_squared_error: 0.5736\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3922 - mean_squared_error: 0.5511\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2441 - mean_squared_error: 0.5317\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1035 - mean_squared_error: 0.5144\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.9695 - mean_squared_error: 0.4988\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8416 - mean_squared_error: 0.4849\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7200 - mean_squared_error: 0.4726\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6042 - mean_squared_error: 0.4618\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.4939 - mean_squared_error: 0.4519\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3889 - mean_squared_error: 0.4432\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2887 - mean_squared_error: 0.4351\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1931 - mean_squared_error: 0.4275\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1019 - mean_squared_error: 0.4205\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0151 - mean_squared_error: 0.4141\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9321 - mean_squared_error: 0.4080\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8534 - mean_squared_error: 0.4027\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7785 - mean_squared_error: 0.3977\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7071 - mean_squared_error: 0.3929\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.6391 - mean_squared_error: 0.3883\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5743 - mean_squared_error: 0.3838\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5126 - mean_squared_error: 0.3793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4540 - mean_squared_error: 0.3752\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3981 - mean_squared_error: 0.3711\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3451 - mean_squared_error: 0.3670\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2945 - mean_squared_error: 0.3629\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2465 - mean_squared_error: 0.3590\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.2008 - mean_squared_error: 0.3551\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1574 - mean_squared_error: 0.3514\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1161 - mean_squared_error: 0.3479\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0768 - mean_squared_error: 0.3447\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0396 - mean_squared_error: 0.3416\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0041 - mean_squared_error: 0.3387\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9704 - mean_squared_error: 0.3360\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9386 - mean_squared_error: 0.3334\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9081 - mean_squared_error: 0.3306\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8793 - mean_squared_error: 0.3282\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8519 - mean_squared_error: 0.3259\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8259 - mean_squared_error: 0.3237\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8011 - mean_squared_error: 0.3214\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7777 - mean_squared_error: 0.3193\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7555 - mean_squared_error: 0.3173\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7343 - mean_squared_error: 0.3155\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7143 - mean_squared_error: 0.3139\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6952 - mean_squared_error: 0.3124\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6770 - mean_squared_error: 0.3109\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6599 - mean_squared_error: 0.3098\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6436 - mean_squared_error: 0.3086\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6282 - mean_squared_error: 0.3072\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6134 - mean_squared_error: 0.3060\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5996 - mean_squared_error: 0.3048\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5863 - mean_squared_error: 0.3035\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5737 - mean_squared_error: 0.3022\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5617 - mean_squared_error: 0.3011\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5504 - mean_squared_error: 0.2999\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5396 - mean_squared_error: 0.2987\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5294 - mean_squared_error: 0.2975\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5197 - mean_squared_error: 0.2963\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5104 - mean_squared_error: 0.2952\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5016 - mean_squared_error: 0.2942\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4933 - mean_squared_error: 0.2934\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4854 - mean_squared_error: 0.2926\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4778 - mean_squared_error: 0.2919\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4707 - mean_squared_error: 0.2913\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4638 - mean_squared_error: 0.2905\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4574 - mean_squared_error: 0.2899\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4513 - mean_squared_error: 0.2892\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4454 - mean_squared_error: 0.2885\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4398 - mean_squared_error: 0.2879\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4344 - mean_squared_error: 0.2873\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4294 - mean_squared_error: 0.2867\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4246 - mean_squared_error: 0.2861\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4200 - mean_squared_error: 0.2855\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4156 - mean_squared_error: 0.2848\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4115 - mean_squared_error: 0.2842\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4076 - mean_squared_error: 0.2835\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4038 - mean_squared_error: 0.2828\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4000 - mean_squared_error: 0.2823\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3967 - mean_squared_error: 0.2820\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3936 - mean_squared_error: 0.2820\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3906 - mean_squared_error: 0.2818\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3876 - mean_squared_error: 0.2814\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3845 - mean_squared_error: 0.2808\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff65c1e8d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4207 - mean_squared_error: 0.3189\n",
            "Training MSE: 0.31888294219970703\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7321 - mean_squared_error: 1.5902\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3376 - mean_squared_error: 1.4407\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.9706 - mean_squared_error: 1.3115\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6219 - mean_squared_error: 1.1938\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2955 - mean_squared_error: 1.0922\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9913 - mean_squared_error: 1.0063\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7031 - mean_squared_error: 0.9300\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4313 - mean_squared_error: 0.8641\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1750 - mean_squared_error: 0.8072\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.9302 - mean_squared_error: 0.7556\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.6991 - mean_squared_error: 0.7112\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4777 - mean_squared_error: 0.6699\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.2662 - mean_squared_error: 0.6321\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.0654 - mean_squared_error: 0.5983\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.8735 - mean_squared_error: 0.5669\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6911 - mean_squared_error: 0.5385\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5170 - mean_squared_error: 0.5121\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3517 - mean_squared_error: 0.4883\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.1944 - mean_squared_error: 0.4665\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0444 - mean_squared_error: 0.4461\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.9029 - mean_squared_error: 0.4284\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7684 - mean_squared_error: 0.4121\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.6405 - mean_squared_error: 0.3972\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5199 - mean_squared_error: 0.3844\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4049 - mean_squared_error: 0.3725\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2961 - mean_squared_error: 0.3621\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.1927 - mean_squared_error: 0.3526\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0949 - mean_squared_error: 0.3446\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0016 - mean_squared_error: 0.3369\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9134 - mean_squared_error: 0.3304\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8293 - mean_squared_error: 0.3244\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7496 - mean_squared_error: 0.3190\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.6740 - mean_squared_error: 0.3143\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6023 - mean_squared_error: 0.3101\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5342 - mean_squared_error: 0.3063\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4697 - mean_squared_error: 0.3030\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4085 - mean_squared_error: 0.3000\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3504 - mean_squared_error: 0.2973\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2951 - mean_squared_error: 0.2947\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2427 - mean_squared_error: 0.2924\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1930 - mean_squared_error: 0.2903\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1457 - mean_squared_error: 0.2883\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1010 - mean_squared_error: 0.2865\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0586 - mean_squared_error: 0.2849\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0183 - mean_squared_error: 0.2834\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9802 - mean_squared_error: 0.2821\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9442 - mean_squared_error: 0.2809\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9098 - mean_squared_error: 0.2797\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8774 - mean_squared_error: 0.2788\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8467 - mean_squared_error: 0.2778\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8176 - mean_squared_error: 0.2770\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7902 - mean_squared_error: 0.2763\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7642 - mean_squared_error: 0.2757\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7395 - mean_squared_error: 0.2751\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7162 - mean_squared_error: 0.2745\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6942 - mean_squared_error: 0.2740\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6733 - mean_squared_error: 0.2735\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6535 - mean_squared_error: 0.2729\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6349 - mean_squared_error: 0.2723\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6172 - mean_squared_error: 0.2717\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6007 - mean_squared_error: 0.2712\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5850 - mean_squared_error: 0.2708\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5702 - mean_squared_error: 0.2706\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5561 - mean_squared_error: 0.2703\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5428 - mean_squared_error: 0.2701\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5303 - mean_squared_error: 0.2700\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5186 - mean_squared_error: 0.2698\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5073 - mean_squared_error: 0.2694\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4967 - mean_squared_error: 0.2689\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4867 - mean_squared_error: 0.2684\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4773 - mean_squared_error: 0.2680\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4686 - mean_squared_error: 0.2677\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4603 - mean_squared_error: 0.2674\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4523 - mean_squared_error: 0.2671\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4448 - mean_squared_error: 0.2669\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4377 - mean_squared_error: 0.2668\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4311 - mean_squared_error: 0.2666\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4248 - mean_squared_error: 0.2665\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4188 - mean_squared_error: 0.2662\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4133 - mean_squared_error: 0.2661\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4081 - mean_squared_error: 0.2660\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4033 - mean_squared_error: 0.2659\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3985 - mean_squared_error: 0.2657\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3939 - mean_squared_error: 0.2655\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3897 - mean_squared_error: 0.2653\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3858 - mean_squared_error: 0.2653\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3822 - mean_squared_error: 0.2653\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3787 - mean_squared_error: 0.2652\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3752 - mean_squared_error: 0.2650\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3721 - mean_squared_error: 0.2650\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3691 - mean_squared_error: 0.2649\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3663 - mean_squared_error: 0.2648\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3637 - mean_squared_error: 0.2649\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3614 - mean_squared_error: 0.2651\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3590 - mean_squared_error: 0.2650\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3565 - mean_squared_error: 0.2647\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3544 - mean_squared_error: 0.2646\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3523 - mean_squared_error: 0.2644\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3504 - mean_squared_error: 0.2643\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3486 - mean_squared_error: 0.2642\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fa225d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3860 - mean_squared_error: 0.3031\n",
            "Training MSE: 0.30306476354599\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1068 - mean_squared_error: 1.9103\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6890 - mean_squared_error: 1.7274\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3042 - mean_squared_error: 1.5713\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9420 - mean_squared_error: 1.4322\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6065 - mean_squared_error: 1.3144\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2969 - mean_squared_error: 1.2166\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0064 - mean_squared_error: 1.1321\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7329 - mean_squared_error: 1.0591\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4735 - mean_squared_error: 0.9948\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2290 - mean_squared_error: 0.9398\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9957 - mean_squared_error: 0.8902\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7724 - mean_squared_error: 0.8450\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5593 - mean_squared_error: 0.8042\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.3558 - mean_squared_error: 0.7671\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.1611 - mean_squared_error: 0.7330\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9749 - mean_squared_error: 0.7015\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7984 - mean_squared_error: 0.6737\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6286 - mean_squared_error: 0.6469\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.4673 - mean_squared_error: 0.6231\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3126 - mean_squared_error: 0.6002\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1659 - mean_squared_error: 0.5799\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.0252 - mean_squared_error: 0.5603\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8916 - mean_squared_error: 0.5425\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.7645 - mean_squared_error: 0.5260\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.6433 - mean_squared_error: 0.5106\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5272 - mean_squared_error: 0.4956\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4177 - mean_squared_error: 0.4825\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.3125 - mean_squared_error: 0.4694\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.2125 - mean_squared_error: 0.4573\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.1174 - mean_squared_error: 0.4460\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0265 - mean_squared_error: 0.4350\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9398 - mean_squared_error: 0.4244\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.8577 - mean_squared_error: 0.4148\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7793 - mean_squared_error: 0.4055\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7047 - mean_squared_error: 0.3967\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6342 - mean_squared_error: 0.3889\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5666 - mean_squared_error: 0.3810\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5026 - mean_squared_error: 0.3741\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4417 - mean_squared_error: 0.3676\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3837 - mean_squared_error: 0.3613\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3287 - mean_squared_error: 0.3557\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.2765 - mean_squared_error: 0.3505\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2268 - mean_squared_error: 0.3454\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1798 - mean_squared_error: 0.3408\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1350 - mean_squared_error: 0.3363\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0924 - mean_squared_error: 0.3318\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0522 - mean_squared_error: 0.3278\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0138 - mean_squared_error: 0.3238\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9775 - mean_squared_error: 0.3202\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9430 - mean_squared_error: 0.3167\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9103 - mean_squared_error: 0.3136\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8793 - mean_squared_error: 0.3106\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8500 - mean_squared_error: 0.3079\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8221 - mean_squared_error: 0.3052\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7957 - mean_squared_error: 0.3028\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7709 - mean_squared_error: 0.3006\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7471 - mean_squared_error: 0.2984\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7248 - mean_squared_error: 0.2966\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7034 - mean_squared_error: 0.2947\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6833 - mean_squared_error: 0.2930\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6643 - mean_squared_error: 0.2914\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6463 - mean_squared_error: 0.2899\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6293 - mean_squared_error: 0.2884\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6131 - mean_squared_error: 0.2870\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5977 - mean_squared_error: 0.2857\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5833 - mean_squared_error: 0.2846\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5695 - mean_squared_error: 0.2835\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5566 - mean_squared_error: 0.2825\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5443 - mean_squared_error: 0.2815\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5327 - mean_squared_error: 0.2806\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5216 - mean_squared_error: 0.2797\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5113 - mean_squared_error: 0.2789\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5013 - mean_squared_error: 0.2781\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4919 - mean_squared_error: 0.2774\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4831 - mean_squared_error: 0.2767\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4748 - mean_squared_error: 0.2763\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4668 - mean_squared_error: 0.2757\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4593 - mean_squared_error: 0.2752\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4522 - mean_squared_error: 0.2749\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4454 - mean_squared_error: 0.2744\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4392 - mean_squared_error: 0.2740\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4330 - mean_squared_error: 0.2733\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4273 - mean_squared_error: 0.2729\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4218 - mean_squared_error: 0.2724\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4167 - mean_squared_error: 0.2720\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4118 - mean_squared_error: 0.2715\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4072 - mean_squared_error: 0.2711\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4029 - mean_squared_error: 0.2707\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3988 - mean_squared_error: 0.2703\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3948 - mean_squared_error: 0.2701\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3910 - mean_squared_error: 0.2698\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3874 - mean_squared_error: 0.2696\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3840 - mean_squared_error: 0.2694\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3809 - mean_squared_error: 0.2693\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3780 - mean_squared_error: 0.2691\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3752 - mean_squared_error: 0.2688\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3724 - mean_squared_error: 0.2685\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3697 - mean_squared_error: 0.2680\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3671 - mean_squared_error: 0.2676\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3648 - mean_squared_error: 0.2675\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fabab510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3986 - mean_squared_error: 0.3029\n",
            "Training MSE: 0.3029375672340393\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4058 - mean_squared_error: 1.0425\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0273 - mean_squared_error: 0.9133\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6824 - mean_squared_error: 0.8117\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3659 - mean_squared_error: 0.7326\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0752 - mean_squared_error: 0.6737\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.8020 - mean_squared_error: 0.6268\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.5458 - mean_squared_error: 0.5911\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3004 - mean_squared_error: 0.5600\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0666 - mean_squared_error: 0.5339\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.8395 - mean_squared_error: 0.5078\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6225 - mean_squared_error: 0.4850\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4137 - mean_squared_error: 0.4634\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.2147 - mean_squared_error: 0.4448\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0243 - mean_squared_error: 0.4279\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8438 - mean_squared_error: 0.4143\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6720 - mean_squared_error: 0.4027\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5079 - mean_squared_error: 0.3925\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3512 - mean_squared_error: 0.3835\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2018 - mean_squared_error: 0.3755\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0587 - mean_squared_error: 0.3678\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9222 - mean_squared_error: 0.3608\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7920 - mean_squared_error: 0.3546\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6674 - mean_squared_error: 0.3487\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5489 - mean_squared_error: 0.3436\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4359 - mean_squared_error: 0.3389\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3283 - mean_squared_error: 0.3349\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2256 - mean_squared_error: 0.3311\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1274 - mean_squared_error: 0.3276\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0341 - mean_squared_error: 0.3246\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9450 - mean_squared_error: 0.3216\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8604 - mean_squared_error: 0.3191\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7796 - mean_squared_error: 0.3165\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7027 - mean_squared_error: 0.3140\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.6296 - mean_squared_error: 0.3118\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5600 - mean_squared_error: 0.3096\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4938 - mean_squared_error: 0.3076\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4309 - mean_squared_error: 0.3057\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3709 - mean_squared_error: 0.3038\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3140 - mean_squared_error: 0.3021\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2600 - mean_squared_error: 0.3006\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2086 - mean_squared_error: 0.2990\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1598 - mean_squared_error: 0.2976\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1136 - mean_squared_error: 0.2963\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0696 - mean_squared_error: 0.2948\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0279 - mean_squared_error: 0.2933\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9883 - mean_squared_error: 0.2919\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9508 - mean_squared_error: 0.2907\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9151 - mean_squared_error: 0.2895\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8814 - mean_squared_error: 0.2884\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8495 - mean_squared_error: 0.2873\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8191 - mean_squared_error: 0.2862\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7905 - mean_squared_error: 0.2852\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7634 - mean_squared_error: 0.2842\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7377 - mean_squared_error: 0.2832\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7133 - mean_squared_error: 0.2822\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6903 - mean_squared_error: 0.2814\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6686 - mean_squared_error: 0.2806\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6480 - mean_squared_error: 0.2797\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6284 - mean_squared_error: 0.2788\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6100 - mean_squared_error: 0.2781\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5926 - mean_squared_error: 0.2774\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5761 - mean_squared_error: 0.2769\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5606 - mean_squared_error: 0.2763\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5459 - mean_squared_error: 0.2756\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5320 - mean_squared_error: 0.2749\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5188 - mean_squared_error: 0.2743\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5064 - mean_squared_error: 0.2738\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4948 - mean_squared_error: 0.2732\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4837 - mean_squared_error: 0.2726\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4735 - mean_squared_error: 0.2721\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4635 - mean_squared_error: 0.2714\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4543 - mean_squared_error: 0.2708\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4455 - mean_squared_error: 0.2702\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4373 - mean_squared_error: 0.2696\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4296 - mean_squared_error: 0.2692\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4223 - mean_squared_error: 0.2688\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4153 - mean_squared_error: 0.2683\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4089 - mean_squared_error: 0.2680\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4027 - mean_squared_error: 0.2676\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3971 - mean_squared_error: 0.2676\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3915 - mean_squared_error: 0.2673\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3864 - mean_squared_error: 0.2670\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3817 - mean_squared_error: 0.2669\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3772 - mean_squared_error: 0.2668\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3728 - mean_squared_error: 0.2665\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3687 - mean_squared_error: 0.2661\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3648 - mean_squared_error: 0.2656\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3612 - mean_squared_error: 0.2651\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3578 - mean_squared_error: 0.2647\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3547 - mean_squared_error: 0.2643\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3517 - mean_squared_error: 0.2640\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3488 - mean_squared_error: 0.2637\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3463 - mean_squared_error: 0.2635\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3437 - mean_squared_error: 0.2633\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3413 - mean_squared_error: 0.2630\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3390 - mean_squared_error: 0.2628\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3371 - mean_squared_error: 0.2629\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3350 - mean_squared_error: 0.2627\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3330 - mean_squared_error: 0.2626\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3313 - mean_squared_error: 0.2624\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5f568b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3700 - mean_squared_error: 0.3024\n",
            "Training MSE: 0.3024336099624634\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.1089 - mean_squared_error: 1.6050\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6971 - mean_squared_error: 1.4427\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3143 - mean_squared_error: 1.3029\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.9626 - mean_squared_error: 1.1880\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6334 - mean_squared_error: 1.0896\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3294 - mean_squared_error: 1.0107\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.0438 - mean_squared_error: 0.9443\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7756 - mean_squared_error: 0.8891\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.5181 - mean_squared_error: 0.8387\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2749 - mean_squared_error: 0.7962\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.0396 - mean_squared_error: 0.7553\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8144 - mean_squared_error: 0.7180\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.5980 - mean_squared_error: 0.6828\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.3910 - mean_squared_error: 0.6506\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1918 - mean_squared_error: 0.6196\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0025 - mean_squared_error: 0.5921\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.8211 - mean_squared_error: 0.5662\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6483 - mean_squared_error: 0.5427\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.4834 - mean_squared_error: 0.5211\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.3275 - mean_squared_error: 0.5026\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1777 - mean_squared_error: 0.4844\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0355 - mean_squared_error: 0.4683\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9001 - mean_squared_error: 0.4536\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7707 - mean_squared_error: 0.4397\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.6476 - mean_squared_error: 0.4269\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.5303 - mean_squared_error: 0.4150\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4192 - mean_squared_error: 0.4045\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3130 - mean_squared_error: 0.3944\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2115 - mean_squared_error: 0.3847\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1153 - mean_squared_error: 0.3762\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0237 - mean_squared_error: 0.3684\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9361 - mean_squared_error: 0.3608\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.8535 - mean_squared_error: 0.3545\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7746 - mean_squared_error: 0.3483\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6999 - mean_squared_error: 0.3427\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6283 - mean_squared_error: 0.3370\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5607 - mean_squared_error: 0.3322\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4962 - mean_squared_error: 0.3275\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4348 - mean_squared_error: 0.3232\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3766 - mean_squared_error: 0.3193\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3214 - mean_squared_error: 0.3157\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2688 - mean_squared_error: 0.3124\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.2190 - mean_squared_error: 0.3095\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1717 - mean_squared_error: 0.3066\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1267 - mean_squared_error: 0.3039\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0843 - mean_squared_error: 0.3015\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0437 - mean_squared_error: 0.2990\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0052 - mean_squared_error: 0.2967\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9689 - mean_squared_error: 0.2947\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9344 - mean_squared_error: 0.2927\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9016 - mean_squared_error: 0.2910\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8705 - mean_squared_error: 0.2892\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8411 - mean_squared_error: 0.2876\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8131 - mean_squared_error: 0.2861\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7867 - mean_squared_error: 0.2846\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7616 - mean_squared_error: 0.2832\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7379 - mean_squared_error: 0.2819\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7154 - mean_squared_error: 0.2808\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6941 - mean_squared_error: 0.2797\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6738 - mean_squared_error: 0.2787\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6546 - mean_squared_error: 0.2778\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6365 - mean_squared_error: 0.2771\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6193 - mean_squared_error: 0.2763\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6033 - mean_squared_error: 0.2758\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5878 - mean_squared_error: 0.2750\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5732 - mean_squared_error: 0.2742\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5594 - mean_squared_error: 0.2735\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5463 - mean_squared_error: 0.2728\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5340 - mean_squared_error: 0.2722\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5223 - mean_squared_error: 0.2717\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5113 - mean_squared_error: 0.2714\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5009 - mean_squared_error: 0.2711\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4909 - mean_squared_error: 0.2708\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4815 - mean_squared_error: 0.2706\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4727 - mean_squared_error: 0.2703\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4644 - mean_squared_error: 0.2702\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4564 - mean_squared_error: 0.2699\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4489 - mean_squared_error: 0.2694\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4418 - mean_squared_error: 0.2691\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4352 - mean_squared_error: 0.2688\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4288 - mean_squared_error: 0.2684\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4227 - mean_squared_error: 0.2682\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4171 - mean_squared_error: 0.2682\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4117 - mean_squared_error: 0.2680\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4067 - mean_squared_error: 0.2679\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4018 - mean_squared_error: 0.2677\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3972 - mean_squared_error: 0.2673\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3927 - mean_squared_error: 0.2668\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3886 - mean_squared_error: 0.2664\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3848 - mean_squared_error: 0.2661\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3811 - mean_squared_error: 0.2658\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3776 - mean_squared_error: 0.2655\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3745 - mean_squared_error: 0.2656\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3711 - mean_squared_error: 0.2651\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3682 - mean_squared_error: 0.2649\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3654 - mean_squared_error: 0.2647\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3626 - mean_squared_error: 0.2645\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3600 - mean_squared_error: 0.2642\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3576 - mean_squared_error: 0.2639\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3554 - mean_squared_error: 0.2636\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5f4cfd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3927 - mean_squared_error: 0.3025\n",
            "Training MSE: 0.3024577498435974\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9352 - mean_squared_error: 1.3050\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5586 - mean_squared_error: 1.1885\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2037 - mean_squared_error: 1.0871\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8654 - mean_squared_error: 0.9951\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.5507 - mean_squared_error: 0.9196\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2496 - mean_squared_error: 0.8508\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9665 - mean_squared_error: 0.7934\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6981 - mean_squared_error: 0.7441\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4438 - mean_squared_error: 0.7025\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.2013 - mean_squared_error: 0.6661\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9708 - mean_squared_error: 0.6349\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7496 - mean_squared_error: 0.6065\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5379 - mean_squared_error: 0.5809\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.3358 - mean_squared_error: 0.5583\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1418 - mean_squared_error: 0.5371\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9558 - mean_squared_error: 0.5174\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7790 - mean_squared_error: 0.5005\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6086 - mean_squared_error: 0.4835\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4461 - mean_squared_error: 0.4683\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.2912 - mean_squared_error: 0.4546\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.1432 - mean_squared_error: 0.4417\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0019 - mean_squared_error: 0.4299\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8672 - mean_squared_error: 0.4189\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7389 - mean_squared_error: 0.4089\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6163 - mean_squared_error: 0.3992\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.4992 - mean_squared_error: 0.3901\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.3878 - mean_squared_error: 0.3820\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2814 - mean_squared_error: 0.3741\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.1800 - mean_squared_error: 0.3669\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0835 - mean_squared_error: 0.3601\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9916 - mean_squared_error: 0.3536\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.9041 - mean_squared_error: 0.3477\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8209 - mean_squared_error: 0.3421\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7416 - mean_squared_error: 0.3368\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6662 - mean_squared_error: 0.3318\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5947 - mean_squared_error: 0.3272\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5265 - mean_squared_error: 0.3229\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4618 - mean_squared_error: 0.3188\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4004 - mean_squared_error: 0.3150\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3421 - mean_squared_error: 0.3114\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2868 - mean_squared_error: 0.3081\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2341 - mean_squared_error: 0.3048\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1842 - mean_squared_error: 0.3020\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1368 - mean_squared_error: 0.2992\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0919 - mean_squared_error: 0.2968\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0493 - mean_squared_error: 0.2945\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0090 - mean_squared_error: 0.2922\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9706 - mean_squared_error: 0.2899\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9345 - mean_squared_error: 0.2879\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9002 - mean_squared_error: 0.2860\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8677 - mean_squared_error: 0.2843\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8368 - mean_squared_error: 0.2827\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8077 - mean_squared_error: 0.2813\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7800 - mean_squared_error: 0.2800\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7540 - mean_squared_error: 0.2789\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7292 - mean_squared_error: 0.2778\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7059 - mean_squared_error: 0.2770\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6838 - mean_squared_error: 0.2762\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6629 - mean_squared_error: 0.2753\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6431 - mean_squared_error: 0.2744\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6244 - mean_squared_error: 0.2734\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6067 - mean_squared_error: 0.2728\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5901 - mean_squared_error: 0.2721\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5743 - mean_squared_error: 0.2715\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5593 - mean_squared_error: 0.2707\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5453 - mean_squared_error: 0.2702\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5320 - mean_squared_error: 0.2697\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5194 - mean_squared_error: 0.2692\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5075 - mean_squared_error: 0.2688\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4963 - mean_squared_error: 0.2684\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4857 - mean_squared_error: 0.2680\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4757 - mean_squared_error: 0.2674\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4664 - mean_squared_error: 0.2672\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4574 - mean_squared_error: 0.2668\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4490 - mean_squared_error: 0.2666\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4410 - mean_squared_error: 0.2661\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4335 - mean_squared_error: 0.2657\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4264 - mean_squared_error: 0.2654\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4199 - mean_squared_error: 0.2652\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4137 - mean_squared_error: 0.2649\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4076 - mean_squared_error: 0.2644\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4019 - mean_squared_error: 0.2640\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3966 - mean_squared_error: 0.2639\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3916 - mean_squared_error: 0.2637\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3868 - mean_squared_error: 0.2632\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3825 - mean_squared_error: 0.2631\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3783 - mean_squared_error: 0.2629\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3742 - mean_squared_error: 0.2627\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3707 - mean_squared_error: 0.2628\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3671 - mean_squared_error: 0.2627\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3636 - mean_squared_error: 0.2622\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3604 - mean_squared_error: 0.2618\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3575 - mean_squared_error: 0.2617\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3546 - mean_squared_error: 0.2615\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3520 - mean_squared_error: 0.2615\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3494 - mean_squared_error: 0.2614\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3470 - mean_squared_error: 0.2615\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3448 - mean_squared_error: 0.2615\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3427 - mean_squared_error: 0.2613\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3406 - mean_squared_error: 0.2611\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fabbd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3780 - mean_squared_error: 0.2999\n",
            "Training MSE: 0.2999005615711212\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.9547 - mean_squared_error: 1.3471\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5862 - mean_squared_error: 1.2381\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2372 - mean_squared_error: 1.1418\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9071 - mean_squared_error: 1.0576\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5940 - mean_squared_error: 0.9838\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3003 - mean_squared_error: 0.9229\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0171 - mean_squared_error: 0.8661\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7509 - mean_squared_error: 0.8198\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4949 - mean_squared_error: 0.7771\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2514 - mean_squared_error: 0.7403\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0180 - mean_squared_error: 0.7067\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 4.7945 - mean_squared_error: 0.6760\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5806 - mean_squared_error: 0.6479\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.3752 - mean_squared_error: 0.6214\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1799 - mean_squared_error: 0.5980\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.9916 - mean_squared_error: 0.5748\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.8133 - mean_squared_error: 0.5549\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6416 - mean_squared_error: 0.5351\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4792 - mean_squared_error: 0.5182\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3237 - mean_squared_error: 0.5022\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1748 - mean_squared_error: 0.4869\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0338 - mean_squared_error: 0.4736\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8992 - mean_squared_error: 0.4613\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7711 - mean_squared_error: 0.4499\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6487 - mean_squared_error: 0.4391\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5322 - mean_squared_error: 0.4293\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4213 - mean_squared_error: 0.4204\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3151 - mean_squared_error: 0.4118\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.2145 - mean_squared_error: 0.4045\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1186 - mean_squared_error: 0.3976\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0272 - mean_squared_error: 0.3911\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.9400 - mean_squared_error: 0.3849\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8571 - mean_squared_error: 0.3792\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7780 - mean_squared_error: 0.3738\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.7031 - mean_squared_error: 0.3690\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6312 - mean_squared_error: 0.3640\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.5632 - mean_squared_error: 0.3595\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4983 - mean_squared_error: 0.3552\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4367 - mean_squared_error: 0.3512\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3780 - mean_squared_error: 0.3475\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3222 - mean_squared_error: 0.3441\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2693 - mean_squared_error: 0.3410\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2191 - mean_squared_error: 0.3381\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1712 - mean_squared_error: 0.3351\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1261 - mean_squared_error: 0.3325\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0827 - mean_squared_error: 0.3294\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0416 - mean_squared_error: 0.3266\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0027 - mean_squared_error: 0.3243\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9659 - mean_squared_error: 0.3221\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9309 - mean_squared_error: 0.3199\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8976 - mean_squared_error: 0.3177\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8662 - mean_squared_error: 0.3156\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8363 - mean_squared_error: 0.3135\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8080 - mean_squared_error: 0.3115\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7811 - mean_squared_error: 0.3094\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7557 - mean_squared_error: 0.3074\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7316 - mean_squared_error: 0.3055\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7088 - mean_squared_error: 0.3038\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6872 - mean_squared_error: 0.3022\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6667 - mean_squared_error: 0.3006\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6474 - mean_squared_error: 0.2993\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6291 - mean_squared_error: 0.2980\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6119 - mean_squared_error: 0.2968\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5954 - mean_squared_error: 0.2955\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5800 - mean_squared_error: 0.2943\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5654 - mean_squared_error: 0.2930\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5516 - mean_squared_error: 0.2916\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5385 - mean_squared_error: 0.2904\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5260 - mean_squared_error: 0.2892\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5144 - mean_squared_error: 0.2883\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5033 - mean_squared_error: 0.2873\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4930 - mean_squared_error: 0.2865\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4831 - mean_squared_error: 0.2856\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4737 - mean_squared_error: 0.2847\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4650 - mean_squared_error: 0.2839\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4566 - mean_squared_error: 0.2830\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4489 - mean_squared_error: 0.2824\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4415 - mean_squared_error: 0.2817\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4344 - mean_squared_error: 0.2811\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4278 - mean_squared_error: 0.2805\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4216 - mean_squared_error: 0.2798\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4158 - mean_squared_error: 0.2791\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4103 - mean_squared_error: 0.2784\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4050 - mean_squared_error: 0.2777\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4001 - mean_squared_error: 0.2772\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3954 - mean_squared_error: 0.2768\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3908 - mean_squared_error: 0.2761\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3867 - mean_squared_error: 0.2756\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3829 - mean_squared_error: 0.2752\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3791 - mean_squared_error: 0.2747\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3753 - mean_squared_error: 0.2739\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3721 - mean_squared_error: 0.2735\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3692 - mean_squared_error: 0.2733\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3661 - mean_squared_error: 0.2728\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3630 - mean_squared_error: 0.2721\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3604 - mean_squared_error: 0.2718\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3581 - mean_squared_error: 0.2715\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3558 - mean_squared_error: 0.2712\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3534 - mean_squared_error: 0.2708\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3513 - mean_squared_error: 0.2706\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'lat': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float32>, 'long': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float32>, 'restaurants': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float32>, 'shopping': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float32>, 'vibrant': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float32>, 'cycling_friendly': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float32>, 'car_friendly': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>, 'historic': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float32>, 'quiet': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float32>, 'elementary_schools': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float32>, 'high_schools': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float32>, 'parks': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float32>, 'nightlife': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float32>, 'groceries': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float32>, 'daycares': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>, 'pedestrian_friendly': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float32>, 'cafes': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'transit_friendly': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float32>, 'greenery': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float32>, 'year_built': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float32>, 'population_2016_': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float32>, 'population_variation_between_2011_2016_': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float32>, 'population_density_': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float32>, 'unemployment_rate_2016_': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float32>, 'walk_score': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float32>, 'rooms': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float32>, 'bedrooms': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'bathrooms': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'powder_rooms': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float32>, 'total_area': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float32>, 'river_proximity': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'has_pool': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'n_parking': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float32>, 'has_garage': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'is_devided': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'mr_distance': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5fa12ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3907 - mean_squared_error: 0.3114\n",
            "Training MSE: 0.31139084696769714\n",
            "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohqIZIP9IxsU",
        "outputId": "c3c102e3-5b81-47e0-fd0d-c5a39ca5fb90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print('Average mses for number of nodes:')\n",
        "for i in range(len(n_nodes)):\n",
        "    print(n_nodes[i], 'number of nodes: average mse =', average_mses[i])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average mses for number of nodes:\n",
            "[25] number of nodes: average mse = 0.30434403121471404\n",
            "[15] number of nodes: average mse = 0.30513900220394136\n",
            "[10] number of nodes: average mse = 0.3056473046541214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjwmdiQfRgTF"
      },
      "source": [
        "One layer performs best, with similar results using ReLu and Tanh activation.\n",
        "There doesn't seem to be a significant diffence in the performance of the linear and non linear nets. The simpler model will therefore be chose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can't pickle local object 'WeakSet.__init__.<locals>._remove'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6d796ce76c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf_linear_model.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_linear_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'WeakSet.__init__.<locals>._remove'"
          ]
        }
      ],
      "source": [
        "filename = 'tf_linear_model.sav'\n",
        "pickle.dump(my_linear_model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}